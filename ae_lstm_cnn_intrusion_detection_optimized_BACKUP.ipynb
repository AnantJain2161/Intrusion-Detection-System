{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b3b922",
   "metadata": {},
   "source": [
    "# AE-LSTM-CNN for CICIoT2023 Intrusion Detection\n",
    "## Hardware-Optimized Architecture with Peak GPU Utilization (Linux/WSL Optimized)\n",
    "\n",
    "This notebook implements an Autoencoder-LSTM-CNN hybrid architecture for intrusion detection on the CICIoT2023 dataset.\n",
    "\n",
    "### Architecture Overview:\n",
    "1. **Autoencoder**: Dimensionality reduction and feature extraction\n",
    "2. **LSTM**: Temporal pattern recognition (Bidirectional)\n",
    "3. **CNN**: Local feature extraction\n",
    "4. **Classification Head**: Multi-class attack detection\n",
    "\n",
    "### GPU Optimization Strategy (LINUX/WSL):\n",
    "- **Large Batch Size**: 20480 samples to saturate GPU compute\n",
    "- **Background File Prefetching**: CPU loads files while GPU trains (eliminates I/O bottleneck)\n",
    "- **VRAM Caching**: Intelligently caches data on GPU when possible (~4.5GB)\n",
    "- **Multi-worker Data Loading**: 4 workers with fork() method (Linux advantage)\n",
    "- **Pinned Memory**: Zero-copy CPU‚ÜíGPU transfer for ~2x faster data movement\n",
    "- **Prefetching**: 4 batches loaded ahead to eliminate GPU stalls\n",
    "- **Persistent Workers**: Workers stay alive between chunks (no restart overhead)\n",
    "- **Non-blocking Transfers**: CPU preprocessing overlaps with GPU compute\n",
    "- **Larger Chunks**: 500K rows for better file I/O efficiency\n",
    "- **cuDNN Autotuner**: Optimal convolution algorithms\n",
    "- **TF32 Operations**: Faster matrix multiplications on modern GPUs\n",
    "- **Gradient Clipping**: Improved training stability\n",
    "- **Mixed Precision (FP16)**: 2x throughput with minimal accuracy loss\n",
    "- **OOM Protection**: Graceful handling of out-of-memory situations\n",
    "\n",
    "### Memory Management:\n",
    "- **File-by-file streaming** for RAM efficiency\n",
    "- **Chunk-based processing** to stay within system RAM limits\n",
    "- **Smart VRAM caching** - data cached on GPU when size allows\n",
    "- **Automatic worker configuration** - num_workers=0 when data is on GPU\n",
    "- **Explicit cache clearing** after each chunk\n",
    "- **~4.5GB VRAM target**: ~75% GPU memory utilization for safety\n",
    "\n",
    "### Expected Performance:\n",
    "- **5-10x faster training** compared to original implementation\n",
    "- **No accuracy degradation** - same model architecture\n",
    "- **GPU utilization**: 85-95% (was ~20-30%)\n",
    "- **Reduced CPU bottleneck** through background file loading\n",
    "- **Handles large-scale datasets** without OOM errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e3df92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "GPU Memory: 6.44 GB\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import glob\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200ac1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA optimizations enabled:\n",
      "  ‚úì TF32 for faster matrix operations\n",
      "  ‚úì cuDNN autotuner for optimal convolution\n",
      "  ‚úì Non-deterministic mode for peak performance\n"
     ]
    }
   ],
   "source": [
    "# CUDA Optimization Settings\n",
    "if torch.cuda.is_available():\n",
    "    # Enable TF32 on Ampere GPUs for faster matmul\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # Enable cuDNN autotuner for optimal convolution algorithms\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Disable cuDNN deterministic mode for better performance\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    print(\"CUDA optimizations enabled:\")\n",
    "    print(\"  ‚úì TF32 for faster matrix operations\")\n",
    "    print(\"  ‚úì cuDNN autotuner for optimal convolution\")\n",
    "    print(\"  ‚úì Non-deterministic mode for peak performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a9df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Linux\n",
      "CPU Cores: 12\n",
      "Multiprocessing Start Method: fork\n",
      "‚úÖ Perfect! Linux fork() available - multiprocessing will work efficiently\n"
     ]
    }
   ],
   "source": [
    "# Verify WSL/Linux environment and multiprocessing support\n",
    "import platform\n",
    "import multiprocessing as mp\n",
    "import gc\n",
    "\n",
    "print(f\"Platform: {platform.system()}\")\n",
    "print(f\"CPU Cores: {mp.cpu_count()}\")\n",
    "print(f\"Multiprocessing Start Method: {mp.get_start_method()}\")\n",
    "\n",
    "# Should show:\n",
    "# Platform: Linux\n",
    "# CPU Cores: 8 (or similar)\n",
    "# Multiprocessing Start Method: fork  ‚Üê This is KEY!\n",
    "\n",
    "if platform.system() == 'Linux' and mp.get_start_method() == 'fork':\n",
    "    print(\"‚úÖ Perfect! Linux fork() available - multiprocessing will work efficiently\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: Not using optimal multiprocessing method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f6e897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration (LINUX GPU-OPTIMIZED):\n",
      "  Platform: Linux (WSL)\n",
      "  Batch Size: 20480\n",
      "  Sequence Length: 10\n",
      "  Epochs: 20\n",
      "  Chunk Size: 500,000\n",
      "  Gradient Accumulation Steps: 1\n",
      "  Data Workers: 4 ‚úÖ (Linux fork)\n",
      "  Pinned Memory: True\n",
      "  Prefetch Factor: 4\n",
      "  Persistent Workers: True\n",
      "  VRAM Cache Limit: 4.5GB\n",
      "  File Prefetch: 3 files\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_DIR = '/home/sandeep_ubuntu/DL_projects/c23_models/data'\n",
    "MODEL_SAVE_PATH = 'best_ae_lstm_cnn_optimized.pth'\n",
    "CHECKPOINT_DIR = 'checkpoints_lstm'\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Training Hyperparameters - LINUX GPU OPTIMIZATION\n",
    "BATCH_SIZE = 20480  # Large batch to saturate GPU\n",
    "SEQUENCE_LENGTH = 10  # For LSTM temporal analysis\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "ACCUMULATION_STEPS = 1  # No accumulation needed with large batches\n",
    "\n",
    "# Memory Optimization - LINUX WORKER SETTINGS (fork method)\n",
    "CHUNK_SIZE = 500000  # Larger chunks for fewer disk reads\n",
    "NUM_WORKERS = 4  # ‚úÖ WORKS ON WSL! Use 4-6 for multi-core CPU\n",
    "PIN_MEMORY = True\n",
    "PREFETCH_FACTOR = 4\n",
    "PERSISTENT_WORKERS = True  # ‚úÖ CRITICAL FOR WSL - keeps workers alive\n",
    "\n",
    "# GPU VRAM Optimization\n",
    "MAX_VRAM_CACHE_GB = 4.5  # ~75% of 6GB VRAM for data caching\n",
    "PREFETCH_FILES = 3  # Number of files to prefetch in background\n",
    "\n",
    "# Architecture parameters\n",
    "ENCODER_DIM = 32  # Autoencoder compressed dimension\n",
    "LSTM_HIDDEN = 64\n",
    "LSTM_LAYERS = 2\n",
    "CNN_FILTERS = [64, 128, 256]\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# Mixed Precision\n",
    "USE_AMP = True\n",
    "\n",
    "print(f\"Configuration (LINUX GPU-OPTIMIZED):\")\n",
    "print(f\"  Platform: Linux (WSL)\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Sequence Length: {SEQUENCE_LENGTH}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Chunk Size: {CHUNK_SIZE:,}\")\n",
    "print(f\"  Gradient Accumulation Steps: {ACCUMULATION_STEPS}\")\n",
    "print(f\"  Data Workers: {NUM_WORKERS} ‚úÖ (Linux fork)\")\n",
    "print(f\"  Pinned Memory: {PIN_MEMORY}\")\n",
    "print(f\"  Prefetch Factor: {PREFETCH_FACTOR}\")\n",
    "print(f\"  Persistent Workers: {PERSISTENT_WORKERS}\")\n",
    "print(f\"  VRAM Cache Limit: {MAX_VRAM_CACHE_GB}GB\")\n",
    "print(f\"  File Prefetch: {PREFETCH_FILES} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee8488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 169 CSV files\n",
      "First 5 files: ['part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv', 'part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv', 'part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv', 'part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv', 'part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get all CSV files\n",
    "csv_files = sorted(glob.glob(os.path.join(DATA_DIR, '*.csv')))\n",
    "csv_files = [f for f in csv_files if not f.endswith('.csvZone.Identifier')]\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "print(f\"First 5 files: {[os.path.basename(f) for f in csv_files[:5]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b8fc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GPU OPTIMIZATION STATUS - LINUX/WSL OPTIMIZED\n",
      "======================================================================\n",
      "Total VRAM: 6.44 GB\n",
      "Target VRAM usage: ~4.5 GB (70% utilization)\n",
      "\n",
      "Optimizations Enabled:\n",
      "  ‚úì Large batch size: 20480\n",
      "  ‚úì Multi-worker data loading: 4 workers (Linux fork)\n",
      "  ‚úì Background file prefetching: 3 files\n",
      "  ‚úì VRAM caching for small files\n",
      "  ‚úì Pinned memory for fast CPU‚ÜíGPU transfer\n",
      "  ‚úì Prefetching: 4 batches ahead\n",
      "  ‚úì Persistent workers (no restart overhead)\n",
      "  ‚úì Non-blocking GPU transfers\n",
      "  ‚úì Gradient clipping for stability\n",
      "  ‚úì Mixed precision training (FP16): True\n",
      "  ‚úì Larger chunk size: 500,000 rows\n",
      "  ‚úì OOM protection enabled\n",
      "\n",
      "Key Advantage: Background file loading eliminates CPU bottleneck!\n",
      "Expected speedup: 5-10x faster than original\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GPU Memory and Optimization Check\n",
    "if torch.cuda.is_available():\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"GPU OPTIMIZATION STATUS - LINUX/WSL OPTIMIZED\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total VRAM: {total_memory:.2f} GB\")\n",
    "    print(f\"Target VRAM usage: ~{MAX_VRAM_CACHE_GB} GB ({MAX_VRAM_CACHE_GB/total_memory*100:.0f}% utilization)\")\n",
    "    print(f\"\\nOptimizations Enabled:\")\n",
    "    print(f\"  ‚úì Large batch size: {BATCH_SIZE}\")\n",
    "    print(f\"  ‚úì Multi-worker data loading: {NUM_WORKERS} workers (Linux fork)\")\n",
    "    print(f\"  ‚úì Background file prefetching: {PREFETCH_FILES} files\")\n",
    "    print(f\"  ‚úì VRAM caching for small files\")\n",
    "    print(f\"  ‚úì Pinned memory for fast CPU‚ÜíGPU transfer\")\n",
    "    print(f\"  ‚úì Prefetching: {PREFETCH_FACTOR} batches ahead\")\n",
    "    print(f\"  ‚úì Persistent workers (no restart overhead)\")\n",
    "    print(f\"  ‚úì Non-blocking GPU transfers\")\n",
    "    print(f\"  ‚úì Gradient clipping for stability\")\n",
    "    print(f\"  ‚úì Mixed precision training (FP16): {USE_AMP}\")\n",
    "    print(f\"  ‚úì Larger chunk size: {CHUNK_SIZE:,} rows\")\n",
    "    print(f\"  ‚úì OOM protection enabled\")\n",
    "    print(f\"\\nKey Advantage: Background file loading eliminates CPU bottleneck!\")\n",
    "    print(f\"Expected speedup: 5-10x faster than original\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "else:\n",
    "    print(\"‚ö† No GPU detected - optimizations will have limited effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f56757",
   "metadata": {},
   "source": [
    "## üöÄ GPU Optimization Summary (Linux/WSL)\n",
    "\n",
    "### Key Changes for Maximum Performance:\n",
    "\n",
    "#### 1. **Background File Prefetching** (Eliminates CPU Bottleneck - THE KEY CHANGE!)\n",
    "- ‚úÖ **BackgroundFileLoader class**: Loads files in parallel with GPU training\n",
    "- ‚úÖ **3 files prefetched**: While GPU trains on file N, CPU loads files N+1,2,3\n",
    "- ‚úÖ **ThreadPoolExecutor**: Async I/O without blocking GPU\n",
    "- ‚úÖ **GPU never waits for CPU** - the main bottleneck solved!\n",
    "\n",
    "#### 2. **VRAM Caching** (Maximizes GPU Utilization)\n",
    "- ‚úÖ **CachedSequenceDataset class**: Caches data in GPU VRAM when possible\n",
    "- ‚úÖ **Smart threshold**: Files < 4.5GB are cached entirely on GPU\n",
    "- ‚úÖ **Automatic worker adjustment**: num_workers=0 when data is on GPU\n",
    "- ‚úÖ **Zero transfer overhead** for cached data\n",
    "\n",
    "#### 3. **Data Loading Pipeline** (Linux Advantage)\n",
    "- ‚úÖ **4 parallel workers**: Uses Linux fork() - fast process creation\n",
    "- ‚úÖ **Pinned memory**: 2x faster CPU‚ÜíGPU transfer\n",
    "- ‚úÖ **Prefetch 4 batches**: GPU never waits for data\n",
    "- ‚úÖ **Persistent workers**: No restart overhead between chunks\n",
    "- ‚úÖ **Non-blocking transfers**: CPU and GPU work simultaneously\n",
    "\n",
    "#### 4. **Batch Size Optimization** (Saturates GPU Compute)\n",
    "- ‚úÖ **20480 samples/batch**: Fills GPU compute units\n",
    "- ‚úÖ **No gradient accumulation needed** - single large batch\n",
    "- ‚úÖ **Better parallelization** of matrix operations\n",
    "\n",
    "#### 5. **Memory Efficiency** (Handles Large Datasets)\n",
    "- ‚úÖ **500K row chunks**: Fewer read operations\n",
    "- ‚úÖ **OOM protection**: Gracefully skips batches on memory errors\n",
    "- ‚úÖ **Explicit cache clearing**: After each file/chunk\n",
    "- ‚úÖ **~4.5GB VRAM usage**: 75% of 6GB capacity for safety\n",
    "\n",
    "#### 6. **CUDA Optimizations**\n",
    "- ‚úÖ **TF32 operations**: Faster matmul on Ampere+ GPUs\n",
    "- ‚úÖ **cuDNN autotuner**: Optimal convolution algorithms\n",
    "- ‚úÖ **Mixed precision (FP16)**: 2x throughput\n",
    "\n",
    "### Performance Expectations:\n",
    "- **Training Time**: 5-10x faster per epoch\n",
    "- **GPU Utilization**: 85-95% (was ~20-30%)\n",
    "- **Throughput**: 100K+ samples/second\n",
    "- **Accuracy**: Unchanged (same architecture)\n",
    "\n",
    "### Why This Works:\n",
    "The original implementation had **GPU waiting for CPU to load data** most of the time.\n",
    "With background prefetching:\n",
    "1. While GPU trains on file N, workers load files N+1, N+2, N+3\n",
    "2. When GPU finishes, next file is already ready\n",
    "3. VRAM caching eliminates transfer overhead for smaller files\n",
    "4. Larger batches mean fewer synchronization points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9653ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing dataset structure...\n",
      "\n",
      "Dataset shape (sample): (1000, 47)\n",
      "\n",
      "Columns (47):\n",
      "['flow_duration', 'Header_Length', 'Protocol Type', 'Duration', 'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number', 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue', 'Radius', 'Covariance', 'Variance', 'Weight', 'label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling labels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 45.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique attack types found: 34\n",
      "Labels: ['Backdoor_Malware', 'BenignTraffic', 'BrowserHijacking', 'CommandInjection', 'DDoS-ACK_Fragmentation', 'DDoS-HTTP_Flood', 'DDoS-ICMP_Flood', 'DDoS-ICMP_Fragmentation', 'DDoS-PSHACK_Flood', 'DDoS-RSTFINFlood', 'DDoS-SYN_Flood', 'DDoS-SlowLoris', 'DDoS-SynonymousIP_Flood', 'DDoS-TCP_Flood', 'DDoS-UDP_Flood', 'DDoS-UDP_Fragmentation', 'DNS_Spoofing', 'DictionaryBruteForce', 'DoS-HTTP_Flood', 'DoS-SYN_Flood', 'DoS-TCP_Flood', 'DoS-UDP_Flood', 'MITM-ArpSpoofing', 'Mirai-greeth_flood', 'Mirai-greip_flood', 'Mirai-udpplain', 'Recon-HostDiscovery', 'Recon-OSScan', 'Recon-PingSweep', 'Recon-PortScan', 'SqlInjection', 'Uploading_Attack', 'VulnerabilityScan', 'XSS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze dataset structure and labels\n",
    "print(\"Analyzing dataset structure...\")\n",
    "\n",
    "# Read first file to get feature names\n",
    "df_sample = pd.read_csv(csv_files[0], nrows=1000)\n",
    "print(f\"\\nDataset shape (sample): {df_sample.shape}\")\n",
    "print(f\"\\nColumns ({len(df_sample.columns)}):\")\n",
    "print(df_sample.columns.tolist())\n",
    "\n",
    "# Check label distribution across all files (sampling)\n",
    "all_labels = []\n",
    "for file in tqdm(csv_files[:10], desc=\"Sampling labels\"):  # Sample from first 10 files\n",
    "    df_temp = pd.read_csv(file, usecols=['label'], nrows=10000)\n",
    "    all_labels.extend(df_temp['label'].unique().tolist())\n",
    "\n",
    "unique_labels = sorted(set(all_labels))\n",
    "print(f\"\\nUnique attack types found: {len(unique_labels)}\")\n",
    "print(f\"Labels: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350dc5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPreprocessor class defined\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing utilities\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.feature_columns = None\n",
    "        self.num_features = None\n",
    "        self.num_classes = None\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self, df):\n",
    "        \"\"\"Fit scaler and label encoder on initial data\"\"\"\n",
    "        # Separate features and labels\n",
    "        self.feature_columns = [col for col in df.columns if col != 'label']\n",
    "        \n",
    "        # Handle missing values\n",
    "        X = df[self.feature_columns].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        y = df['label']\n",
    "        \n",
    "        # Fit transformers\n",
    "        self.scaler.fit(X)\n",
    "        self.label_encoder.fit(y)\n",
    "        \n",
    "        self.num_features = len(self.feature_columns)\n",
    "        self.num_classes = len(self.label_encoder.classes_)\n",
    "        self.fitted = True\n",
    "        \n",
    "        print(f\"Preprocessor fitted:\")\n",
    "        print(f\"  Features: {self.num_features}\")\n",
    "        print(f\"  Classes: {self.num_classes}\")\n",
    "        print(f\"  Class names: {self.label_encoder.classes_}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"Transform data\"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Preprocessor must be fitted before transform\")\n",
    "        \n",
    "        # Handle missing values\n",
    "        X = df[self.feature_columns].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        y = df['label']\n",
    "        \n",
    "        # Transform\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        y_encoded = self.label_encoder.transform(y)\n",
    "        \n",
    "        return X_scaled, y_encoded\n",
    "    \n",
    "    def inverse_transform_labels(self, y_encoded):\n",
    "        \"\"\"Convert encoded labels back to original\"\"\"\n",
    "        return self.label_encoder.inverse_transform(y_encoded)\n",
    "\n",
    "print(\"DataPreprocessor class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd8848c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceDataset and CachedSequenceDataset classes defined\n"
     ]
    }
   ],
   "source": [
    "# Custom Dataset for Sequence Data - OPTIMIZED\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X, y, sequence_length=10):\n",
    "        # Keep data on CPU but as contiguous arrays for fast transfer\n",
    "        self.X = torch.FloatTensor(X).contiguous()\n",
    "        self.y = torch.LongTensor(y).contiguous()\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.sequence_length + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Create sequence - returns contiguous tensors for efficient GPU transfer\n",
    "        X_seq = self.X[idx:idx + self.sequence_length]\n",
    "        y_target = self.y[idx + self.sequence_length - 1]\n",
    "        return X_seq, y_target\n",
    "\n",
    "\n",
    "# VRAM-Cached Dataset with Intelligent Batching\n",
    "class CachedSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that caches data in VRAM for optimal GPU utilization.\n",
    "    \n",
    "    IMPORTANT: When data is cached on GPU (self.on_gpu=True), the DataLoader\n",
    "    MUST use num_workers=0 because worker processes cannot access CUDA tensors\n",
    "    from the main process. This is a PyTorch multiprocessing limitation.\n",
    "    \"\"\"\n",
    "    def __init__(self, features, labels, sequence_length, device, max_cache_gb=MAX_VRAM_CACHE_GB):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.device = device\n",
    "        \n",
    "        # Calculate data size\n",
    "        data_size_gb = (features.nbytes + labels.nbytes) / 1e9\n",
    "        \n",
    "        if data_size_gb < max_cache_gb and torch.cuda.is_available():\n",
    "            # Cache in VRAM\n",
    "            self.features = torch.FloatTensor(features).to(device)\n",
    "            self.labels = torch.LongTensor(labels).to(device)\n",
    "            self.on_gpu = True\n",
    "        else:\n",
    "            # Keep in CPU memory (will use pinned memory for transfer)\n",
    "            self.features = torch.FloatTensor(features)\n",
    "            self.labels = torch.LongTensor(labels)\n",
    "            self.on_gpu = False\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.sequence_length + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.features[idx:idx + self.sequence_length]\n",
    "        label = self.labels[idx + self.sequence_length - 1]\n",
    "        return sequence, label\n",
    "\n",
    "print(\"SequenceDataset and CachedSequenceDataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b8e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BackgroundFileLoader defined for pipelined I/O\n"
     ]
    }
   ],
   "source": [
    "# Background File Loader for Pipelined I/O\n",
    "import concurrent.futures\n",
    "from threading import Lock\n",
    "\n",
    "class BackgroundFileLoader:\n",
    "    \"\"\"Loads and preprocesses files in background while GPU trains\"\"\"\n",
    "    def __init__(self, preprocessor, num_workers=2):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=num_workers)\n",
    "        self.cache = {}\n",
    "        self.lock = Lock()\n",
    "    \n",
    "    def load_file(self, file_path):\n",
    "        \"\"\"Load and preprocess a single file in chunks\"\"\"\n",
    "        try:\n",
    "            chunks = []\n",
    "            chunk_iterator = pd.read_csv(file_path, chunksize=CHUNK_SIZE)\n",
    "            \n",
    "            for chunk_df in chunk_iterator:\n",
    "                if 'label' not in chunk_df.columns:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    X_scaled, y_encoded = self.preprocessor.transform(chunk_df)\n",
    "                    chunks.append((X_scaled, y_encoded))\n",
    "                except Exception as e:\n",
    "                    # Skip chunks with unseen labels\n",
    "                    continue\n",
    "            \n",
    "            return file_path, chunks\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return file_path, None\n",
    "    \n",
    "    def prefetch_files(self, file_paths):\n",
    "        \"\"\"Start prefetching files in background\"\"\"\n",
    "        futures = {self.executor.submit(self.load_file, fp): fp for fp in file_paths}\n",
    "        return futures\n",
    "    \n",
    "    def get_file_data(self, future):\n",
    "        \"\"\"Get loaded file data from future\"\"\"\n",
    "        try:\n",
    "            return future.result(timeout=300)  # 5 min timeout\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving file: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    def shutdown(self):\n",
    "        self.executor.shutdown(wait=False)\n",
    "\n",
    "print(\"BackgroundFileLoader defined for pipelined I/O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de04f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE_LSTM_CNN model architecture defined\n"
     ]
    }
   ],
   "source": [
    "# AE-LSTM-CNN Hybrid Architecture\n",
    "class AE_LSTM_CNN(nn.Module):\n",
    "    def __init__(self, input_dim, encoder_dim, lstm_hidden, lstm_layers, \n",
    "                 cnn_filters, num_classes, dropout=0.3):\n",
    "        super(AE_LSTM_CNN, self).__init__()\n",
    "        \n",
    "        # Autoencoder for dimensionality reduction\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, encoder_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoder_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "        \n",
    "        # LSTM for temporal patterns\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=encoder_dim,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # CNN for local feature extraction\n",
    "        self.conv1d_layers = nn.ModuleList([\n",
    "            nn.Conv1d(lstm_hidden * 2, cnn_filters[0], kernel_size=3, padding=1),\n",
    "            nn.Conv1d(cnn_filters[0], cnn_filters[1], kernel_size=3, padding=1),\n",
    "            nn.Conv1d(cnn_filters[1], cnn_filters[2], kernel_size=3, padding=1)\n",
    "        ])\n",
    "        \n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(cnn_filters[0]),\n",
    "            nn.BatchNorm1d(cnn_filters[1]),\n",
    "            nn.BatchNorm1d(cnn_filters[2])\n",
    "        ])\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc1 = nn.Linear(cnn_filters[2], 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x, return_reconstruction=False):\n",
    "        batch_size, seq_len, features = x.shape\n",
    "        \n",
    "        # Reshape for autoencoder\n",
    "        x_flat = x.view(-1, features)\n",
    "        \n",
    "        # Encode\n",
    "        encoded = self.encoder(x_flat)\n",
    "        \n",
    "        # Decode (for reconstruction loss)\n",
    "        if return_reconstruction:\n",
    "            decoded = self.decoder(encoded)\n",
    "            reconstruction = decoded.view(batch_size, seq_len, features)\n",
    "        else:\n",
    "            reconstruction = None\n",
    "        \n",
    "        # Reshape for LSTM\n",
    "        encoded = encoded.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, (hidden, cell) = self.lstm(encoded)\n",
    "        \n",
    "        # Transpose for CNN (batch, channels, sequence)\n",
    "        cnn_input = lstm_out.transpose(1, 2)\n",
    "        \n",
    "        # CNN processing\n",
    "        x_cnn = cnn_input\n",
    "        for conv, bn in zip(self.conv1d_layers, self.batch_norms):\n",
    "            x_cnn = conv(x_cnn)\n",
    "            x_cnn = bn(x_cnn)\n",
    "            x_cnn = F.relu(x_cnn)\n",
    "            if x_cnn.shape[2] > 2:  # Only pool if sequence length allows\n",
    "                x_cnn = self.pool(x_cnn)\n",
    "            x_cnn = self.dropout(x_cnn)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x_cnn = F.adaptive_avg_pool1d(x_cnn, 1).squeeze(-1)\n",
    "        \n",
    "        # Classification\n",
    "        x_out = F.relu(self.fc1(x_cnn))\n",
    "        x_out = self.dropout(x_out)\n",
    "        x_out = F.relu(self.fc2(x_out))\n",
    "        x_out = self.dropout(x_out)\n",
    "        x_out = self.fc3(x_out)\n",
    "        \n",
    "        if return_reconstruction:\n",
    "            return x_out, reconstruction\n",
    "        return x_out\n",
    "\n",
    "print(\"AE_LSTM_CNN model architecture defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "324f1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing preprocessor...\n",
      "Preprocessor fitted:\n",
      "  Features: 46\n",
      "  Classes: 31\n",
      "  Class names: ['Backdoor_Malware' 'BenignTraffic' 'BrowserHijacking' 'CommandInjection'\n",
      " 'DDoS-ACK_Fragmentation' 'DDoS-HTTP_Flood' 'DDoS-ICMP_Flood'\n",
      " 'DDoS-ICMP_Fragmentation' 'DDoS-PSHACK_Flood' 'DDoS-RSTFINFlood'\n",
      " 'DDoS-SYN_Flood' 'DDoS-SlowLoris' 'DDoS-SynonymousIP_Flood'\n",
      " 'DDoS-TCP_Flood' 'DDoS-UDP_Flood' 'DDoS-UDP_Fragmentation' 'DNS_Spoofing'\n",
      " 'DictionaryBruteForce' 'DoS-HTTP_Flood' 'DoS-SYN_Flood' 'DoS-TCP_Flood'\n",
      " 'DoS-UDP_Flood' 'MITM-ArpSpoofing' 'Mirai-greeth_flood'\n",
      " 'Mirai-greip_flood' 'Mirai-udpplain' 'Recon-HostDiscovery' 'Recon-OSScan'\n",
      " 'Recon-PortScan' 'VulnerabilityScan' 'XSS']\n",
      "\n",
      "Dataset configuration:\n",
      "  Number of features: 46\n",
      "  Number of classes: 31\n"
     ]
    }
   ],
   "source": [
    "# Initialize preprocessor with sample data\n",
    "print(\"Initializing preprocessor...\")\n",
    "df_init = pd.read_csv(csv_files[0], nrows=10000)\n",
    "preprocessor = DataPreprocessor()\n",
    "preprocessor.fit(df_init)\n",
    "\n",
    "NUM_FEATURES = preprocessor.num_features\n",
    "NUM_CLASSES = preprocessor.num_classes\n",
    "\n",
    "print(f\"\\nDataset configuration:\")\n",
    "print(f\"  Number of features: {NUM_FEATURES}\")\n",
    "print(f\"  Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed4885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing preprocessor with complete label set...\n",
      "Sampling from all CSV files to get complete label set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 169/169 [00:03<00:00, 50.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 34 unique labels across all files\n",
      "Labels: ['Backdoor_Malware', 'BenignTraffic', 'BrowserHijacking', 'CommandInjection', 'DDoS-ACK_Fragmentation', 'DDoS-HTTP_Flood', 'DDoS-ICMP_Flood', 'DDoS-ICMP_Fragmentation', 'DDoS-PSHACK_Flood', 'DDoS-RSTFINFlood', 'DDoS-SYN_Flood', 'DDoS-SlowLoris', 'DDoS-SynonymousIP_Flood', 'DDoS-TCP_Flood', 'DDoS-UDP_Flood', 'DDoS-UDP_Fragmentation', 'DNS_Spoofing', 'DictionaryBruteForce', 'DoS-HTTP_Flood', 'DoS-SYN_Flood', 'DoS-TCP_Flood', 'DoS-UDP_Flood', 'MITM-ArpSpoofing', 'Mirai-greeth_flood', 'Mirai-greip_flood', 'Mirai-udpplain', 'Recon-HostDiscovery', 'Recon-OSScan', 'Recon-PingSweep', 'Recon-PortScan', 'SqlInjection', 'Uploading_Attack', 'VulnerabilityScan', 'XSS']\n",
      "\n",
      "Preprocessor re-fitted with complete data:\n",
      "  Features: 46\n",
      "  Classes: 34\n",
      "  Class names: ['Backdoor_Malware' 'BenignTraffic' 'BrowserHijacking' 'CommandInjection'\n",
      " 'DDoS-ACK_Fragmentation' 'DDoS-HTTP_Flood' 'DDoS-ICMP_Flood'\n",
      " 'DDoS-ICMP_Fragmentation' 'DDoS-PSHACK_Flood' 'DDoS-RSTFINFlood'\n",
      " 'DDoS-SYN_Flood' 'DDoS-SlowLoris' 'DDoS-SynonymousIP_Flood'\n",
      " 'DDoS-TCP_Flood' 'DDoS-UDP_Flood' 'DDoS-UDP_Fragmentation' 'DNS_Spoofing'\n",
      " 'DictionaryBruteForce' 'DoS-HTTP_Flood' 'DoS-SYN_Flood' 'DoS-TCP_Flood'\n",
      " 'DoS-UDP_Flood' 'MITM-ArpSpoofing' 'Mirai-greeth_flood'\n",
      " 'Mirai-greip_flood' 'Mirai-udpplain' 'Recon-HostDiscovery' 'Recon-OSScan'\n",
      " 'Recon-PingSweep' 'Recon-PortScan' 'SqlInjection' 'Uploading_Attack'\n",
      " 'VulnerabilityScan' 'XSS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize preprocessor with ALL labels from dataset\n",
    "print(\"Re-initializing preprocessor with complete label set...\")\n",
    "\n",
    "# Collect labels from all files to ensure complete coverage\n",
    "all_unique_labels = set()\n",
    "sample_df_list = []\n",
    "\n",
    "print(\"Sampling from all CSV files to get complete label set...\")\n",
    "for file in tqdm(csv_files, desc=\"Scanning files\"):\n",
    "    try:\n",
    "        # Read small sample from each file to get labels\n",
    "        df_temp = pd.read_csv(file, nrows=5000)\n",
    "        all_unique_labels.update(df_temp['label'].unique())\n",
    "        \n",
    "        # Collect some samples for fitting scaler\n",
    "        if len(sample_df_list) < 5:  # Collect from first 5 files\n",
    "            sample_df_list.append(df_temp)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {os.path.basename(file)}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nFound {len(all_unique_labels)} unique labels across all files\")\n",
    "print(f\"Labels: {sorted(all_unique_labels)}\")\n",
    "\n",
    "# Combine samples for scaler fitting\n",
    "df_combined = pd.concat(sample_df_list, ignore_index=True)\n",
    "\n",
    "# Create a complete label set for the encoder\n",
    "complete_labels = sorted(list(all_unique_labels))\n",
    "\n",
    "# Re-initialize and fit preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "preprocessor.feature_columns = [col for col in df_combined.columns if col != 'label']\n",
    "\n",
    "# Fit scaler\n",
    "X_combined = df_combined[preprocessor.feature_columns].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "preprocessor.scaler.fit(X_combined)\n",
    "\n",
    "# Fit label encoder with complete label set\n",
    "preprocessor.label_encoder.fit(complete_labels)\n",
    "\n",
    "preprocessor.num_features = len(preprocessor.feature_columns)\n",
    "preprocessor.num_classes = len(preprocessor.label_encoder.classes_)\n",
    "preprocessor.fitted = True\n",
    "\n",
    "NUM_FEATURES = preprocessor.num_features\n",
    "NUM_CLASSES = preprocessor.num_classes\n",
    "\n",
    "print(f\"\\nPreprocessor re-fitted with complete data:\")\n",
    "print(f\"  Features: {NUM_FEATURES}\")\n",
    "print(f\"  Classes: {NUM_CLASSES}\")\n",
    "print(f\"  Class names: {preprocessor.label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cecac043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing model with correct number of classes...\n",
      "\n",
      "Model re-initialized:\n",
      "  Total parameters: 434,096\n",
      "  Trainable parameters: 434,096\n",
      "  Number of classes: 34\n",
      "\n",
      "Model re-initialized:\n",
      "  Total parameters: 434,096\n",
      "  Trainable parameters: 434,096\n",
      "  Number of classes: 34\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize model with correct number of classes\n",
    "print(\"Re-initializing model with correct number of classes...\")\n",
    "\n",
    "model = AE_LSTM_CNN(\n",
    "    input_dim=NUM_FEATURES,\n",
    "    encoder_dim=ENCODER_DIM,\n",
    "    lstm_hidden=LSTM_HIDDEN,\n",
    "    lstm_layers=LSTM_LAYERS,\n",
    "    cnn_filters=CNN_FILTERS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "# Re-initialize optimizer and scaler with new API\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2\n",
    ")\n",
    "scaler = torch.amp.GradScaler('cuda') if USE_AMP and torch.cuda.is_available() else None\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel re-initialized:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59befd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model initialized:\n",
      "  Total parameters: 434,096\n",
      "  Trainable parameters: 434,096\n",
      "\n",
      "Model architecture:\n",
      "AE_LSTM_CNN(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=46, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=46, bias=True)\n",
      "  )\n",
      "  (lstm): LSTM(32, 64, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (conv1d_layers): ModuleList(\n",
      "    (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  )\n",
      "  (batch_norms): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=34, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = AE_LSTM_CNN(\n",
    "    input_dim=NUM_FEATURES,\n",
    "    encoder_dim=ENCODER_DIM,\n",
    "    lstm_hidden=LSTM_HIDDEN,\n",
    "    lstm_layers=LSTM_LAYERS,\n",
    "    cnn_filters=CNN_FILTERS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel initialized:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e41568c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer and loss functions initialized\n",
      "Using mixed precision: True\n"
     ]
    }
   ],
   "source": [
    "# Loss functions and optimizer\n",
    "criterion_classification = nn.CrossEntropyLoss()\n",
    "criterion_reconstruction = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2\n",
    ")\n",
    "\n",
    "# Mixed precision training with updated API\n",
    "scaler = torch.amp.GradScaler('cuda') if USE_AMP and torch.cuda.is_available() else None\n",
    "\n",
    "print(\"Optimizer and loss functions initialized\")\n",
    "print(f\"Using mixed precision: {scaler is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7721f19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU-optimized training function with VRAM caching and OOM protection defined\n"
     ]
    }
   ],
   "source": [
    "# GPU-OPTIMIZED Training with Smart Chunk Caching and Prefetching\n",
    "def train_on_prefetched_file(model, file_data, device, accumulation_steps=1):\n",
    "    \"\"\"\n",
    "    Train on prefetched file data with smart chunk-level VRAM caching.\n",
    "    Process chunks individually if file is too large, cache if small enough.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    file_path, chunks = file_data\n",
    "    \n",
    "    if chunks is None or len(chunks) == 0:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    # Calculate total file size\n",
    "    total_size = sum(chunk[0].nbytes + chunk[1].nbytes for chunk in chunks) / 1e9\n",
    "    \n",
    "    # Strategy 1: If entire file fits in cache, load once\n",
    "    if total_size < MAX_VRAM_CACHE_GB * 0.8:  # Use 80% threshold for safety\n",
    "        all_X = np.vstack([chunk[0] for chunk in chunks])\n",
    "        all_y = np.concatenate([chunk[1] for chunk in chunks])\n",
    "        \n",
    "        dataset = CachedSequenceDataset(all_X, all_y, SEQUENCE_LENGTH, device)\n",
    "        \n",
    "        if len(dataset) == 0:\n",
    "            return 0, 0, 0\n",
    "        \n",
    "        # CRITICAL: num_workers must be 0 when data is cached on GPU\n",
    "        # Worker processes cannot access CUDA tensors from main process\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=0 if dataset.on_gpu else NUM_WORKERS,\n",
    "            pin_memory=False if dataset.on_gpu else PIN_MEMORY,\n",
    "            prefetch_factor=None if dataset.on_gpu else PREFETCH_FACTOR,\n",
    "            persistent_workers=False,  # Must be False when num_workers might be 0\n",
    "            drop_last=False\n",
    "        )\n",
    "        \n",
    "        # Train on entire cached file\n",
    "        loss, acc, samples = _train_on_dataloader(\n",
    "            model, dataloader, device, dataset.on_gpu, \n",
    "            accumulation_steps, batch_count\n",
    "        )\n",
    "        \n",
    "        del dataset, dataloader, all_X, all_y\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return loss, acc, samples\n",
    "    \n",
    "    # Strategy 2: Process chunks individually (file too large)\n",
    "    else:\n",
    "        for chunk_idx, (X_chunk, y_chunk) in enumerate(chunks):\n",
    "            # Create dataset for this chunk\n",
    "            dataset = CachedSequenceDataset(X_chunk, y_chunk, SEQUENCE_LENGTH, device)\n",
    "            \n",
    "            if len(dataset) == 0:\n",
    "                continue\n",
    "            \n",
    "            # CRITICAL: num_workers must be 0 when data is cached on GPU\n",
    "            dataloader = DataLoader(\n",
    "                dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=0 if dataset.on_gpu else NUM_WORKERS,\n",
    "                pin_memory=False if dataset.on_gpu else PIN_MEMORY,\n",
    "                prefetch_factor=None if dataset.on_gpu else PREFETCH_FACTOR,\n",
    "                persistent_workers=False,\n",
    "                drop_last=False\n",
    "            )\n",
    "            \n",
    "            # Train on chunk\n",
    "            chunk_loss, chunk_acc, chunk_samples = _train_on_dataloader(\n",
    "                model, dataloader, device, dataset.on_gpu,\n",
    "                accumulation_steps, batch_count\n",
    "            )\n",
    "            \n",
    "            total_loss += chunk_loss * chunk_samples\n",
    "            total_correct += (chunk_acc / 100.0) * chunk_samples\n",
    "            total_samples += chunk_samples\n",
    "            batch_count += len(dataloader)\n",
    "            \n",
    "            # Clean up chunk\n",
    "            del dataset, dataloader\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        if total_samples == 0:\n",
    "            return 0, 0, 0\n",
    "        \n",
    "        return total_loss / total_samples, (total_correct / total_samples) * 100, total_samples\n",
    "\n",
    "\n",
    "def _train_on_dataloader(model, dataloader, device, data_on_gpu, accumulation_steps, batch_count):\n",
    "    \"\"\"Helper function to train on a single dataloader with OOM protection\"\"\"\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    try:\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(dataloader):\n",
    "            try:\n",
    "                # Skip transfer if already on GPU\n",
    "                if not data_on_gpu:\n",
    "                    X_batch = X_batch.to(device, non_blocking=True)\n",
    "                    y_batch = y_batch.to(device, non_blocking=True)\n",
    "                \n",
    "                # Forward pass with mixed precision\n",
    "                if scaler is not None:\n",
    "                    with autocast(device_type='cuda'):\n",
    "                        outputs, reconstruction = model(X_batch, return_reconstruction=True)\n",
    "                        \n",
    "                        # Combined loss\n",
    "                        loss_cls = criterion_classification(outputs, y_batch)\n",
    "                        loss_rec = criterion_reconstruction(reconstruction, X_batch)\n",
    "                        loss = loss_cls + 0.1 * loss_rec\n",
    "                        \n",
    "                        if accumulation_steps > 1:\n",
    "                            loss = loss / accumulation_steps\n",
    "                    \n",
    "                    # Backward pass\n",
    "                    scaler.scale(loss).backward()\n",
    "                    \n",
    "                    batch_count += 1\n",
    "                    if batch_count % accumulation_steps == 0:\n",
    "                        scaler.unscale_(optimizer)\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                else:\n",
    "                    outputs, reconstruction = model(X_batch, return_reconstruction=True)\n",
    "                    \n",
    "                    loss_cls = criterion_classification(outputs, y_batch)\n",
    "                    loss_rec = criterion_reconstruction(reconstruction, X_batch)\n",
    "                    loss = loss_cls + 0.1 * loss_rec\n",
    "                    \n",
    "                    if accumulation_steps > 1:\n",
    "                        loss = loss / accumulation_steps\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    \n",
    "                    batch_count += 1\n",
    "                    if batch_count % accumulation_steps == 0:\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                \n",
    "                # Statistics\n",
    "                with torch.no_grad():\n",
    "                    actual_loss = loss.item() * accumulation_steps if accumulation_steps > 1 else loss.item()\n",
    "                    total_loss += actual_loss * y_batch.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_correct += (predicted == y_batch).sum().item()\n",
    "                    total_samples += y_batch.size(0)\n",
    "                    \n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    print(f\"‚ö†Ô∏è OOM on batch {batch_idx}, skipping...\")\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    optimizer.zero_grad()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in dataloader: {e}\")\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if total_samples == 0:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    return avg_loss, accuracy, total_samples\n",
    "\n",
    "print(\"GPU-optimized training function with VRAM caching and OOM protection defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daffdf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU-optimized validation function with VRAM caching defined\n"
     ]
    }
   ],
   "source": [
    "# GPU-OPTIMIZED Validation function with VRAM caching\n",
    "def validate_on_file(model, file_path, preprocessor):\n",
    "    \"\"\"\n",
    "    Validate on a single file using chunk-based loading with VRAM caching.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        chunk_iterator = pd.read_csv(file_path, chunksize=CHUNK_SIZE)\n",
    "        \n",
    "        for chunk_df in chunk_iterator:\n",
    "            try:\n",
    "                X_scaled, y_encoded = preprocessor.transform(chunk_df)\n",
    "                \n",
    "                # Use cached dataset for validation too\n",
    "                dataset = CachedSequenceDataset(X_scaled, y_encoded, SEQUENCE_LENGTH, device)\n",
    "                if len(dataset) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # CRITICAL: num_workers must be 0 when data is cached on GPU\n",
    "                dataloader = DataLoader(\n",
    "                    dataset, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    shuffle=False, \n",
    "                    num_workers=0 if dataset.on_gpu else NUM_WORKERS,\n",
    "                    pin_memory=False if dataset.on_gpu else PIN_MEMORY,\n",
    "                    prefetch_factor=None if dataset.on_gpu else PREFETCH_FACTOR,\n",
    "                    persistent_workers=False,\n",
    "                    drop_last=False\n",
    "                )\n",
    "                \n",
    "                for X_batch, y_batch in dataloader:\n",
    "                    # Skip transfer if already on GPU\n",
    "                    if not dataset.on_gpu:\n",
    "                        X_batch = X_batch.to(device, non_blocking=True)\n",
    "                        y_batch = y_batch.to(device, non_blocking=True)\n",
    "                    \n",
    "                    if scaler is not None:\n",
    "                        with autocast(device_type='cuda'):\n",
    "                            outputs = model(X_batch, return_reconstruction=False)\n",
    "                            loss = criterion_classification(outputs, y_batch)\n",
    "                    else:\n",
    "                        outputs = model(X_batch, return_reconstruction=False)\n",
    "                        loss = criterion_classification(outputs, y_batch)\n",
    "                    \n",
    "                    total_loss += loss.item() * y_batch.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_correct += (predicted == y_batch).sum().item()\n",
    "                    total_samples += y_batch.size(0)\n",
    "                    \n",
    "                    # Move to CPU for accumulation\n",
    "                    all_predictions.extend(predicted.cpu().numpy())\n",
    "                    all_labels.extend(y_batch.cpu().numpy())\n",
    "                \n",
    "                del X_scaled, y_encoded, dataset, dataloader\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error during validation: {e}\")\n",
    "                continue\n",
    "    \n",
    "    avg_loss = total_loss / max(total_samples, 1)\n",
    "    accuracy = 100.0 * total_correct / max(total_samples, 1)\n",
    "    \n",
    "    # Calculate weighted F1 score\n",
    "    if len(all_predictions) > 0 and len(all_labels) > 0:\n",
    "        weighted_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    else:\n",
    "        weighted_f1 = 0.0\n",
    "    \n",
    "    return avg_loss, accuracy, total_samples, all_predictions, all_labels, weighted_f1\n",
    "\n",
    "print(\"GPU-optimized validation function with VRAM caching and F1 score defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc8348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files: 135\n",
      "Validation files: 34\n"
     ]
    }
   ],
   "source": [
    "# Split files into train, validation, and test sets\n",
    "from sklearn.model_selection import train_test_split as split_files\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "train_val_files, test_files = split_files(csv_files, test_size=0.15, random_state=42)\n",
    "\n",
    "# Second split: 80% train, 20% val (of the remaining)\n",
    "train_files, val_files = split_files(train_val_files, test_size=0.18, random_state=42)\n",
    "\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Validation files: {len(val_files)}\")\n",
    "print(f\"Test files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d3daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Starting PEAK GPU-Optimized Training - AE-LSTM-CNN\n",
      "Optimizations: VRAM Caching + Background Prefetch + Large Batches\n",
      "Log file: training_log_lstm_20251130_225410.txt\n",
      "Batch=20480, VRAM=4.5GB, Prefetch=3\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Epoch 1/20\n",
      "======================================================================\n",
      "\n",
      "Training on 135 files (with 3-file prefetch)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   0%|          | 0/135 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   7%|‚ñã         | 10/135 [00:44<09:17,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 10/135 - Loss: 1.5791, Acc: 46.32% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  15%|‚ñà‚ñç        | 20/135 [01:27<07:19,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 20/135 - Loss: 1.0835, Acc: 60.81% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  22%|‚ñà‚ñà‚ñè       | 30/135 [02:08<07:13,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 30/135 - Loss: 0.8954, Acc: 66.48% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  30%|‚ñà‚ñà‚ñâ       | 40/135 [02:49<06:34,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 40/135 - Loss: 0.7919, Acc: 69.65% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 50/135 [03:28<05:23,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 50/135 - Loss: 0.7323, Acc: 71.48% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 60/135 [04:14<05:03,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 60/135 - Loss: 0.6784, Acc: 73.15% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 70/135 [04:55<04:17,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 70/135 - Loss: 0.6408, Acc: 74.33% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 80/135 [05:32<03:34,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 80/135 - Loss: 0.6152, Acc: 75.14% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 90/135 [06:09<03:12,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 90/135 - Loss: 0.5938, Acc: 75.86% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 100/135 [06:47<02:14,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 100/135 - Loss: 0.5753, Acc: 76.51% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 110/135 [07:27<01:35,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 110/135 - Loss: 0.5581, Acc: 77.12% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 120/135 [08:09<01:15,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 120/135 - Loss: 0.5415, Acc: 77.73% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 130/135 [08:44<00:17,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Files 130/135 - Loss: 0.5289, Acc: 78.20% | GPU: 0.02GB (0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 135/135 [09:00<00:00,  4.00s/it]\n",
      "Epoch 1 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 135/135 [09:00<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating on 34 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation:  18%|‚ñà‚ñä        | 6/34 [00:27<02:09,  4.61s/it]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    125\u001b[39m log_print(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mValidating on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m files...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m val_file \u001b[38;5;129;01min\u001b[39;00m tqdm(val_files, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Validation\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     loss, acc_pct, samples, _, _ = \u001b[43mvalidate_on_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     epoch_val_loss += loss * samples\n\u001b[32m    131\u001b[39m     epoch_val_correct += (acc_pct / \u001b[32m100.0\u001b[39m) * samples\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mvalidate_on_file\u001b[39m\u001b[34m(model, file_path, preprocessor)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk_df \u001b[38;5;129;01min\u001b[39;00m chunk_iterator:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         X_scaled, y_encoded = \u001b[43mpreprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# Use cached dataset for validation too\u001b[39;00m\n\u001b[32m     22\u001b[39m         dataset = CachedSequenceDataset(X_scaled, y_encoded, SEQUENCE_LENGTH, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mDataPreprocessor.transform\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPreprocessor must be fitted before transform\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Handle missing values\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m X = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnan\u001b[49m\u001b[43m)\u001b[49m.fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     42\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Transform\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programs/linux_gpu_env/lib/python3.12/site-packages/pandas/core/generic.py:8125\u001b[39m, in \u001b[36mNDFrame.replace\u001b[39m\u001b[34m(self, to_replace, value, inplace, limit, regex, method)\u001b[39m\n\u001b[32m   8120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(to_replace) != \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[32m   8121\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   8122\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReplacement lists must match in length. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   8123\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_replace)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   8124\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m8125\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   8126\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto_replace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   8127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdest_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   8128\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   8129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   8130\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   8132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m to_replace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   8133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[32m   8134\u001b[39m         is_re_compilable(regex)\n\u001b[32m   8135\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m is_list_like(regex)\n\u001b[32m   8136\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m is_dict_like(regex)\n\u001b[32m   8137\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programs/linux_gpu_env/lib/python3.12/site-packages/pandas/core/internals/base.py:278\u001b[39m, in \u001b[36mDataManager.replace_list\u001b[39m\u001b[34m(self, src_list, dest_list, inplace, regex)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"do a list replace\"\"\"\u001b[39;00m\n\u001b[32m    276\u001b[39m inplace = validate_bool_kwarg(inplace, \u001b[33m\"\u001b[39m\u001b[33minplace\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m bm = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreplace_list\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdest_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdest_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m bm._consolidate_inplace()\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programs/linux_gpu_env/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programs/linux_gpu_env/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1178\u001b[39m, in \u001b[36mBlock.replace_list\u001b[39m\u001b[34m(self, src_list, dest_list, inplace, regex, using_cow, already_warned)\u001b[39m\n\u001b[32m   1173\u001b[39m     m = mib[blk_num : blk_num + \u001b[32m1\u001b[39m]\n\u001b[32m   1175\u001b[39m \u001b[38;5;66;03m# error: Argument \"mask\" to \"_replace_coerce\" of \"Block\" has\u001b[39;00m\n\u001b[32m   1176\u001b[39m \u001b[38;5;66;03m# incompatible type \"Union[ExtensionArray, ndarray[Any, Any], bool]\";\u001b[39;00m\n\u001b[32m   1177\u001b[39m \u001b[38;5;66;03m# expected \"ndarray[Any, dtype[bool_]]\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1178\u001b[39m result = \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_replace_coerce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mto_replace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m i != src_len:\n\u001b[32m   1189\u001b[39m     \u001b[38;5;66;03m# This is ugly, but we have to get rid of intermediate refs\u001b[39;00m\n\u001b[32m   1190\u001b[39m     \u001b[38;5;66;03m# that did not go out of scope yet, otherwise we will trigger\u001b[39;00m\n\u001b[32m   1191\u001b[39m     \u001b[38;5;66;03m# many unnecessary copies\u001b[39;00m\n\u001b[32m   1192\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programs/linux_gpu_env/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1288\u001b[39m, in \u001b[36mBlock._replace_coerce\u001b[39m\u001b[34m(self, to_replace, value, mask, inplace, regex, using_cow, convert_string)\u001b[39m\n\u001b[32m   1286\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.copy()]\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mto_replace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto_replace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1291\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1293\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programs/linux_gpu_env/lib/python3.12/site-packages/pandas/core/internals/blocks.py:902\u001b[39m, in \u001b[36mBlock.replace\u001b[39m\u001b[34m(self, to_replace, value, inplace, mask, using_cow, already_warned, convert_string)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    904\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_hold_element(value) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.dtype == \u001b[33m\"\u001b[39m\u001b[33mstring\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_re(value)):\n\u001b[32m    905\u001b[39m     \u001b[38;5;66;03m# TODO(CoW): Maybe split here as well into columns where mask has True\u001b[39;00m\n\u001b[32m    906\u001b[39m     \u001b[38;5;66;03m# and rest?\u001b[39;00m\n\u001b[32m    907\u001b[39m     blk = \u001b[38;5;28mself\u001b[39m._maybe_copy(using_cow, inplace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programs/linux_gpu_env/lib/python3.12/site-packages/pandas/core/internals/blocks.py:822\u001b[39m, in \u001b[36mBlock.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    820\u001b[39m refs: BlockValuesRefs | \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     values = \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    823\u001b[39m     refs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# GPU-OPTIMIZED Training loop with Background File Prefetching\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Create log file to save training output\n",
    "log_filename = f\"training_log_lstm_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "log_file = open(log_filename, 'w', encoding='utf-8')\n",
    "\n",
    "# Custom print function that writes to both console and file\n",
    "def log_print(message):\n",
    "    print(message)\n",
    "    log_file.write(str(message) + '\\n')\n",
    "    log_file.flush()\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_f1': [],  # Added weighted F1 score tracking\n",
    "    'epoch_time': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "log_print(\"\\n\" + \"=\"*70)\n",
    "log_print(\"Starting PEAK GPU-Optimized Training - AE-LSTM-CNN\")\n",
    "log_print(f\"Optimizations: VRAM Caching + Background Prefetch + Large Batches\")\n",
    "log_print(f\"Log file: {log_filename}\")\n",
    "log_print(f\"Batch={BATCH_SIZE}, VRAM={MAX_VRAM_CACHE_GB}GB, Prefetch={PREFETCH_FILES}\")\n",
    "log_print(\"=\"*70)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    log_print(f\"\\n{'='*70}\")\n",
    "    log_print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    log_print(f\"{'='*70}\")\n",
    "    \n",
    "    # ===== TRAINING PHASE - FILE BY FILE WITH PREFETCHING =====\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_correct = 0\n",
    "    epoch_train_samples = 0\n",
    "\n",
    "    train_start_time = time.time()\n",
    "    log_print(f\"\\nTraining on {len(train_files)} files (with {PREFETCH_FILES}-file prefetch)...\")\n",
    "\n",
    "    # Initialize background loader\n",
    "    bg_loader = BackgroundFileLoader(preprocessor, num_workers=PREFETCH_FILES)\n",
    "\n",
    "    # Start prefetching first batch of files\n",
    "    prefetch_batch_size = PREFETCH_FILES\n",
    "    file_idx = 0\n",
    "    futures = {}\n",
    "\n",
    "    # Prefetch first batch\n",
    "    batch_files = train_files[file_idx:min(file_idx + prefetch_batch_size, len(train_files))]\n",
    "    futures = bg_loader.prefetch_files(batch_files)\n",
    "\n",
    "    pbar = tqdm(total=len(train_files), desc=f\"Epoch {epoch+1} Training\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    while file_idx < len(train_files):\n",
    "        # Get next prefetched file\n",
    "        if futures:\n",
    "            future = list(futures.keys())[0]\n",
    "            file_data = bg_loader.get_file_data(future)\n",
    "            del futures[future]\n",
    "            \n",
    "            # Start prefetching next file\n",
    "            next_idx = file_idx + prefetch_batch_size\n",
    "            if next_idx < len(train_files):\n",
    "                next_file = train_files[next_idx]\n",
    "                new_future = bg_loader.executor.submit(bg_loader.load_file, next_file)\n",
    "                futures[new_future] = next_file\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # Train on prefetched data\n",
    "        loss, acc_pct, samples = train_on_prefetched_file(model, file_data, device, ACCUMULATION_STEPS)\n",
    "        \n",
    "        # Accumulate weighted metrics\n",
    "        epoch_train_loss += loss * samples\n",
    "        epoch_train_correct += (acc_pct / 100.0) * samples\n",
    "        epoch_train_samples += samples\n",
    "        \n",
    "        pbar.update(1)\n",
    "        file_idx += 1\n",
    "        \n",
    "        # Periodic progress update\n",
    "        if file_idx % 10 == 0 and epoch_train_samples > 0:\n",
    "            avg_loss = epoch_train_loss / epoch_train_samples\n",
    "            avg_acc = (epoch_train_correct / epoch_train_samples) * 100\n",
    "            \n",
    "            gpu_mem_str = \"\"\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_mem = torch.cuda.memory_allocated(0) / 1e9\n",
    "                gpu_util = (gpu_mem / 6.0) * 100\n",
    "                gpu_mem_str = f\" | GPU: {gpu_mem:.2f}GB ({gpu_util:.0f}%)\"\n",
    "            \n",
    "            log_print(f\"  Files {file_idx}/{len(train_files)} - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%{gpu_mem_str}\")\n",
    "\n",
    "    pbar.close()\n",
    "    bg_loader.shutdown()\n",
    "\n",
    "    train_time = time.time() - train_start_time\n",
    "\n",
    "    # Calculate epoch averages\n",
    "    if epoch_train_samples > 0:\n",
    "        avg_train_loss = epoch_train_loss / epoch_train_samples\n",
    "        avg_train_acc = (epoch_train_correct / epoch_train_samples) * 100\n",
    "    else:\n",
    "        log_print(\"‚ö†Ô∏è WARNING: No training samples processed in this epoch!\")\n",
    "        avg_train_loss = 0\n",
    "        avg_train_acc = 0\n",
    "    \n",
    "    # ===== VALIDATION PHASE - FILE BY FILE =====\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_correct = 0\n",
    "    epoch_val_samples = 0\n",
    "    all_val_preds = []\n",
    "    all_val_labels = []\n",
    "\n",
    "    val_start_time = time.time()\n",
    "    log_print(f\"\\nValidating on {len(val_files)} files...\")\n",
    "\n",
    "    for val_file in tqdm(val_files, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "        loss, acc_pct, samples, preds, labels, _ = validate_on_file(model, val_file, preprocessor)\n",
    "        \n",
    "        epoch_val_loss += loss * samples\n",
    "        epoch_val_correct += (acc_pct / 100.0) * samples\n",
    "        epoch_val_samples += samples\n",
    "        all_val_preds.extend(preds)\n",
    "        all_val_labels.extend(labels)\n",
    "\n",
    "    val_time = time.time() - val_start_time\n",
    "\n",
    "    # Calculate epoch averages and F1 score\n",
    "    if epoch_val_samples > 0:\n",
    "        avg_val_loss = epoch_val_loss / epoch_val_samples\n",
    "        avg_val_acc = (epoch_val_correct / epoch_val_samples) * 100\n",
    "        avg_val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
    "    else:\n",
    "        log_print(\"‚ö†Ô∏è WARNING: No validation samples processed in this epoch!\")\n",
    "        avg_val_loss = 0\n",
    "        avg_val_acc = 0\n",
    "        avg_val_f1 = 0\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # Calculate epoch time\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['train_acc'].append(avg_train_acc)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['val_acc'].append(avg_val_acc)\n",
    "    history['val_f1'].append(avg_val_f1)\n",
    "    history['epoch_time'].append(epoch_time)\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary with performance metrics\n",
    "    log_print(f\"\\n{'='*70}\")\n",
    "    log_print(f\"Epoch {epoch+1} Summary:\")\n",
    "    log_print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.2f}%\")\n",
    "    log_print(f\"  Val Loss:   {avg_val_loss:.4f} | Val Acc:   {avg_val_acc:.2f}% | Val F1: {avg_val_f1:.4f}\")\n",
    "    log_print(f\"  LR: {current_lr:.6f}\")\n",
    "    log_print(f\"  Time: {epoch_time:.1f}s (Train: {train_time:.1f}s, Val: {val_time:.1f}s)\")\n",
    "    log_print(f\"  Samples: Train={epoch_train_samples:,}, Val={epoch_val_samples:,}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_mem_peak = torch.cuda.max_memory_allocated(0) / 1e9\n",
    "        log_print(f\"  Peak GPU Memory: {gpu_mem_peak:.2f} GB\")\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    if train_time > 0 and epoch_train_samples > 0:\n",
    "        samples_per_sec = epoch_train_samples / train_time\n",
    "        log_print(f\"  Throughput: {samples_per_sec:.0f} samples/sec\")\n",
    "    log_print(f\"{'='*70}\")\n",
    "    \n",
    "    # Save best model (based on F1 score)\n",
    "    if avg_val_f1 > best_val_f1:\n",
    "        best_val_f1 = avg_val_f1\n",
    "        best_val_acc = avg_val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_acc': best_val_acc,\n",
    "            'val_f1': best_val_f1,\n",
    "            'history': history\n",
    "        }, MODEL_SAVE_PATH)\n",
    "        log_print(f\"‚úì Best model saved: Val Acc={best_val_acc:.2f}%, Val F1={best_val_f1:.4f}\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'history': history\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    # Garbage collection\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "total_time = sum(history['epoch_time'])\n",
    "avg_epoch_time = total_time / len(history['epoch_time']) if history['epoch_time'] else 0\n",
    "\n",
    "log_print(\"\\n\" + \"=\"*70)\n",
    "log_print(\"Training Complete!\")\n",
    "log_print(\"=\"*70)\n",
    "log_print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "log_print(f\"Best Validation F1 Score: {best_val_f1:.4f}\")\n",
    "log_print(f\"Total Time: {total_time/60:.1f} minutes\")\n",
    "log_print(f\"Average Time per Epoch: {avg_epoch_time:.1f} seconds\")\n",
    "log_print(\"=\"*70)\n",
    "\n",
    "# Close log file\n",
    "log_file.close()\n",
    "print(f\"\\n‚úì Training output saved to: {log_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eccadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Val Accuracy', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score plot\n",
    "axes[2].plot(history['val_f1'], label='Val F1 (Weighted)', marker='o', color='green')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].set_title('Validation Weighted F1 Score')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_lstm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history plots saved as 'training_history_lstm.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fbc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Best model loaded from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "print(f\"Best validation F1 score: {checkpoint['val_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dcdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FINAL TEST EVALUATION =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TEST EVALUATION ON HELD-OUT TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "test_total_loss = 0\n",
    "test_total_samples = 0\n",
    "\n",
    "print(f\"\\nEvaluating on {len(test_files)} test files...\")\n",
    "\n",
    "for test_file in tqdm(test_files, desc=\"Testing\"):\n",
    "    loss, acc, samples, preds, labels, f1 = validate_on_file(model, test_file, preprocessor)\n",
    "    test_predictions.extend(preds)\n",
    "    test_labels.extend(labels)\n",
    "    test_total_loss += loss * samples\n",
    "    test_total_samples += samples\n",
    "\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_f1_macro = f1_score(test_labels, test_predictions, average='macro', zero_division=0)\n",
    "test_f1_weighted = f1_score(test_labels, test_predictions, average='weighted', zero_division=0)\n",
    "test_avg_loss = test_total_loss / max(test_total_samples, 1)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Total Test Samples: {test_total_samples:,}\")\n",
    "print(f\"  Test Loss: {test_avg_loss:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"  Test F1-Score (Macro): {test_f1_macro:.4f}\")\n",
    "print(f\"  Test F1-Score (Weighted): {test_f1_weighted:.4f}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report for Test Set\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT (TEST SET)\")\n",
    "print(\"=\"*70)\n",
    "class_names = preprocessor.label_encoder.classes_\n",
    "print(classification_report(test_labels, test_predictions, \n",
    "                          target_names=class_names, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60741215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for Test Set\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Confusion Matrix - AE-LSTM-CNN Test Set', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_lstm_test.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix saved as 'confusion_matrix_lstm_test.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class performance analysis for Test Set\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    test_labels, test_predictions, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "performance_df = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support\n",
    "}).sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-CLASS PERFORMANCE (TEST SET - sorted by F1-Score)\")\n",
    "print(\"=\"*70)\n",
    "print(performance_df.to_string(index=False))\n",
    "\n",
    "# Plot per-class F1 scores\n",
    "plt.figure(figsize=(14, 10))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(class_names)))\n",
    "bars = plt.barh(range(len(class_names)), performance_df['F1-Score'], color=colors)\n",
    "plt.yticks(range(len(class_names)), performance_df['Class'])\n",
    "plt.xlabel('F1-Score', fontsize=12)\n",
    "plt.title('Per-Class F1-Scores - AE-LSTM-CNN Test Set', fontsize=14)\n",
    "plt.xlim([0, 1.0])\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_class_f1_scores_lstm_test.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Per-class F1-scores plot saved as 'per_class_f1_scores_lstm_test.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab42c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary with all metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL MODEL SUMMARY - AE-LSTM-CNN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nArchitecture:\")\n",
    "print(f\"  - Autoencoder: {NUM_FEATURES} ‚Üí {ENCODER_DIM} dimensions\")\n",
    "print(f\"  - LSTM: {LSTM_LAYERS} layers, {LSTM_HIDDEN} hidden units (bidirectional)\")\n",
    "print(f\"  - CNN: {len(CNN_FILTERS)} layers, filters: {CNN_FILTERS}\")\n",
    "print(f\"  - Total Parameters: {total_params:,}\")\n",
    "\n",
    "print(f\"\\nDataset Split:\")\n",
    "print(f\"  - Total CSV files: {len(csv_files)}\")\n",
    "print(f\"  - Training files: {len(train_files)} ({len(train_files)/len(csv_files)*100:.1f}%)\")\n",
    "print(f\"  - Validation files: {len(val_files)} ({len(val_files)/len(csv_files)*100:.1f}%)\")\n",
    "print(f\"  - Test files: {len(test_files)} ({len(test_files)/len(csv_files)*100:.1f}%)\")\n",
    "print(f\"  - Features: {NUM_FEATURES}\")\n",
    "print(f\"  - Classes: {NUM_CLASSES}\")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Sequence Length: {SEQUENCE_LENGTH}\")\n",
    "print(f\"  - Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Chunk Size: {CHUNK_SIZE:,} rows\")\n",
    "\n",
    "print(f\"\\nBest Validation Performance:\")\n",
    "print(f\"  - Val Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"  - Val F1 (Weighted): {best_val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nFinal Test Performance:\")\n",
    "print(f\"  - Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"  - Test F1 (Macro): {test_f1_macro:.4f}\")\n",
    "print(f\"  - Test F1 (Weighted): {test_f1_weighted:.4f}\")\n",
    "\n",
    "print(f\"\\nModel saved as: {MODEL_SAVE_PATH}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Best model loaded from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best validation accuracy: {checkpoint['val_acc']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive evaluation on validation set\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Comprehensive Evaluation on Validation Set\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_val_predictions = []\n",
    "all_val_labels = []\n",
    "\n",
    "for val_file in tqdm(val_files, desc=\"Evaluating\"):\n",
    "    _, _, _, predictions, labels = validate_on_file(model, val_file, preprocessor)\n",
    "    all_val_predictions.extend(predictions)\n",
    "    all_val_labels.extend(labels)\n",
    "\n",
    "all_val_predictions = np.array(all_val_predictions)\n",
    "all_val_labels = np.array(all_val_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_val_labels, all_val_predictions)\n",
    "f1_macro = f1_score(all_val_labels, all_val_predictions, average='macro')\n",
    "f1_weighted = f1_score(all_val_labels, all_val_predictions, average='weighted')\n",
    "\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"  Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"  F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"  F1-Score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Classification Report:\")\n",
    "print(f\"{'='*70}\")\n",
    "class_names = preprocessor.label_encoder.classes_\n",
    "print(classification_report(all_val_labels, all_val_predictions, \n",
    "                          target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_val_labels, all_val_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Confusion Matrix - AE-LSTM-CNN Intrusion Detection', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix saved as 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8daf251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class performance analysis\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    all_val_labels, all_val_predictions, average=None\n",
    ")\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "performance_df = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support\n",
    "}).sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\nPer-Class Performance (sorted by F1-Score):\")\n",
    "print(performance_df.to_string(index=False))\n",
    "\n",
    "# Plot per-class F1 scores\n",
    "plt.figure(figsize=(14, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(class_names)))\n",
    "bars = plt.barh(range(len(class_names)), performance_df['F1-Score'], color=colors)\n",
    "plt.yticks(range(len(class_names)), performance_df['Class'])\n",
    "plt.xlabel('F1-Score', fontsize=12)\n",
    "plt.title('Per-Class F1-Scores - AE-LSTM-CNN Model', fontsize=14)\n",
    "plt.xlim([0, 1.0])\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_class_f1_scores.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Per-class F1-scores plot saved as 'per_class_f1_scores.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary and final statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Final Model Summary\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nArchitecture: AE-LSTM-CNN Hybrid\")\n",
    "print(f\"  - Autoencoder: {NUM_FEATURES} ‚Üí {ENCODER_DIM} dimensions\")\n",
    "print(f\"  - LSTM: {LSTM_LAYERS} layers, {LSTM_HIDDEN} hidden units (bidirectional)\")\n",
    "print(f\"  - CNN: {len(CNN_FILTERS)} layers, filters: {CNN_FILTERS}\")\n",
    "print(f\"  - Total Parameters: {total_params:,}\")\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  - Total CSV files: {len(csv_files)}\")\n",
    "print(f\"  - Training files: {len(train_files)}\")\n",
    "print(f\"  - Validation files: {len(val_files)}\")\n",
    "print(f\"  - Features: {NUM_FEATURES}\")\n",
    "print(f\"  - Classes: {NUM_CLASSES}\")\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Sequence Length: {SEQUENCE_LENGTH}\")\n",
    "print(f\"  - Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Gradient Accumulation: {ACCUMULATION_STEPS} steps\")\n",
    "print(f\"  - Chunk Size: {CHUNK_SIZE:,} rows\")\n",
    "print(f\"\\nFinal Performance:\")\n",
    "print(f\"  - Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"  - Final F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"  - Final F1-Score (Weighted): {f1_weighted:.4f}\")\n",
    "print(f\"\\nModel saved as: {MODEL_SAVE_PATH}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c625865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessor for future use\n",
    "import pickle\n",
    "\n",
    "with open('preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "print(\"Preprocessor saved as 'preprocessor.pkl'\")\n",
    "print(\"\\nTo use this model for inference:\")\n",
    "print(\"1. Load the preprocessor: preprocessor = pickle.load(open('preprocessor.pkl', 'rb'))\")\n",
    "print(\"2. Load the model: model.load_state_dict(torch.load('best_ae_lstm_cnn_optimized.pth')['model_state_dict'])\")\n",
    "print(\"3. Preprocess new data and make predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linux_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
