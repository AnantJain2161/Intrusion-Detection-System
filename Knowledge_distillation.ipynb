{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VomgG90GcSF",
        "outputId": "c385b4d9-fe40-4031-d930-053a02d53019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üéÆ GPU Configuration\n",
            "================================================================================\n",
            "‚ö†Ô∏è  No GPU detected, running on CPU\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üì• Downloading CIC-IoT-2023 Dataset from Kaggle...\n",
            "================================================================================\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/akashdogra/cic-iot-2023?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.77G/2.77G [00:25<00:00, 117MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset downloaded to: /root/.cache/kagglehub/datasets/akashdogra/cic-iot-2023/versions/1\n",
            "üìÇ Found 169 CSV files.\n",
            "\n",
            "üìä Dataset Split:\n",
            "   Training:   101 files\n",
            "   Validation: 34 files\n",
            "   Testing:    34 files\n",
            "\n",
            "================================================================================\n",
            "üè∑Ô∏è  Fitting Label Encoder...\n",
            "================================================================================\n",
            "Processing batch 1/21\n",
            "Processing batch 2/21\n",
            "Processing batch 3/21\n",
            "Processing batch 4/21\n",
            "Processing batch 5/21\n",
            "Processing batch 6/21\n",
            "Processing batch 7/21\n",
            "Processing batch 8/21\n",
            "Processing batch 9/21\n",
            "Processing batch 10/21\n",
            "Processing batch 11/21\n",
            "Processing batch 12/21\n",
            "Processing batch 13/21\n",
            "Processing batch 14/21\n",
            "Processing batch 15/21\n",
            "Processing batch 16/21\n",
            "Processing batch 17/21\n",
            "Processing batch 18/21\n",
            "Processing batch 19/21\n",
            "Processing batch 20/21\n",
            "Processing batch 21/21\n",
            "‚úÖ LabelEncoder fitted with 34 classes\n",
            "\n",
            "================================================================================\n",
            "üèóÔ∏è  Fitting Scaler & PCA...\n",
            "================================================================================\n",
            "PCA will use 30 components (dataset has 46 features)\n",
            "Pass 1: Fitting Scaler...\n",
            "  Scaler batch 1/21\n",
            "  Scaler batch 2/21\n",
            "  Scaler batch 3/21\n",
            "  Scaler batch 4/21\n",
            "  Scaler batch 5/21\n",
            "  Scaler batch 6/21\n",
            "  Scaler batch 7/21\n",
            "  Scaler batch 8/21\n",
            "  Scaler batch 9/21\n",
            "  Scaler batch 10/21\n",
            "  Scaler batch 11/21\n",
            "  Scaler batch 12/21\n",
            "  Scaler batch 13/21\n",
            "  Scaler batch 14/21\n",
            "  Scaler batch 15/21\n",
            "  Scaler batch 16/21\n",
            "  Scaler batch 17/21\n",
            "  Scaler batch 18/21\n",
            "  Scaler batch 19/21\n",
            "  Scaler batch 20/21\n",
            "  Scaler batch 21/21\n",
            "‚úÖ Scaler fitted\n",
            "\n",
            "Pass 2: Fitting PCA...\n",
            "  PCA batch 1/21\n",
            "  PCA batch 2/21\n",
            "  PCA batch 3/21\n",
            "  PCA batch 4/21\n",
            "  PCA batch 5/21\n",
            "  PCA batch 6/21\n",
            "  PCA batch 7/21\n",
            "  PCA batch 8/21\n",
            "  PCA batch 9/21\n",
            "  PCA batch 10/21\n",
            "  PCA batch 11/21\n",
            "  PCA batch 12/21\n",
            "  PCA batch 13/21\n",
            "  PCA batch 14/21\n",
            "  PCA batch 15/21\n",
            "  PCA batch 16/21\n",
            "  PCA batch 17/21\n",
            "  PCA batch 18/21\n",
            "  PCA batch 19/21\n",
            "  PCA batch 20/21\n",
            "  PCA batch 21/21\n",
            "‚úÖ PCA fitted with 30 components\n",
            "\n",
            "================================================================================\n",
            "üéì STAGE 1: Training Teacher Model (Large)\n",
            "================================================================================\n",
            "\n",
            "üèóÔ∏è  Teacher Model: 560,994 parameters\n",
            "\n",
            "üöÄ Training Teacher Model...\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 1/20\n",
            "================================================================================\n",
            "Training on 3 files\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Knowledge Distillation for IoT Intrusion Detection - PyTorch Implementation\n",
        "Teacher: Large LSTM Model\n",
        "Student: Lightweight LSTM Model (10x smaller)\n",
        "60-20-20 Train-Val-Test Split\n",
        "Max 5 files loaded at once\n",
        "GPU Accelerated with PyTorch\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import kagglehub\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Use non-interactive backend for servers\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==========================================================\n",
        "# üéÆ GPU CONFIGURATION\n",
        "# ==========================================================\n",
        "\n",
        "def setup_gpu():\n",
        "    \"\"\"Configure PyTorch to use GPU efficiently\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üéÆ GPU Configuration\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
        "        print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "        print(f\"‚úÖ Number of GPUs: {torch.cuda.device_count()}\")\n",
        "\n",
        "        # Enable cudnn autotuner for optimal performance\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        print(\"‚úÖ cuDNN autotuner enabled\")\n",
        "\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"‚ö†Ô∏è  No GPU detected, running on CPU\")\n",
        "\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "    return device\n",
        "\n",
        "device = setup_gpu()\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ HELPER FUNCTIONS\n",
        "# ==========================================================\n",
        "\n",
        "def load_and_clean(path, label_col=None):\n",
        "    \"\"\"Load CSV and separate features from labels\"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    df = df.dropna()\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    if label_col is None:\n",
        "        label_col = \"Label\" if \"Label\" in df.columns else df.columns[-1]\n",
        "\n",
        "    X = df.drop(columns=[label_col])\n",
        "    y = df[label_col]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def encode_objects(X):\n",
        "    \"\"\"Encode categorical columns and convert to numpy array\"\"\"\n",
        "    for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "        X[col] = LabelEncoder().fit_transform(X[col])\n",
        "    return X.values\n",
        "\n",
        "\n",
        "def process_files_generator(file_list, scaler, pca, label_encoder, batch_size=5):\n",
        "    \"\"\"Generator that yields batches of processed data without storing all in memory\"\"\"\n",
        "    for i in range(0, len(file_list), batch_size):\n",
        "        batch_files = file_list[i:i+batch_size]\n",
        "\n",
        "        X_batch = []\n",
        "        y_batch = []\n",
        "\n",
        "        for f in batch_files:\n",
        "            try:\n",
        "                X, y = load_and_clean(f)\n",
        "                X = encode_objects(X)\n",
        "\n",
        "                X_scaled = scaler.transform(X)\n",
        "                X_reduced = pca.transform(X_scaled)\n",
        "\n",
        "                X_batch.append(X_reduced)\n",
        "                y_batch.append(label_encoder.transform(y.astype(str)))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {f}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if X_batch:\n",
        "            X_combined = np.vstack(X_batch)\n",
        "            y_combined = np.hstack(y_batch)\n",
        "\n",
        "            del X_batch, y_batch\n",
        "            gc.collect()\n",
        "\n",
        "            yield X_combined, y_combined\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# üéì PYTORCH MODELS\n",
        "# ==========================================================\n",
        "\n",
        "class TeacherLSTM(nn.Module):\n",
        "    \"\"\"Large Teacher Model - High Capacity (~200K parameters)\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes, dropout=0.3):\n",
        "        super(TeacherLSTM, self).__init__()\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_sizes[0], batch_first=True)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(hidden_sizes[0], hidden_sizes[1], batch_first=True)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.lstm3 = nn.LSTM(hidden_sizes[1], hidden_sizes[2], batch_first=True)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_sizes[2], 128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, features)\n",
        "        out, _ = self.lstm1(x)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        out, _ = self.lstm2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        out, _ = self.lstm3(out)\n",
        "        out = self.dropout3(out)\n",
        "\n",
        "        # Take last timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.relu1(self.fc1(out))\n",
        "        out = self.relu2(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class StudentLSTM(nn.Module):\n",
        "    \"\"\"Lightweight Student Model - 10x smaller (~20K parameters)\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes, dropout=0.2):\n",
        "        super(StudentLSTM, self).__init__()\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_sizes[0], batch_first=True)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(hidden_sizes[0], hidden_sizes[1], batch_first=True)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_sizes[1], 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm1(x)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        out, _ = self.lstm2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        # Take last timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# üéì KNOWLEDGE DISTILLATION LOSS\n",
        "# ==========================================================\n",
        "\n",
        "class DistillationLoss(nn.Module):\n",
        "    \"\"\"Combined loss for knowledge distillation\"\"\"\n",
        "\n",
        "    def __init__(self, temperature=4.0, alpha=0.7):\n",
        "        super(DistillationLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.alpha = alpha\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "        self.kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, labels):\n",
        "        # Hard target loss (cross-entropy with true labels)\n",
        "        hard_loss = self.ce_loss(student_logits, labels)\n",
        "\n",
        "        # Soft target loss (KL divergence with teacher)\n",
        "        soft_student = torch.log_softmax(student_logits / self.temperature, dim=1)\n",
        "        soft_teacher = torch.softmax(teacher_logits / self.temperature, dim=1)\n",
        "\n",
        "        soft_loss = self.kl_loss(soft_student, soft_teacher) * (self.temperature ** 2)\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
        "\n",
        "        return total_loss, hard_loss, soft_loss\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# üèãÔ∏è TRAINING FUNCTIONS\n",
        "# ==========================================================\n",
        "\n",
        "def train_epoch(model, data_generator, optimizer, criterion, device, is_distillation=False, teacher_model=None):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    if teacher_model is not None:\n",
        "        teacher_model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for X_batch, y_batch in data_generator:\n",
        "        # Convert to tensors\n",
        "        X_tensor = torch.FloatTensor(X_batch).unsqueeze(1).to(device)  # Add sequence dimension\n",
        "        y_tensor = torch.LongTensor(y_batch).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_tensor)\n",
        "\n",
        "        if is_distillation and teacher_model is not None:\n",
        "            # Get teacher predictions\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(X_tensor)\n",
        "\n",
        "            loss, hard_loss, soft_loss = criterion(outputs, teacher_outputs, y_tensor)\n",
        "        else:\n",
        "            loss = criterion(outputs, y_tensor)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * len(y_batch)\n",
        "        total_samples += len(y_batch)\n",
        "\n",
        "        # Free memory\n",
        "        del X_tensor, y_tensor, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return total_loss / total_samples\n",
        "\n",
        "\n",
        "def evaluate(model, data_generator, criterion, device):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_generator:\n",
        "            X_tensor = torch.FloatTensor(X_batch).unsqueeze(1).to(device)\n",
        "            y_tensor = torch.LongTensor(y_batch).to(device)\n",
        "\n",
        "            outputs = model(X_tensor)\n",
        "            loss = criterion(outputs, y_tensor)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == y_tensor).sum().item()\n",
        "            total_loss += loss.item() * len(y_batch)\n",
        "            total_samples += len(y_batch)\n",
        "\n",
        "            del X_tensor, y_tensor, outputs\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    accuracy = correct / total_samples\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# üìÇ DOWNLOAD & SPLIT DATASET\n",
        "# ==========================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üì• Downloading CIC-IoT-2023 Dataset from Kaggle...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "dataset_dir = kagglehub.dataset_download(\"akashdogra/cic-iot-2023\")\n",
        "print(f\"‚úÖ Dataset downloaded to: {dataset_dir}\")\n",
        "\n",
        "csv_files = sorted([\n",
        "    os.path.join(dataset_dir, f)\n",
        "    for f in os.listdir(dataset_dir)\n",
        "    if f.endswith(\".csv\")\n",
        "])\n",
        "\n",
        "print(f\"üìÇ Found {len(csv_files)} CSV files.\")\n",
        "\n",
        "# 60-20-20 split\n",
        "n_files = len(csv_files)\n",
        "train_idx = int(n_files * 0.60)\n",
        "val_idx = int(n_files * 0.80)\n",
        "\n",
        "train_files = csv_files[:train_idx]\n",
        "val_files = csv_files[train_idx:val_idx]\n",
        "test_files = csv_files[val_idx:]\n",
        "\n",
        "print(f\"\\nüìä Dataset Split:\")\n",
        "print(f\"   Training:   {len(train_files)} files\")\n",
        "print(f\"   Validation: {len(val_files)} files\")\n",
        "print(f\"   Testing:    {len(test_files)} files\")\n",
        "\n",
        "# ==========================================================\n",
        "# üè∑Ô∏è FIT LABEL ENCODER\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üè∑Ô∏è  Fitting Label Encoder...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "all_labels = []\n",
        "max_batch = 5\n",
        "\n",
        "for i in range(0, len(train_files), max_batch):\n",
        "    batch_files = train_files[i:i+max_batch]\n",
        "    print(f\"Processing batch {i//max_batch + 1}/{(len(train_files)-1)//max_batch + 1}\")\n",
        "\n",
        "    for f in batch_files:\n",
        "        _, y = load_and_clean(f)\n",
        "        all_labels.extend(list(y.astype(str)))\n",
        "\n",
        "    if i % (max_batch * 4) == 0:\n",
        "        gc.collect()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_labels)\n",
        "del all_labels\n",
        "gc.collect()\n",
        "\n",
        "print(f\"‚úÖ LabelEncoder fitted with {len(label_encoder.classes_)} classes\")\n",
        "\n",
        "# ==========================================================\n",
        "# üèóÔ∏è FIT SCALER & PCA\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üèóÔ∏è  Fitting Scaler & PCA...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "sample_X, _ = load_and_clean(train_files[0])\n",
        "sample_X = encode_objects(sample_X)\n",
        "n_features = sample_X.shape[1]\n",
        "n_components = min(30, n_features)\n",
        "del sample_X\n",
        "gc.collect()\n",
        "\n",
        "print(f\"PCA will use {n_components} components (dataset has {n_features} features)\")\n",
        "\n",
        "pca = IncrementalPCA(n_components=n_components)\n",
        "\n",
        "# Pass 1: Fit Scaler\n",
        "print(\"Pass 1: Fitting Scaler...\")\n",
        "for i in range(0, len(train_files), max_batch):\n",
        "    batch_files = train_files[i:i+max_batch]\n",
        "    print(f\"  Scaler batch {i//max_batch + 1}/{(len(train_files)-1)//max_batch + 1}\")\n",
        "\n",
        "    for f in batch_files:\n",
        "        X, _ = load_and_clean(f)\n",
        "        X = encode_objects(X)\n",
        "        scaler.partial_fit(X)\n",
        "        del X\n",
        "        gc.collect()\n",
        "\n",
        "print(\"‚úÖ Scaler fitted\")\n",
        "\n",
        "# Pass 2: Fit PCA\n",
        "print(\"\\nPass 2: Fitting PCA...\")\n",
        "for i in range(0, len(train_files), max_batch):\n",
        "    batch_files = train_files[i:i+max_batch]\n",
        "    print(f\"  PCA batch {i//max_batch + 1}/{(len(train_files)-1)//max_batch + 1}\")\n",
        "\n",
        "    for f in batch_files:\n",
        "        X, _ = load_and_clean(f)\n",
        "        X = encode_objects(X)\n",
        "        X_scaled = scaler.transform(X)\n",
        "        pca.partial_fit(X_scaled)\n",
        "        del X, X_scaled\n",
        "        gc.collect()\n",
        "\n",
        "print(f\"‚úÖ PCA fitted with {pca.n_components_} components\")\n",
        "gc.collect()\n",
        "\n",
        "# ==========================================================\n",
        "# üéì STAGE 1: TRAIN TEACHER MODEL\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéì STAGE 1: Training Teacher Model (Large)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "n_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Initialize teacher model\n",
        "teacher_model = TeacherLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_sizes=[256, 128, 64],\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "# Count parameters\n",
        "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
        "print(f\"\\nüèóÔ∏è  Teacher Model: {teacher_params:,} parameters\")\n",
        "\n",
        "# Optimizer and criterion\n",
        "teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
        "teacher_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "epochs_teacher = 20\n",
        "files_per_epoch = 3\n",
        "\n",
        "best_teacher_acc = 0\n",
        "patience_counter = 0\n",
        "patience = 3\n",
        "\n",
        "print(\"\\nüöÄ Training Teacher Model...\")\n",
        "\n",
        "for epoch in range(epochs_teacher):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TEACHER EPOCH {epoch+1}/{epochs_teacher}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Select training files\n",
        "    start = (epoch * files_per_epoch) % len(train_files)\n",
        "    selected_files = train_files[start:start + files_per_epoch]\n",
        "\n",
        "    if len(selected_files) < files_per_epoch:\n",
        "        selected_files += train_files[:files_per_epoch - len(selected_files)]\n",
        "\n",
        "    print(f\"Training on {len(selected_files)} files\")\n",
        "\n",
        "    # Train\n",
        "    train_gen = process_files_generator(selected_files, scaler, pca, label_encoder, batch_size=files_per_epoch)\n",
        "    train_loss = train_epoch(teacher_model, train_gen, teacher_optimizer, teacher_criterion, device)\n",
        "\n",
        "    # Validate\n",
        "    val_gen = process_files_generator(val_files[:5], scaler, pca, label_encoder, batch_size=5)\n",
        "    val_loss, val_acc = evaluate(teacher_model, val_gen, teacher_criterion, device)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_teacher_acc:\n",
        "        best_teacher_acc = val_acc\n",
        "        torch.save(teacher_model.state_dict(), 'teacher_model.pth')\n",
        "        print(f\"‚úÖ Best teacher model saved! Val Acc: {val_acc:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n‚úÖ Teacher Model Training Complete!\")\n",
        "teacher_model.load_state_dict(torch.load('teacher_model.pth'))\n",
        "\n",
        "# ==========================================================\n",
        "# üéí STAGE 2: KNOWLEDGE DISTILLATION - TRAIN STUDENT\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéí STAGE 2: Knowledge Distillation - Training Student Model\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize student model\n",
        "student_model = StudentLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_sizes=[32, 16],\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "student_params = sum(p.numel() for p in student_model.parameters())\n",
        "reduction_ratio = teacher_params / student_params\n",
        "\n",
        "print(f\"\\nüèóÔ∏è  Student Model: {student_params:,} parameters\")\n",
        "print(f\"\\nüìä Model Comparison:\")\n",
        "print(f\"   Teacher Parameters: {teacher_params:,}\")\n",
        "print(f\"   Student Parameters: {student_params:,}\")\n",
        "print(f\"   Size Reduction:     {reduction_ratio:.1f}x smaller\")\n",
        "\n",
        "# Optimizer and distillation loss\n",
        "student_optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
        "distillation_criterion = DistillationLoss(temperature=4.0, alpha=0.7)\n",
        "\n",
        "epochs_student = 25\n",
        "best_student_acc = 0\n",
        "patience_counter = 0\n",
        "\n",
        "print(f\"\\nüöÄ Training Student with Knowledge Distillation...\")\n",
        "print(f\"   Temperature: {distillation_criterion.temperature}\")\n",
        "print(f\"   Alpha (soft target weight): {distillation_criterion.alpha}\")\n",
        "\n",
        "for epoch in range(epochs_student):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"STUDENT EPOCH {epoch+1}/{epochs_student}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Select training files\n",
        "    start = (epoch * files_per_epoch) % len(train_files)\n",
        "    selected_files = train_files[start:start + files_per_epoch]\n",
        "\n",
        "    if len(selected_files) < files_per_epoch:\n",
        "        selected_files += train_files[:files_per_epoch - len(selected_files)]\n",
        "\n",
        "    print(f\"Training on {len(selected_files)} files\")\n",
        "\n",
        "    # Train with distillation\n",
        "    train_gen = process_files_generator(selected_files, scaler, pca, label_encoder, batch_size=files_per_epoch)\n",
        "    train_loss = train_epoch(student_model, train_gen, student_optimizer, distillation_criterion,\n",
        "                            device, is_distillation=True, teacher_model=teacher_model)\n",
        "\n",
        "    # Validate\n",
        "    val_gen = process_files_generator(val_files[:5], scaler, pca, label_encoder, batch_size=5)\n",
        "    val_criterion = nn.CrossEntropyLoss()\n",
        "    val_loss, val_acc = evaluate(student_model, val_gen, val_criterion, device)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_student_acc:\n",
        "        best_student_acc = val_acc\n",
        "        torch.save(student_model.state_dict(), 'student_model.pth')\n",
        "        print(f\"‚úÖ Best student model saved! Val Acc: {val_acc:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n‚úÖ Student Model Training Complete!\")\n",
        "student_model.load_state_dict(torch.load('student_model.pth'))\n",
        "\n",
        "# ==========================================================\n",
        "# üìà STAGE 3: EVALUATION - COMPARE TEACHER VS STUDENT\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìà STAGE 3: Final Evaluation - Teacher vs Student\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def evaluate_model_detailed(model, model_name):\n",
        "    \"\"\"Evaluate model on test set with detailed metrics\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model.eval()\n",
        "    y_true_all = []\n",
        "    y_pred_all = []\n",
        "\n",
        "    test_gen = process_files_generator(test_files, scaler, pca, label_encoder, batch_size=5)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_num, (X_test, y_test) in enumerate(test_gen):\n",
        "            print(f\"Test batch {batch_num + 1}/{(len(test_files)-1)//5 + 1}\")\n",
        "\n",
        "            X_tensor = torch.FloatTensor(X_test).unsqueeze(1).to(device)\n",
        "            outputs = model(X_tensor)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            y_true_all.extend(y_test)\n",
        "            y_pred_all.extend(predicted.cpu().numpy())\n",
        "\n",
        "            del X_tensor, outputs\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    y_true_all = np.array(y_true_all)\n",
        "    y_pred_all = np.array(y_pred_all)\n",
        "\n",
        "    accuracy = accuracy_score(y_true_all, y_pred_all)\n",
        "    precision = precision_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"\\nüìä {model_name} Performance:\")\n",
        "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"   Precision: {precision:.4f}\")\n",
        "    print(f\"   Recall:    {recall:.4f}\")\n",
        "    print(f\"   F1-Score:  {f1:.4f}\")\n",
        "\n",
        "    return y_true_all, y_pred_all, accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate both models\n",
        "teacher_results = evaluate_model_detailed(teacher_model, \"TEACHER MODEL\")\n",
        "student_results = evaluate_model_detailed(student_model, \"STUDENT MODEL (Distilled)\")\n",
        "\n",
        "# ==========================================================\n",
        "# üìä CONFUSION MATRIX & COMPARISON\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä Generating Comparison Report...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "y_true, y_pred, s_acc, s_prec, s_rec, s_f1 = student_results\n",
        "_, _, t_acc, t_prec, t_rec, t_f1 = teacher_results\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Student Model Confusion Matrix (Knowledge Distillation - PyTorch)', fontsize=16, pad=20)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
        "plt.yticks(rotation=0, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.savefig('student_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úÖ Student confusion matrix saved as 'student_confusion_matrix.png'\")\n",
        "\n",
        "# Comparison Summary\n",
        "performance_retention = (s_acc / t_acc) * 100\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä FINAL COMPARISON: TEACHER vs STUDENT\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Metric':<15} {'Teacher':<15} {'Student':<15} {'Difference':<15}\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Accuracy':<15} {t_acc:<15.4f} {s_acc:<15.4f} {(s_acc-t_acc):<15.4f}\")\n",
        "print(f\"{'Precision':<15} {t_prec:<15.4f} {s_prec:<15.4f} {(s_prec-t_prec):<15.4f}\")\n",
        "print(f\"{'Recall':<15} {t_rec:<15.4f} {s_rec:<15.4f} {(s_rec-t_rec):<15.4f}\")\n",
        "print(f\"{'F1-Score':<15} {t_f1:<15.4f} {s_f1:<15.4f} {(s_f1-t_f1):<15.4f}\")\n",
        "print(f\"{'Parameters':<15} {teacher_params:<15,} {student_params:<15,} {'-':<15}\")\n",
        "print(f\"{'Model Size':<15} {'1.0x':<15} {f'{1/reduction_ratio:.2f}x':<15} {f'{reduction_ratio:.1f}x smaller':<15}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nüéØ Performance Retention: {performance_retention:.2f}%\")\n",
        "print(f\"üéØ Model Size Reduction: {reduction_ratio:.1f}x smaller\")\n",
        "print(f\"üéØ Parameter Reduction: {((teacher_params - student_params) / teacher_params * 100):.1f}% fewer parameters\")\n",
        "\n",
        "# ==========================================================\n",
        "# üíæ SAVE MODELS AND PREPROCESSING OBJECTS\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üíæ Saving Models and Preprocessing Objects\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save PyTorch models\n",
        "torch.save({\n",
        "    'model_state_dict': teacher_model.state_dict(),\n",
        "    'input_size': n_components,\n",
        "    'hidden_sizes': [256, 128, 64],\n",
        "    'num_classes': n_classes,\n",
        "    'accuracy': t_acc,\n",
        "    'params': teacher_params\n",
        "}, 'teacher_model_complete.pth')\n",
        "print(\"‚úÖ Saved: teacher_model_complete.pth\")\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': student_model.state_dict(),\n",
        "    'input_size': n_components,\n",
        "    'hidden_sizes': [32, 16],\n",
        "    'num_classes': n_classes,\n",
        "    'accuracy': s_acc,\n",
        "    'params': student_params\n",
        "}, 'student_model_complete.pth')\n",
        "print(\"‚úÖ Saved: student_model_complete.pth\")\n",
        "\n",
        "# Save preprocessing objects\n",
        "preprocessing_objects = {\n",
        "    'scaler': scaler,\n",
        "    'pca': pca,\n",
        "    'label_encoder': label_encoder\n",
        "}\n",
        "\n",
        "with open('preprocessing.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessing_objects, f)\n",
        "print(\"‚úÖ Saved: preprocessing.pkl\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'n_classes': int(n_classes),\n",
        "    'n_features': int(n_features),\n",
        "    'n_components': int(n_components),\n",
        "    'teacher_params': int(teacher_params),\n",
        "    'student_params': int(student_params),\n",
        "    'teacher_accuracy': float(t_acc),\n",
        "    'student_accuracy': float(s_acc),\n",
        "    'size_reduction': float(reduction_ratio),\n",
        "    'performance_retention': float(performance_retention),\n",
        "    'classes': label_encoder.classes_.tolist()\n",
        "}\n",
        "\n",
        "with open('model_metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "print(\"‚úÖ Saved: model_metadata.json\")\n",
        "\n",
        "# Create summary\n",
        "with open('model_summary.txt', 'w') as f:\n",
        "    f.write(\"=\" * 80 + \"\\n\")\n",
        "    f.write(\"KNOWLEDGE DISTILLATION - PYTORCH MODEL SUMMARY\\n\")\n",
        "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"TEACHER MODEL:\\n\")\n",
        "    f.write(f\"  Parameters: {teacher_params:,}\\n\")\n",
        "    f.write(f\"  Accuracy: {t_acc:.4f}\\n\")\n",
        "    f.write(f\"  Precision: {t_prec:.4f}\\n\")\n",
        "    f.write(f\"  Recall: {t_rec:.4f}\\n\")\n",
        "    f.write(f\"  F1-Score: {t_f1:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"STUDENT MODEL (DISTILLED):\\n\")\n",
        "    f.write(f\"  Parameters: {student_params:,}\\n\")\n",
        "    f.write(f\"  Accuracy: {s_acc:.4f}\\n\")\n",
        "    f.write(f\"  Precision: {s_prec:.4f}\\n\")\n",
        "    f.write(f\"  Recall: {s_rec:.4f}\\n\")\n",
        "    f.write(f\"  F1-Score: {s_f1:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"COMPRESSION METRICS:\\n\")\n",
        "    f.write(f\"  Size Reduction: {reduction_ratio:.1f}x smaller\\n\")\n",
        "    f.write(f\"  Performance Retention: {performance_retention:.2f}%\\n\")\n",
        "    f.write(f\"  Parameter Reduction: {((teacher_params - student_params) / teacher_params * 100):.1f}%\\n\\n\")\n",
        "\n",
        "    f.write(\"FILES GENERATED:\\n\")\n",
        "    f.write(\"  - teacher_model_complete.pth (Teacher model with metadata)\\n\")\n",
        "    f.write(\"  - student_model_complete.pth (Student model with metadata)\\n\")\n",
        "    f.write(\"  - preprocessing.pkl (Scaler, PCA, Label Encoder)\\n\")\n",
        "    f.write(\"  - model_metadata.json (Model specifications)\\n\")\n",
        "    f.write(\"  - student_confusion_matrix.png (Confusion matrix visualization)\\n\")\n",
        "\n",
        "print(\"‚úÖ Saved: model_summary.txt\")\n",
        "\n",
        "# List all files\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìÅ Generated Files:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "files_to_check = [\n",
        "    'teacher_model_complete.pth',\n",
        "    'student_model_complete.pth',\n",
        "    'preprocessing.pkl',\n",
        "    'model_metadata.json',\n",
        "    'model_summary.txt',\n",
        "    'student_confusion_matrix.png'\n",
        "]\n",
        "\n",
        "total_size = 0\n",
        "for filename in files_to_check:\n",
        "    if os.path.exists(filename):\n",
        "        size = os.path.getsize(filename)\n",
        "        total_size += size\n",
        "        size_mb = size / (1024 * 1024)\n",
        "        print(f\"‚úÖ {filename:<40} {size_mb:>10.2f} MB\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"üìä Total Size: {total_size / (1024 * 1024):.2f} MB\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéâ KNOWLEDGE DISTILLATION COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nYour lightweight student model is ready for deployment!\")\n",
        "print(f\"Model size reduced by {reduction_ratio:.1f}x with {performance_retention:.1f}% performance retention\")\n",
        "print(\"\\nAll model files have been saved and are ready for download.\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "RAM-EFFICIENT Knowledge Distillation for IoT Intrusion Detection\n",
        "Key Fixes:\n",
        "- NEVER loads all data into RAM\n",
        "- Streaming data processing\n",
        "- Train on one file at a time\n",
        "- Incremental learning approach\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import kagglehub\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==========================================================\n",
        "# üéÆ GPU CONFIGURATION\n",
        "# ==========================================================\n",
        "\n",
        "def setup_gpu():\n",
        "    \"\"\"Configure PyTorch to use GPU efficiently\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üéÆ GPU Configuration\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"‚ö†Ô∏è  No GPU detected\")\n",
        "\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "    return device\n",
        "\n",
        "device = setup_gpu()\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ AGGRESSIVE RAM MANAGEMENT\n",
        "# ==========================================================\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Aggressive memory cleanup\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def print_ram_usage():\n",
        "    \"\"\"Print RAM usage (Linux only)\"\"\"\n",
        "    try:\n",
        "        import psutil\n",
        "        process = psutil.Process()\n",
        "        ram_mb = process.memory_info().rss / 1024 / 1024\n",
        "        print(f\"üíæ RAM Usage: {ram_mb:.0f} MB\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# ==========================================================\n",
        "# üì¶ STREAMING DATASET (NO RAM LOADING)\n",
        "# ==========================================================\n",
        "\n",
        "class StreamingIoTDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset that NEVER loads data into RAM.\n",
        "    Reads from disk on-the-fly for each batch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, csv_path, scaler, pca, label_encoder, chunk_size=5000):\n",
        "        self.csv_path = csv_path\n",
        "        self.scaler = scaler\n",
        "        self.pca = pca\n",
        "        self.label_encoder = label_encoder\n",
        "        self.chunk_size = chunk_size\n",
        "\n",
        "        # Only read the file length, not the data\n",
        "        self.length = sum(1 for _ in open(csv_path)) - 1  # Exclude header\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        This is inefficient for random access but saves RAM.\n",
        "        For production, use chunked iteration instead.\n",
        "        \"\"\"\n",
        "        # Read only the specific row (very slow, see note below)\n",
        "        df = pd.read_csv(self.csv_path, skiprows=range(1, idx+1), nrows=1)\n",
        "\n",
        "        label_col = \"Label\" if \"Label\" in df.columns else df.columns[-1]\n",
        "        X = df.drop(columns=[label_col])\n",
        "        y = df[label_col].values[0]\n",
        "\n",
        "        # Encode\n",
        "        for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "            try:\n",
        "                X[col] = LabelEncoder().fit_transform(X[col])\n",
        "            except:\n",
        "                X[col] = 0\n",
        "\n",
        "        X = X.values.astype(np.float32)\n",
        "\n",
        "        # Transform\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        X_reduced = self.pca.transform(X_scaled)\n",
        "        y_encoded = self.label_encoder.transform([str(y)])[0]\n",
        "\n",
        "        return torch.FloatTensor(X_reduced[0]), torch.LongTensor([y_encoded])[0]\n",
        "\n",
        "\n",
        "class ChunkedFileLoader:\n",
        "    \"\"\"\n",
        "    Better approach: Load file in chunks, iterate through chunks.\n",
        "    This is what we'll actually use.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, csv_path, scaler, pca, label_encoder, chunk_size=5000):\n",
        "        self.csv_path = csv_path\n",
        "        self.scaler = scaler\n",
        "        self.pca = pca\n",
        "        self.label_encoder = label_encoder\n",
        "        self.chunk_size = chunk_size\n",
        "\n",
        "    def get_chunks(self):\n",
        "        \"\"\"Yield chunks of data without loading entire file\"\"\"\n",
        "        chunks = pd.read_csv(self.csv_path, chunksize=self.chunk_size, low_memory=False)\n",
        "\n",
        "        for chunk_df in chunks:\n",
        "            # Clean\n",
        "            chunk_df = chunk_df.dropna()\n",
        "            chunk_df = chunk_df.drop_duplicates()\n",
        "\n",
        "            if len(chunk_df) == 0:\n",
        "                continue\n",
        "\n",
        "            # Separate X and y\n",
        "            label_col = \"Label\" if \"Label\" in chunk_df.columns else chunk_df.columns[-1]\n",
        "            X = chunk_df.drop(columns=[label_col])\n",
        "            y = chunk_df[label_col]\n",
        "\n",
        "            # Encode objects\n",
        "            for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "                try:\n",
        "                    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "                except:\n",
        "                    X[col] = 0\n",
        "\n",
        "            X = X.values.astype(np.float32)\n",
        "\n",
        "            # Transform\n",
        "            try:\n",
        "                X_scaled = self.scaler.transform(X)\n",
        "                X_reduced = self.pca.transform(X_scaled)\n",
        "                y_encoded = self.label_encoder.transform(y.astype(str))\n",
        "\n",
        "                yield X_reduced, y_encoded\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing chunk: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Clean up immediately\n",
        "            del chunk_df, X, y\n",
        "            gc.collect()\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ HELPER FUNCTIONS\n",
        "# ==========================================================\n",
        "\n",
        "def load_and_clean_sample(path, max_rows=1000):\n",
        "    \"\"\"Load ONLY a small sample for fitting preprocessing\"\"\"\n",
        "    df = pd.read_csv(path, nrows=max_rows, low_memory=False)\n",
        "    df = df.dropna()\n",
        "\n",
        "    label_col = \"Label\" if \"Label\" in df.columns else df.columns[-1]\n",
        "    X = df.drop(columns=[label_col])\n",
        "    y = df[label_col]\n",
        "\n",
        "    # Encode objects\n",
        "    for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "        try:\n",
        "            X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "        except:\n",
        "            X[col] = 0\n",
        "\n",
        "    return X.values.astype(np.float32), y.astype(str).values\n",
        "\n",
        "# ==========================================================\n",
        "# üéì SMALLER PYTORCH MODELS\n",
        "# ==========================================================\n",
        "\n",
        "class TeacherLSTM(nn.Module):\n",
        "    \"\"\"Compact Teacher Model\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_classes, dropout=0.3):\n",
        "        super(TeacherLSTM, self).__init__()\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.lstm2 = nn.LSTM(hidden_size, hidden_size//2, batch_first=True)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(hidden_size//2, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm1(x)\n",
        "        out = self.dropout1(out)\n",
        "        out, _ = self.lstm2(out)\n",
        "        out = self.dropout2(out)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class StudentLSTM(nn.Module):\n",
        "    \"\"\"Tiny Student Model\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_classes, dropout=0.2):\n",
        "        super(StudentLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(hidden_size, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.dropout(out)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# ==========================================================\n",
        "# üéì DISTILLATION LOSS\n",
        "# ==========================================================\n",
        "\n",
        "class DistillationLoss(nn.Module):\n",
        "    def __init__(self, temperature=3.0, alpha=0.7):\n",
        "        super(DistillationLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.alpha = alpha\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "        self.kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, labels):\n",
        "        hard_loss = self.ce_loss(student_logits, labels)\n",
        "\n",
        "        soft_student = torch.log_softmax(student_logits / self.temperature, dim=1)\n",
        "        soft_teacher = torch.softmax(teacher_logits / self.temperature, dim=1)\n",
        "        soft_loss = self.kl_loss(soft_student, soft_teacher) * (self.temperature ** 2)\n",
        "\n",
        "        return self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
        "\n",
        "# ==========================================================\n",
        "# üèãÔ∏è TRAINING WITH STREAMING DATA\n",
        "# ==========================================================\n",
        "\n",
        "def train_on_file(model, csv_path, scaler, pca, label_encoder, optimizer,\n",
        "                  criterion, device, batch_size=32, is_distillation=False,\n",
        "                  teacher_model=None):\n",
        "    \"\"\"Train on a single file using streaming chunks\"\"\"\n",
        "    model.train()\n",
        "    if teacher_model is not None:\n",
        "        teacher_model.eval()\n",
        "\n",
        "    loader = ChunkedFileLoader(csv_path, scaler, pca, label_encoder, chunk_size=5000)\n",
        "\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for X_chunk, y_chunk in loader.get_chunks():\n",
        "        # Create mini-batches from chunk\n",
        "        n_samples = len(X_chunk)\n",
        "\n",
        "        for i in range(0, n_samples, batch_size):\n",
        "            batch_X = X_chunk[i:i+batch_size]\n",
        "            batch_y = y_chunk[i:i+batch_size]\n",
        "\n",
        "            X_tensor = torch.FloatTensor(batch_X).unsqueeze(1).to(device)\n",
        "            y_tensor = torch.LongTensor(batch_y).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(X_tensor)\n",
        "\n",
        "            if is_distillation and teacher_model is not None:\n",
        "                with torch.no_grad():\n",
        "                    teacher_outputs = teacher_model(X_tensor)\n",
        "                loss = criterion(outputs, teacher_outputs, y_tensor)\n",
        "            else:\n",
        "                loss = criterion(outputs, y_tensor)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * len(batch_y)\n",
        "            total_samples += len(batch_y)\n",
        "\n",
        "            del X_tensor, y_tensor, outputs\n",
        "            clear_memory()\n",
        "\n",
        "        # Clean up chunk\n",
        "        del X_chunk, y_chunk\n",
        "        clear_memory()\n",
        "\n",
        "    return total_loss / total_samples if total_samples > 0 else 0\n",
        "\n",
        "\n",
        "def evaluate_on_file(model, csv_path, scaler, pca, label_encoder,\n",
        "                     criterion, device, batch_size=32):\n",
        "    \"\"\"Evaluate on a single file using streaming\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    loader = ChunkedFileLoader(csv_path, scaler, pca, label_encoder, chunk_size=5000)\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_chunk, y_chunk in loader.get_chunks():\n",
        "            n_samples = len(X_chunk)\n",
        "\n",
        "            for i in range(0, n_samples, batch_size):\n",
        "                batch_X = X_chunk[i:i+batch_size]\n",
        "                batch_y = y_chunk[i:i+batch_size]\n",
        "\n",
        "                X_tensor = torch.FloatTensor(batch_X).unsqueeze(1).to(device)\n",
        "                y_tensor = torch.LongTensor(batch_y).to(device)\n",
        "\n",
        "                outputs = model(X_tensor)\n",
        "                loss = criterion(outputs, y_tensor)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct += (predicted == y_tensor).sum().item()\n",
        "                total_loss += loss.item() * len(batch_y)\n",
        "                total_samples += len(batch_y)\n",
        "\n",
        "                del X_tensor, y_tensor, outputs\n",
        "\n",
        "            del X_chunk, y_chunk\n",
        "            clear_memory()\n",
        "\n",
        "    avg_loss = total_loss / total_samples if total_samples > 0 else 0\n",
        "    accuracy = correct / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# ==========================================================\n",
        "# üìÇ DATASET DOWNLOAD & SPLIT\n",
        "# ==========================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üì• Downloading Dataset...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "dataset_dir = kagglehub.dataset_download(\"akashdogra/cic-iot-2023\")\n",
        "csv_files = sorted([os.path.join(dataset_dir, f) for f in os.listdir(dataset_dir) if f.endswith(\".csv\")])\n",
        "\n",
        "print(f\"üìÇ Found {len(csv_files)} CSV files\")\n",
        "\n",
        "# Split files (not data!)\n",
        "n_files = len(csv_files)\n",
        "train_idx = int(n_files * 0.60)\n",
        "val_idx = int(n_files * 0.80)\n",
        "\n",
        "train_files = csv_files[:train_idx]\n",
        "val_files = csv_files[train_idx:val_idx]\n",
        "test_files = csv_files[val_idx:]\n",
        "\n",
        "print(f\"üìä Split: {len(train_files)} train, {len(val_files)} val, {len(test_files)} test files\")\n",
        "\n",
        "# ==========================================================\n",
        "# üè∑Ô∏è FIT PREPROCESSING (SAMPLING ONLY)\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üè∑Ô∏è  Fitting Preprocessing (Memory-Safe)...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Collect labels from SAMPLES only\n",
        "all_labels = []\n",
        "sample_X_list = []\n",
        "\n",
        "for f in train_files[:3]:  # Only 3 files\n",
        "    X_sample, y_sample = load_and_clean_sample(f, max_rows=1000)\n",
        "    all_labels.extend(y_sample)\n",
        "    sample_X_list.append(X_sample)\n",
        "    print(f\"Sampled {len(y_sample)} rows from {os.path.basename(f)}\")\n",
        "\n",
        "# Fit label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_labels)\n",
        "n_classes = len(label_encoder.classes_)\n",
        "\n",
        "print(f\"‚úÖ Found {n_classes} classes\")\n",
        "\n",
        "# Fit scaler\n",
        "scaler = StandardScaler()\n",
        "for X in sample_X_list:\n",
        "    scaler.partial_fit(X)\n",
        "\n",
        "print(\"‚úÖ Scaler fitted\")\n",
        "\n",
        "# Fit PCA\n",
        "n_components = 20\n",
        "pca = IncrementalPCA(n_components=n_components)\n",
        "\n",
        "for X in sample_X_list:\n",
        "    X_scaled = scaler.transform(X)\n",
        "    pca.partial_fit(X_scaled)\n",
        "\n",
        "print(f\"‚úÖ PCA fitted with {n_components} components\")\n",
        "\n",
        "del all_labels, sample_X_list\n",
        "clear_memory()\n",
        "print_ram_usage()\n",
        "\n",
        "# ==========================================================\n",
        "# üéì TRAIN TEACHER MODEL (FILE-BY-FILE)\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéì Training Teacher Model (Streaming)...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "teacher_model = TeacherLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_size=64,  # Small\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
        "print(f\"Teacher: {teacher_params:,} parameters\")\n",
        "\n",
        "teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
        "teacher_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 5  # Process files multiple times\n",
        "best_teacher_acc = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TEACHER EPOCH {epoch+1}/{epochs}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Train on 2 files per epoch (cycling through)\n",
        "    files_to_use = train_files[(epoch*2) % len(train_files):(epoch*2+2) % len(train_files)]\n",
        "    if len(files_to_use) < 2:\n",
        "        files_to_use = train_files[:2]\n",
        "\n",
        "    for i, train_file in enumerate(files_to_use):\n",
        "        print(f\"\\nüìÇ Training on file {i+1}/{len(files_to_use)}: {os.path.basename(train_file)}\")\n",
        "\n",
        "        train_loss = train_on_file(\n",
        "            teacher_model, train_file, scaler, pca, label_encoder,\n",
        "            teacher_optimizer, teacher_criterion, device, batch_size=32\n",
        "        )\n",
        "\n",
        "        print(f\"   Loss: {train_loss:.4f}\")\n",
        "        print_ram_usage()\n",
        "\n",
        "    # Validate on first val file only\n",
        "    print(f\"\\nüìä Validating...\")\n",
        "    val_loss, val_acc = evaluate_on_file(\n",
        "        teacher_model, val_files[0], scaler, pca, label_encoder,\n",
        "        teacher_criterion, device, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_teacher_acc:\n",
        "        best_teacher_acc = val_acc\n",
        "        torch.save(teacher_model.state_dict(), 'teacher_model.pth')\n",
        "        print(f\"‚úÖ Saved best teacher: {val_acc:.4f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Teacher complete! Best: {best_teacher_acc:.4f}\")\n",
        "teacher_model.load_state_dict(torch.load('teacher_model.pth'))\n",
        "\n",
        "# ==========================================================\n",
        "# üéí TRAIN STUDENT WITH DISTILLATION (FILE-BY-FILE)\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéí Training Student with Knowledge Distillation...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "student_model = StudentLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_size=24,  # Tiny\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "student_params = sum(p.numel() for p in student_model.parameters())\n",
        "print(f\"Student: {student_params:,} parameters\")\n",
        "print(f\"Compression: {teacher_params/student_params:.1f}x\")\n",
        "\n",
        "student_optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
        "distillation_criterion = DistillationLoss(temperature=3.0, alpha=0.7)\n",
        "\n",
        "epochs = 8\n",
        "best_student_acc = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"STUDENT EPOCH {epoch+1}/{epochs}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    files_to_use = train_files[(epoch*2) % len(train_files):(epoch*2+2) % len(train_files)]\n",
        "    if len(files_to_use) < 2:\n",
        "        files_to_use = train_files[:2]\n",
        "\n",
        "    for i, train_file in enumerate(files_to_use):\n",
        "        print(f\"\\nüìÇ Training on file {i+1}/{len(files_to_use)}: {os.path.basename(train_file)}\")\n",
        "\n",
        "        train_loss = train_on_file(\n",
        "            student_model, train_file, scaler, pca, label_encoder,\n",
        "            student_optimizer, distillation_criterion, device, batch_size=32,\n",
        "            is_distillation=True, teacher_model=teacher_model\n",
        "        )\n",
        "\n",
        "        print(f\"   Loss: {train_loss:.4f}\")\n",
        "        print_ram_usage()\n",
        "\n",
        "    print(f\"\\nüìä Validating...\")\n",
        "    val_criterion = nn.CrossEntropyLoss()\n",
        "    val_loss, val_acc = evaluate_on_file(\n",
        "        student_model, val_files[0], scaler, pca, label_encoder,\n",
        "        val_criterion, device, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_student_acc:\n",
        "        best_student_acc = val_acc\n",
        "        torch.save(student_model.state_dict(), 'student_model.pth')\n",
        "        print(f\"‚úÖ Saved best student: {val_acc:.4f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Student complete! Best: {best_student_acc:.4f}\")\n",
        "\n",
        "# ==========================================================\n",
        "# üìà FINAL EVALUATION\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìà Final Evaluation on Test Set...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "student_model.load_state_dict(torch.load('student_model.pth'))\n",
        "\n",
        "# Evaluate on first test file\n",
        "test_criterion = nn.CrossEntropyLoss()\n",
        "test_loss, test_acc = evaluate_on_file(\n",
        "    student_model, test_files[0], scaler, pca, label_encoder,\n",
        "    test_criterion, device, batch_size=32\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä FINAL RESULTS:\")\n",
        "print(f\"   Teacher Accuracy: {best_teacher_acc:.4f}\")\n",
        "print(f\"   Student Accuracy: {best_student_acc:.4f}\")\n",
        "print(f\"   Test Accuracy:    {test_acc:.4f}\")\n",
        "print(f\"   Compression:      {teacher_params/student_params:.1f}x\")\n",
        "\n",
        "# ==========================================================\n",
        "# üíæ SAVE EVERYTHING\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üíæ Saving Models...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "torch.save(teacher_model.state_dict(), 'teacher_final.pth')\n",
        "torch.save(student_model.state_dict(), 'student_final.pth')\n",
        "\n",
        "with open('preprocessing.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'scaler': scaler,\n",
        "        'pca': pca,\n",
        "        'label_encoder': label_encoder\n",
        "    }, f)\n",
        "\n",
        "metadata = {\n",
        "    'teacher_params': int(teacher_params),\n",
        "    'student_params': int(student_params),\n",
        "    'compression_ratio': float(teacher_params / student_params),\n",
        "    'n_classes': int(n_classes),\n",
        "    'teacher_accuracy': float(best_teacher_acc),\n",
        "    'student_accuracy': float(best_student_acc),\n",
        "    'test_accuracy': float(test_acc)\n",
        "}\n",
        "\n",
        "with open('metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ All models saved!\")\n",
        "print(f\"\\nüéâ SUCCESS!\")\n",
        "print(f\"   Compression: {teacher_params/student_params:.1f}x smaller\")\n",
        "print(f\"   Performance: {test_acc:.4f}\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXJjuunvGm6_",
        "outputId": "b33c5e8c-af35-435b-a8aa-5becb20cc251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üéÆ GPU Configuration\n",
            "================================================================================\n",
            "‚ö†Ô∏è  No GPU detected\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üì• Downloading Dataset...\n",
            "================================================================================\n",
            "Using Colab cache for faster access to the 'cic-iot-2023' dataset.\n",
            "üìÇ Found 169 CSV files\n",
            "üìä Split: 101 train, 34 val, 34 test files\n",
            "\n",
            "================================================================================\n",
            "üè∑Ô∏è  Fitting Preprocessing (Memory-Safe)...\n",
            "================================================================================\n",
            "Sampled 1000 rows from part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Sampled 1000 rows from part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Sampled 1000 rows from part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚úÖ Found 28 classes\n",
            "‚úÖ Scaler fitted\n",
            "‚úÖ PCA fitted with 20 components\n",
            "üíæ RAM Usage: 652 MB\n",
            "\n",
            "================================================================================\n",
            "üéì Training Teacher Model (Streaming)...\n",
            "================================================================================\n",
            "Teacher: 38,492 parameters\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 1/5\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "   Loss: 1.1907\n",
            "üíæ RAM Usage: 783 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "   Loss: 0.5831\n",
            "üíæ RAM Usage: 783 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.5345 | Val Acc: 0.7582\n",
            "‚úÖ Saved best teacher: 0.7582\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 2/5\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "   Loss: 0.5327\n",
            "üíæ RAM Usage: 786 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "   Loss: 0.5116\n",
            "üíæ RAM Usage: 785 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4812 | Val Acc: 0.7776\n",
            "‚úÖ Saved best teacher: 0.7776\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 3/5\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "   Loss: 0.5032\n",
            "üíæ RAM Usage: 787 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00005-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "   Loss: 0.4882\n",
            "üíæ RAM Usage: 785 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4769 | Val Acc: 0.7744\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 4/5\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00006-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "   Loss: 0.4850\n",
            "üíæ RAM Usage: 785 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00007-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "   Loss: 0.4871\n",
            "üíæ RAM Usage: 787 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4604 | Val Acc: 0.7848\n",
            "‚úÖ Saved best teacher: 0.7848\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 5/5\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00008-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "   Loss: 0.4724\n",
            "üíæ RAM Usage: 789 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00009-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "   Loss: 0.4765\n",
            "üíæ RAM Usage: 790 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4524 | Val Acc: 0.7828\n",
            "\n",
            "‚úÖ Teacher complete! Best: 0.7848\n",
            "\n",
            "================================================================================\n",
            "üéí Training Student with Knowledge Distillation...\n",
            "================================================================================\n",
            "Student: 6,140 parameters\n",
            "Compression: 6.3x\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 1/8\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "   Loss: 4.7349\n",
            "üíæ RAM Usage: 790 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "   Loss: 0.8628\n",
            "üíæ RAM Usage: 788 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.5509 | Val Acc: 0.7512\n",
            "‚úÖ Saved best student: 0.7512\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 2/8\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "   Loss: 0.5006\n",
            "üíæ RAM Usage: 790 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "   Loss: 0.3932\n",
            "üíæ RAM Usage: 789 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4825 | Val Acc: 0.7776\n",
            "‚úÖ Saved best student: 0.7776\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 3/8\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "   Loss: 0.3649\n",
            "üíæ RAM Usage: 789 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00005-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "   Loss: 0.3399\n",
            "üíæ RAM Usage: 789 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4750 | Val Acc: 0.7774\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 4/8\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00006-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "   Loss: 0.3131\n",
            "üíæ RAM Usage: 789 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00007-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "   Loss: 0.2963\n",
            "üíæ RAM Usage: 789 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4700 | Val Acc: 0.7834\n",
            "‚úÖ Saved best student: 0.7834\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 5/8\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00008-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "   Loss: 0.2812\n",
            "üíæ RAM Usage: 789 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00009-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "   Loss: 0.2838\n",
            "üíæ RAM Usage: 793 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4652 | Val Acc: 0.7842\n",
            "‚úÖ Saved best student: 0.7842\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 6/8\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00010-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "   Loss: 0.2730\n",
            "üíæ RAM Usage: 790 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00011-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "   Loss: 0.2640\n",
            "üíæ RAM Usage: 790 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4664 | Val Acc: 0.7828\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 7/8\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00012-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "   Loss: 0.2600\n",
            "üíæ RAM Usage: 793 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00013-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "   Loss: 0.2539\n",
            "üíæ RAM Usage: 793 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4644 | Val Acc: 0.7862\n",
            "‚úÖ Saved best student: 0.7862\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 8/8\n",
            "================================================================================\n",
            "\n",
            "üìÇ Training on file 1/2: part-00014-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "   Loss: 0.2479\n",
            "üíæ RAM Usage: 794 MB\n",
            "\n",
            "üìÇ Training on file 2/2: part-00015-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "   Loss: 0.2428\n",
            "üíæ RAM Usage: 794 MB\n",
            "\n",
            "üìä Validating...\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Val Loss: 0.4593 | Val Acc: 0.7874\n",
            "‚úÖ Saved best student: 0.7874\n",
            "\n",
            "‚úÖ Student complete! Best: 0.7874\n",
            "\n",
            "================================================================================\n",
            "üìà Final Evaluation on Test Set...\n",
            "================================================================================\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "Error processing chunk: y contains previously unseen labels: np.str_('Recon-PingSweep')\n",
            "\n",
            "üìä FINAL RESULTS:\n",
            "   Teacher Accuracy: 0.7848\n",
            "   Student Accuracy: 0.7874\n",
            "   Test Accuracy:    0.7878\n",
            "   Compression:      6.3x\n",
            "\n",
            "================================================================================\n",
            "üíæ Saving Models...\n",
            "================================================================================\n",
            "‚úÖ All models saved!\n",
            "\n",
            "üéâ SUCCESS!\n",
            "   Compression: 6.3x smaller\n",
            "   Performance: 0.7878\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Knowledge Distillation for IoT Intrusion Detection - Full File Processing\n",
        "- Reduced model sizes for memory efficiency\n",
        "- Process entire files at once (no chunking within files)\n",
        "- Handle all 169 files properly\n",
        "- Stream one file at a time to avoid RAM overflow\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import kagglehub\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==========================================================\n",
        "# üéÆ GPU CONFIGURATION\n",
        "# ==========================================================\n",
        "\n",
        "def setup_gpu():\n",
        "    \"\"\"Configure PyTorch to use GPU efficiently\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üéÆ GPU Configuration\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
        "        print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        print(\"‚úÖ cuDNN autotuner enabled\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"‚ö†Ô∏è  No GPU detected, running on CPU\")\n",
        "\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "    return device\n",
        "\n",
        "device = setup_gpu()\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ MEMORY MANAGEMENT\n",
        "# ==========================================================\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Aggressive memory cleanup\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def print_memory_stats():\n",
        "    \"\"\"Print RAM and GPU usage\"\"\"\n",
        "    try:\n",
        "        import psutil\n",
        "        process = psutil.Process()\n",
        "        ram_gb = process.memory_info().rss / 1e9\n",
        "        print(f\"üíæ RAM Usage: {ram_gb:.2f} GB\", end=\"\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_gb = torch.cuda.memory_allocated() / 1e9\n",
        "        print(f\" | GPU: {gpu_gb:.2f} GB\")\n",
        "    else:\n",
        "        print()\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ HELPER FUNCTIONS\n",
        "# ==========================================================\n",
        "\n",
        "def load_and_clean(path, label_col=None):\n",
        "    \"\"\"Load CSV and separate features from labels\"\"\"\n",
        "    df = pd.read_csv(path, low_memory=False)\n",
        "    df = df.dropna()\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    if label_col is None:\n",
        "        label_col = \"Label\" if \"Label\" in df.columns else df.columns[-1]\n",
        "\n",
        "    X = df.drop(columns=[label_col])\n",
        "    y = df[label_col]\n",
        "\n",
        "    del df\n",
        "    gc.collect()\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def encode_objects(X):\n",
        "    \"\"\"Encode categorical columns and convert to numpy array\"\"\"\n",
        "    for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "        try:\n",
        "            X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "        except:\n",
        "            X[col] = 0\n",
        "    return X.values.astype(np.float32)\n",
        "\n",
        "def load_and_process_file(filepath, scaler, pca, label_encoder):\n",
        "    \"\"\"Load and process a single file completely\"\"\"\n",
        "    try:\n",
        "        X, y = load_and_clean(filepath)\n",
        "        X = encode_objects(X)\n",
        "\n",
        "        X_scaled = scaler.transform(X)\n",
        "        X_reduced = pca.transform(X_scaled)\n",
        "        y_encoded = label_encoder.transform(y.astype(str))\n",
        "\n",
        "        del X, y, X_scaled\n",
        "        gc.collect()\n",
        "\n",
        "        return X_reduced, y_encoded\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {os.path.basename(filepath)}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# ==========================================================\n",
        "# üì¶ FULL FILE DATASET\n",
        "# ==========================================================\n",
        "\n",
        "class FullFileDataset(Dataset):\n",
        "    \"\"\"Dataset that holds entire file in memory\"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ==========================================================\n",
        "# üéì REDUCED PYTORCH MODELS\n",
        "# ==========================================================\n",
        "\n",
        "class TeacherLSTM(nn.Module):\n",
        "    \"\"\"Teacher Model - [128, 64] (Reduced from [256,128,64])\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes, dropout=0.3):\n",
        "        super(TeacherLSTM, self).__init__()\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_sizes[0], batch_first=True)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(hidden_sizes[0], hidden_sizes[1], batch_first=True)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_sizes[1], 64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, features)\n",
        "        out, _ = self.lstm1(x)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        out, _ = self.lstm2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        # Take last timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.relu1(self.fc1(out))\n",
        "        out = self.relu2(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class StudentLSTM(nn.Module):\n",
        "    \"\"\"Student Model - [32] (Reduced from [32,16])\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_classes, dropout=0.2):\n",
        "        super(StudentLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_size, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        # Take last timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# ==========================================================\n",
        "# üéì KNOWLEDGE DISTILLATION LOSS\n",
        "# ==========================================================\n",
        "\n",
        "class DistillationLoss(nn.Module):\n",
        "    \"\"\"Combined loss for knowledge distillation\"\"\"\n",
        "\n",
        "    def __init__(self, temperature=4.0, alpha=0.7):\n",
        "        super(DistillationLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.alpha = alpha\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "        self.kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, labels):\n",
        "        # Hard target loss\n",
        "        hard_loss = self.ce_loss(student_logits, labels)\n",
        "\n",
        "        # Soft target loss\n",
        "        soft_student = torch.log_softmax(student_logits / self.temperature, dim=1)\n",
        "        soft_teacher = torch.softmax(teacher_logits / self.temperature, dim=1)\n",
        "\n",
        "        soft_loss = self.kl_loss(soft_student, soft_teacher) * (self.temperature ** 2)\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "# ==========================================================\n",
        "# üèãÔ∏è TRAINING FUNCTIONS (FULL FILE AT ONCE)\n",
        "# ==========================================================\n",
        "\n",
        "def train_on_file(model, filepath, scaler, pca, label_encoder, optimizer,\n",
        "                  criterion, device, batch_size=512, is_distillation=False,\n",
        "                  teacher_model=None):\n",
        "    \"\"\"Train on entire file at once\"\"\"\n",
        "\n",
        "    # Load and process entire file\n",
        "    X_file, y_file = load_and_process_file(filepath, scaler, pca, label_encoder)\n",
        "\n",
        "    if X_file is None:\n",
        "        return 0\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = FullFileDataset(X_file, y_file)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    model.train()\n",
        "    if teacher_model is not None:\n",
        "        teacher_model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        X_batch = X_batch.unsqueeze(1).to(device)  # Add sequence dimension\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        if is_distillation and teacher_model is not None:\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(X_batch)\n",
        "            loss = criterion(outputs, teacher_outputs, y_batch)\n",
        "        else:\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * len(y_batch)\n",
        "        total_samples += len(y_batch)\n",
        "\n",
        "        del X_batch, y_batch, outputs\n",
        "        clear_memory()\n",
        "\n",
        "    # Clean up file data\n",
        "    del X_file, y_file, dataset, dataloader\n",
        "    clear_memory()\n",
        "\n",
        "    return total_loss / total_samples if total_samples > 0 else 0\n",
        "\n",
        "\n",
        "def evaluate_on_files(model, file_list, scaler, pca, label_encoder,\n",
        "                      criterion, device, batch_size=512):\n",
        "    \"\"\"Evaluate on multiple files\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for filepath in file_list:\n",
        "        X_file, y_file = load_and_process_file(filepath, scaler, pca, label_encoder)\n",
        "\n",
        "        if X_file is None:\n",
        "            continue\n",
        "\n",
        "        dataset = FullFileDataset(X_file, y_file)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in dataloader:\n",
        "                X_batch = X_batch.unsqueeze(1).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct += (predicted == y_batch).sum().item()\n",
        "                total_loss += loss.item() * len(y_batch)\n",
        "                total_samples += len(y_batch)\n",
        "\n",
        "                del X_batch, y_batch, outputs\n",
        "                clear_memory()\n",
        "\n",
        "        del X_file, y_file, dataset, dataloader\n",
        "        clear_memory()\n",
        "\n",
        "    accuracy = correct / total_samples if total_samples > 0 else 0\n",
        "    avg_loss = total_loss / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# ==========================================================\n",
        "# üìÇ DOWNLOAD & SPLIT DATASET (169 FILES)\n",
        "# ==========================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üì• Downloading CIC-IoT-2023 Dataset from Kaggle...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "dataset_dir = kagglehub.dataset_download(\"akashdogra/cic-iot-2023\")\n",
        "print(f\"‚úÖ Dataset downloaded to: {dataset_dir}\")\n",
        "\n",
        "csv_files = sorted([\n",
        "    os.path.join(dataset_dir, f)\n",
        "    for f in os.listdir(dataset_dir)\n",
        "    if f.endswith(\".csv\")\n",
        "])\n",
        "\n",
        "print(f\"üìÇ Found {len(csv_files)} CSV files.\")\n",
        "\n",
        "# 60-20-20 split\n",
        "n_files = len(csv_files)\n",
        "train_idx = int(n_files * 0.60)\n",
        "val_idx = int(n_files * 0.80)\n",
        "\n",
        "train_files = csv_files[:train_idx]\n",
        "val_files = csv_files[train_idx:val_idx]\n",
        "test_files = csv_files[val_idx:]\n",
        "\n",
        "print(f\"\\nüìä Dataset Split (from {n_files} files):\")\n",
        "print(f\"   Training:   {len(train_files)} files\")\n",
        "print(f\"   Validation: {len(val_files)} files\")\n",
        "print(f\"   Testing:    {len(test_files)} files\")\n",
        "\n",
        "# ==========================================================\n",
        "# üè∑Ô∏è FIT PREPROCESSING (SAMPLING FROM MULTIPLE FILES)\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üè∑Ô∏è  Fitting Preprocessing...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Collect labels and samples from first 5 files\n",
        "all_labels = []\n",
        "sample_data = []\n",
        "\n",
        "for i, filepath in enumerate(train_files[:5]):\n",
        "    print(f\"Sampling file {i+1}/5: {os.path.basename(filepath)}\")\n",
        "\n",
        "    # Load small sample\n",
        "    df = pd.read_csv(filepath, nrows=1000, low_memory=False)\n",
        "    df = df.dropna()\n",
        "\n",
        "    label_col = \"Label\" if \"Label\" in df.columns else df.columns[-1]\n",
        "    X = df.drop(columns=[label_col])\n",
        "    y = df[label_col]\n",
        "\n",
        "    all_labels.extend(list(y.astype(str)))\n",
        "\n",
        "    # Encode objects\n",
        "    for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "        try:\n",
        "            X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "        except:\n",
        "            X[col] = 0\n",
        "\n",
        "    sample_data.append(X.values.astype(np.float32))\n",
        "\n",
        "    del df, X, y\n",
        "    gc.collect()\n",
        "\n",
        "# Fit label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_labels)\n",
        "n_classes = len(label_encoder.classes_)\n",
        "\n",
        "print(f\"‚úÖ LabelEncoder fitted with {n_classes} classes\")\n",
        "\n",
        "# Fit scaler\n",
        "scaler = StandardScaler()\n",
        "for data in sample_data:\n",
        "    scaler.partial_fit(data)\n",
        "\n",
        "print(f\"‚úÖ Scaler fitted\")\n",
        "\n",
        "# Fit PCA\n",
        "n_features = sample_data[0].shape[1]\n",
        "n_components = min(30, n_features)\n",
        "\n",
        "pca = IncrementalPCA(n_components=n_components)\n",
        "for data in sample_data:\n",
        "    X_scaled = scaler.transform(data)\n",
        "    pca.partial_fit(X_scaled)\n",
        "\n",
        "print(f\"‚úÖ PCA fitted with {n_components} components (from {n_features} features)\")\n",
        "\n",
        "del all_labels, sample_data\n",
        "clear_memory()\n",
        "print_memory_stats()\n",
        "\n",
        "# ==========================================================\n",
        "# üéì STAGE 1: TRAIN TEACHER MODEL\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéì STAGE 1: Training Teacher Model\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize teacher model with REDUCED sizes\n",
        "teacher_model = TeacherLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_sizes=[128, 64],  # Reduced from [256, 128, 64]\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
        "print(f\"\\nüèóÔ∏è  Teacher Model: {teacher_params:,} parameters\")\n",
        "print(f\"   Architecture: Input({n_components}) ‚Üí LSTM(128) ‚Üí LSTM(64) ‚Üí FC(64) ‚Üí FC(32) ‚Üí Output({n_classes})\")\n",
        "\n",
        "# Optimizer and criterion\n",
        "teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
        "teacher_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "epochs_teacher = 3  # Train over all files 3 times\n",
        "batch_size = 512  # Large batch size allowed\n",
        "files_per_epoch = 5  # Process 5 files per epoch cycle\n",
        "\n",
        "best_teacher_acc = 0\n",
        "patience_counter = 0\n",
        "patience = 3\n",
        "\n",
        "print(\"\\nüöÄ Training Teacher Model...\")\n",
        "print(f\"   Batch Size: {batch_size}\")\n",
        "print(f\"   Files per Epoch Cycle: {files_per_epoch}\")\n",
        "\n",
        "for epoch in range(epochs_teacher):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TEACHER EPOCH {epoch+1}/{epochs_teacher}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Select rotating files\n",
        "    start_idx = (epoch * files_per_epoch) % len(train_files)\n",
        "    end_idx = min(start_idx + files_per_epoch, len(train_files))\n",
        "    selected_files = train_files[start_idx:end_idx]\n",
        "\n",
        "    if len(selected_files) < files_per_epoch and len(train_files) > files_per_epoch:\n",
        "        remaining = files_per_epoch - len(selected_files)\n",
        "        selected_files += train_files[:remaining]\n",
        "\n",
        "    print(f\"Training on {len(selected_files)} files (indices {start_idx} to {end_idx})\")\n",
        "\n",
        "    # Train on each file\n",
        "    epoch_losses = []\n",
        "    for i, filepath in enumerate(selected_files):\n",
        "        print(f\"\\n  üìÇ File {i+1}/{len(selected_files)}: {os.path.basename(filepath)}\")\n",
        "\n",
        "        train_loss = train_on_file(\n",
        "            teacher_model, filepath, scaler, pca, label_encoder,\n",
        "            teacher_optimizer, teacher_criterion, device, batch_size=batch_size\n",
        "        )\n",
        "\n",
        "        epoch_losses.append(train_loss)\n",
        "        print(f\"     Loss: {train_loss:.4f}\")\n",
        "        print_memory_stats()\n",
        "\n",
        "    avg_train_loss = np.mean(epoch_losses)\n",
        "\n",
        "    # Validate on subset of validation files\n",
        "    print(f\"\\n  üìä Validating...\")\n",
        "    val_loss, val_acc = evaluate_on_files(\n",
        "        teacher_model, val_files[:3], scaler, pca, label_encoder,\n",
        "        teacher_criterion, device, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  üìà Epoch Summary:\")\n",
        "    print(f\"     Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"     Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"     Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_teacher_acc:\n",
        "        best_teacher_acc = val_acc\n",
        "        torch.save(teacher_model.state_dict(), 'teacher_model.pth')\n",
        "        print(f\"  ‚úÖ Best teacher model saved! Val Acc: {val_acc:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    clear_memory()\n",
        "\n",
        "print(\"\\n‚úÖ Teacher Model Training Complete!\")\n",
        "print(f\"   Best Validation Accuracy: {best_teacher_acc:.4f}\")\n",
        "teacher_model.load_state_dict(torch.load('teacher_model.pth'))\n",
        "\n",
        "# ==========================================================\n",
        "# üéí STAGE 2: KNOWLEDGE DISTILLATION - TRAIN STUDENT\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéí STAGE 2: Knowledge Distillation - Training Student Model\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize student model with REDUCED size\n",
        "student_model = StudentLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_size=32,  # Single layer, reduced from [32, 16]\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "student_params = sum(p.numel() for p in student_model.parameters())\n",
        "reduction_ratio = teacher_params / student_params\n",
        "\n",
        "print(f\"\\nüèóÔ∏è  Student Model: {student_params:,} parameters\")\n",
        "print(f\"   Architecture: Input({n_components}) ‚Üí LSTM(32) ‚Üí FC(32) ‚Üí Output({n_classes})\")\n",
        "print(f\"\\nüìä Model Comparison:\")\n",
        "print(f\"   Teacher Parameters: {teacher_params:,}\")\n",
        "print(f\"   Student Parameters: {student_params:,}\")\n",
        "print(f\"   Size Reduction:     {reduction_ratio:.1f}x smaller\")\n",
        "\n",
        "# Optimizer and distillation loss\n",
        "student_optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
        "distillation_criterion = DistillationLoss(temperature=4.0, alpha=0.7)\n",
        "\n",
        "epochs_student = 4\n",
        "best_student_acc = 0\n",
        "patience_counter = 0\n",
        "\n",
        "print(f\"\\nüöÄ Training Student with Knowledge Distillation...\")\n",
        "print(f\"   Temperature: {distillation_criterion.temperature}\")\n",
        "print(f\"   Alpha (soft target weight): {distillation_criterion.alpha}\")\n",
        "print(f\"   Batch Size: {batch_size}\")\n",
        "\n",
        "for epoch in range(epochs_student):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"STUDENT EPOCH {epoch+1}/{epochs_student}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Select rotating files\n",
        "    start_idx = (epoch * files_per_epoch) % len(train_files)\n",
        "    end_idx = min(start_idx + files_per_epoch, len(train_files))\n",
        "    selected_files = train_files[start_idx:end_idx]\n",
        "\n",
        "    if len(selected_files) < files_per_epoch and len(train_files) > files_per_epoch:\n",
        "        remaining = files_per_epoch - len(selected_files)\n",
        "        selected_files += train_files[:remaining]\n",
        "\n",
        "    print(f\"Training on {len(selected_files)} files (indices {start_idx} to {end_idx})\")\n",
        "\n",
        "    # Train with distillation\n",
        "    epoch_losses = []\n",
        "    for i, filepath in enumerate(selected_files):\n",
        "        print(f\"\\n  üìÇ File {i+1}/{len(selected_files)}: {os.path.basename(filepath)}\")\n",
        "\n",
        "        train_loss = train_on_file(\n",
        "            student_model, filepath, scaler, pca, label_encoder,\n",
        "            student_optimizer, distillation_criterion, device,\n",
        "            batch_size=batch_size, is_distillation=True, teacher_model=teacher_model\n",
        "        )\n",
        "\n",
        "        epoch_losses.append(train_loss)\n",
        "        print(f\"     Loss: {train_loss:.4f}\")\n",
        "        print_memory_stats()\n",
        "\n",
        "    avg_train_loss = np.mean(epoch_losses)\n",
        "\n",
        "    # Validate\n",
        "    print(f\"\\n  üìä Validating...\")\n",
        "    val_criterion = nn.CrossEntropyLoss()\n",
        "    val_loss, val_acc = evaluate_on_files(\n",
        "        student_model, val_files[:3], scaler, pca, label_encoder,\n",
        "        val_criterion, device, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  üìà Epoch Summary:\")\n",
        "    print(f\"     Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"     Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"     Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_student_acc:\n",
        "        best_student_acc = val_acc\n",
        "        torch.save(student_model.state_dict(), 'student_model.pth')\n",
        "        print(f\"  ‚úÖ Best student model saved! Val Acc: {val_acc:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    clear_memory()\n",
        "\n",
        "print(\"\\n‚úÖ Student Model Training Complete!\")\n",
        "print(f\"   Best Validation Accuracy: {best_student_acc:.4f}\")\n",
        "student_model.load_state_dict(torch.load('student_model.pth'))\n",
        "\n",
        "# ==========================================================\n",
        "# üìà STAGE 3: FINAL EVALUATION\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìà STAGE 3: Final Evaluation on Test Set\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def evaluate_model_detailed(model, model_name, file_list):\n",
        "    \"\"\"Evaluate model on test set with detailed metrics\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model.eval()\n",
        "    y_true_all = []\n",
        "    y_pred_all = []\n",
        "\n",
        "    for i, filepath in enumerate(file_list):\n",
        "        print(f\"Processing file {i+1}/{len(file_list)}: {os.path.basename(filepath)}\")\n",
        "\n",
        "        X_file, y_file = load_and_process_file(filepath, scaler, pca, label_encoder)\n",
        "\n",
        "        if X_file is None:\n",
        "            continue\n",
        "\n",
        "        dataset = FullFileDataset(X_file, y_file)\n",
        "        dataloader = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in dataloader:\n",
        "                X_batch = X_batch.unsqueeze(1).to(device)\n",
        "\n",
        "                outputs = model(X_batch)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                y_true_all.extend(y_batch.numpy())\n",
        "                y_pred_all.extend(predicted.cpu().numpy())\n",
        "\n",
        "                del X_batch, outputs\n",
        "                clear_memory()\n",
        "\n",
        "        del X_file, y_file, dataset, dataloader\n",
        "        clear_memory()\n",
        "\n",
        "    y_true_all = np.array(y_true_all)\n",
        "    y_pred_all = np.array(y_pred_all)\n",
        "\n",
        "    accuracy = accuracy_score(y_true_all, y_pred_all)\n",
        "    precision = precision_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"\\nüìä {model_name} Performance:\")\n",
        "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"   Precision: {precision:.4f}\")\n",
        "    print(f\"   Recall:    {recall:.4f}\")\n",
        "    print(f\"   F1-Score:  {f1:.4f}\")\n",
        "\n",
        "    return y_true_all, y_pred_all, accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate both models\n",
        "teacher_results = evaluate_model_detailed(teacher_model, \"TEACHER MODEL\", test_files)\n",
        "student_results = evaluate_model_detailed(student_model, \"STUDENT MODEL (Distilled)\", test_files)\n",
        "\n",
        "# ==========================================================\n",
        "# üìä GENERATE REPORTS\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä Generating Final Report...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "y_true, y_pred, s_acc, s_prec, s_rec, s_f1 = student_results\n",
        "_, _, t_acc, t_prec, t_rec, t_f1 = teacher_results\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Student Model Confusion Matrix (Knowledge Distillation)', fontsize=16, pad=20)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
        "plt.yticks(rotation=0, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.savefig('student_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úÖ Confusion matrix saved as 'student_confusion_matrix.png'\")\n",
        "\n",
        "# Performance comparison\n",
        "performance_retention = (s_acc / t_acc) * 100 if t_acc > 0 else 0\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä FINAL COMPARISON: TEACHER vs STUDENT\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Metric':<15} {'Teacher':<15} {'Student':<15} {'Difference':<15}\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Accuracy':<15} {t_acc:<15.4f} {s_acc:<15.4f} {(s_acc-t_acc):<15.4f}\")\n",
        "print(f\"{'Precision':<15} {t_prec:<15.4f} {s_prec:<15.4f} {(s_prec-t_prec):<15.4f}\")\n",
        "print(f\"{'Recall':<15} {t_rec:<15.4f} {s_rec:<15.4f} {(s_rec-t_rec):<15.4f}\")\n",
        "print(f\"{'F1-Score':<15} {t_f1:<15.4f} {s_f1:<15.4f} {(s_f1-t_f1):<15.4f}\")\n",
        "print(f\"{'Parameters':<15} {teacher_params:<15,} {student_params:<15,} {'-':<15}\")\n",
        "print(f\"{'Model Size':<15} {'1.0x':<15} {f'{1/reduction_ratio:.2f}x':<15} {f'{reduction_ratio:.1f}x smaller':<15}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nüéØ Performance Retention: {performance_retention:.2f}%\")\n",
        "print(f\"üéØ Model Size Reduction: {reduction_ratio:.1f}x smaller\")\n",
        "print(f\"üéØ Parameter Reduction: {((teacher_params - student_params) / teacher_params * 100):.1f}% fewer parameters\")\n",
        "\n",
        "# ==========================================================\n",
        "# üíæ SAVE MODELS AND PREPROCESSING OBJECTS\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üíæ Saving Models and Preprocessing Objects\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save PyTorch models\n",
        "torch.save({\n",
        "    'model_state_dict': teacher_model.state_dict(),\n",
        "    'input_size': n_components,\n",
        "    'hidden_sizes': [128, 64],\n",
        "    'num_classes': n_classes,\n",
        "    'accuracy': t_acc,\n",
        "    'params': teacher_params\n",
        "}, 'teacher_model_complete.pth')\n",
        "print(\"‚úÖ Saved: teacher_model_complete.pth\")\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': student_model.state_dict(),\n",
        "    'input_size': n_components,\n",
        "    'hidden_size': 32,\n",
        "    'num_classes': n_classes,\n",
        "    'accuracy': s_acc,\n",
        "    'params': student_params\n",
        "}, 'student_model_complete.pth')\n",
        "print(\"‚úÖ Saved: student_model_complete.pth\")\n",
        "\n",
        "# Save preprocessing objects\n",
        "preprocessing_objects = {\n",
        "    'scaler': scaler,\n",
        "    'pca': pca,\n",
        "    'label_encoder': label_encoder\n",
        "}\n",
        "\n",
        "with open('preprocessing.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessing_objects, f)\n",
        "print(\"‚úÖ Saved: preprocessing.pkl\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'n_classes': int(n_classes),\n",
        "    'n_features': int(n_features),\n",
        "    'n_components': int(n_components),\n",
        "    'teacher_params': int(teacher_params),\n",
        "    'student_params': int(student_params),\n",
        "    'teacher_accuracy': float(t_acc),\n",
        "    'student_accuracy': float(s_acc),\n",
        "    'size_reduction': float(reduction_ratio),\n",
        "    'performance_retention': float(performance_retention),\n",
        "    'total_files': len(csv_files),\n",
        "    'train_files': len(train_files),\n",
        "    'val_files': len(val_files),\n",
        "    'test_files': len(test_files),\n",
        "    'classes': label_encoder.classes_.tolist()\n",
        "}\n",
        "\n",
        "with open('model_metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "print(\"‚úÖ Saved: model_metadata.json\")\n",
        "\n",
        "# Create summary\n",
        "with open('model_summary.txt', 'w') as f:\n",
        "    f.write(\"=\" * 80 + \"\\n\")\n",
        "    f.write(\"KNOWLEDGE DISTILLATION - PYTORCH MODEL SUMMARY\\n\")\n",
        "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"DATASET INFORMATION:\\n\")\n",
        "    f.write(f\"  Total Files: {len(csv_files)}\\n\")\n",
        "    f.write(f\"  Training Files: {len(train_files)}\\n\")\n",
        "    f.write(f\"  Validation Files: {len(val_files)}\\n\")\n",
        "    f.write(f\"  Test Files: {len(test_files)}\\n\\n\")\n",
        "\n",
        "    f.write(\"TEACHER MODEL:\\n\")\n",
        "    f.write(f\"  Architecture: LSTM [128, 64]\\n\")\n",
        "    f.write(f\"  Parameters: {teacher_params:,}\\n\")\n",
        "    f.write(f\"  Accuracy: {t_acc:.4f}\\n\")\n",
        "    f.write(f\"  Precision: {t_prec:.4f}\\n\")\n",
        "    f.write(f\"  Recall: {t_rec:.4f}\\n\")\n",
        "    f.write(f\"  F1-Score: {t_f1:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"STUDENT MODEL (DISTILLED):\\n\")\n",
        "    f.write(f\"  Architecture: LSTM [32]\\n\")\n",
        "    f.write(f\"  Parameters: {student_params:,}\\n\")\n",
        "    f.write(f\"  Accuracy: {s_acc:.4f}\\n\")\n",
        "    f.write(f\"  Precision: {s_prec:.4f}\\n\")\n",
        "    f.write(f\"  Recall: {s_rec:.4f}\\n\")\n",
        "    f.write(f\"  F1-Score: {s_f1:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"COMPRESSION METRICS:\\n\")\n",
        "    f.write(f\"  Size Reduction: {reduction_ratio:.1f}x smaller\\n\")\n",
        "    f.write(f\"  Performance Retention: {performance_retention:.2f}%\\n\")\n",
        "    f.write(f\"  Parameter Reduction: {((teacher_params - student_params) / teacher_params * 100):.1f}%\\n\\n\")\n",
        "\n",
        "    f.write(\"FILES GENERATED:\\n\")\n",
        "    f.write(\"  - teacher_model_complete.pth (Teacher model with metadata)\\n\")\n",
        "    f.write(\"  - student_model_complete.pth (Student model with metadata)\\n\")\n",
        "    f.write(\"  - preprocessing.pkl (Scaler, PCA, Label Encoder)\\n\")\n",
        "    f.write(\"  - model_metadata.json (Model specifications)\\n\")\n",
        "    f.write(\"  - student_confusion_matrix.png (Confusion matrix visualization)\\n\")\n",
        "\n",
        "print(\"‚úÖ Saved: model_summary.txt\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéâ KNOWLEDGE DISTILLATION COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n‚ú® Successfully processed all {len(csv_files)} files!\")\n",
        "print(f\"‚ú® Teacher Model: {teacher_params:,} parameters ‚Üí Accuracy: {t_acc:.4f}\")\n",
        "print(f\"‚ú® Student Model: {student_params:,} parameters ‚Üí Accuracy: {s_acc:.4f}\")\n",
        "print(f\"‚ú® Compression: {reduction_ratio:.1f}x smaller with {performance_retention:.1f}% performance retention\")\n",
        "print(\"\\nüì¶ All models saved and ready for deployment!\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "obn1mJ5ULWlC",
        "outputId": "4195af0d-24e8-47ba-d544-f904c9b2c6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üéÆ GPU Configuration\n",
            "================================================================================\n",
            "‚úÖ GPU detected: Tesla T4\n",
            "‚úÖ CUDA Version: 12.6\n",
            "‚úÖ GPU Memory: 15.83 GB\n",
            "‚úÖ cuDNN autotuner enabled\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üì• Downloading CIC-IoT-2023 Dataset from Kaggle...\n",
            "================================================================================\n",
            "Using Colab cache for faster access to the 'cic-iot-2023' dataset.\n",
            "‚úÖ Dataset downloaded to: /kaggle/input/cic-iot-2023\n",
            "üìÇ Found 169 CSV files.\n",
            "\n",
            "üìä Dataset Split (from 169 files):\n",
            "   Training:   101 files\n",
            "   Validation: 34 files\n",
            "   Testing:    34 files\n",
            "\n",
            "================================================================================\n",
            "üè∑Ô∏è  Fitting Preprocessing...\n",
            "================================================================================\n",
            "Sampling file 1/5: part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Sampling file 2/5: part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Sampling file 3/5: part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Sampling file 4/5: part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Sampling file 5/5: part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚úÖ LabelEncoder fitted with 29 classes\n",
            "‚úÖ Scaler fitted\n",
            "‚úÖ PCA fitted with 30 components (from 46 features)\n",
            "üíæ RAM Usage: 0.72 GB | GPU: 0.00 GB\n",
            "\n",
            "================================================================================\n",
            "üéì STAGE 1: Training Teacher Model\n",
            "================================================================================\n",
            "\n",
            "üèóÔ∏è  Teacher Model: 138,781 parameters\n",
            "   Architecture: Input(30) ‚Üí LSTM(128) ‚Üí LSTM(64) ‚Üí FC(64) ‚Üí FC(32) ‚Üí Output(29)\n",
            "\n",
            "üöÄ Training Teacher Model...\n",
            "   Batch Size: 512\n",
            "   Files per Epoch Cycle: 5\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 1/3\n",
            "================================================================================\n",
            "Training on 5 files (indices 0 to 5)\n",
            "\n",
            "  üìÇ File 1/5: part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 0.98 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 2/5: part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 0.99 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 3/5: part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 0.99 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 4/5: part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.02 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 5/5: part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.02 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìä Validating...\n",
            "‚ùå Error processing part-00101-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "‚ùå Error processing part-00102-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "‚ùå Error processing part-00103-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 0.0000\n",
            "     Val Loss: 0.0000\n",
            "     Val Accuracy: 0.0000\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 2/3\n",
            "================================================================================\n",
            "Training on 5 files (indices 5 to 10)\n",
            "\n",
            "  üìÇ File 1/5: part-00005-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00005-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.02 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 2/5: part-00006-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00006-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.02 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 3/5: part-00007-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00007-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.02 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 4/5: part-00008-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00008-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.02 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 5/5: part-00009-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00009-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('Backdoor_Malware')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.02 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìä Validating...\n",
            "‚ùå Error processing part-00101-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "‚ùå Error processing part-00102-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "‚ùå Error processing part-00103-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 0.0000\n",
            "     Val Loss: 0.0000\n",
            "     Val Accuracy: 0.0000\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 3/3\n",
            "================================================================================\n",
            "Training on 5 files (indices 10 to 15)\n",
            "\n",
            "  üìÇ File 1/5: part-00010-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00010-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.03 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 2/5: part-00011-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00011-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.02 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 3/5: part-00012-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00012-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('CommandInjection')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.03 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 4/5: part-00013-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00013-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('SqlInjection')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.03 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìÇ File 5/5: part-00014-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "‚ùå Error processing part-00014-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "     Loss: 0.0000\n",
            "üíæ RAM Usage: 1.02 GB | GPU: 0.00 GB\n",
            "\n",
            "  üìä Validating...\n",
            "‚ùå Error processing part-00101-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "‚ùå Error processing part-00102-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('Uploading_Attack')\n",
            "‚ùå Error processing part-00103-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv: y contains previously unseen labels: np.str_('BrowserHijacking')\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 0.0000\n",
            "     Val Loss: 0.0000\n",
            "     Val Accuracy: 0.0000\n",
            "\n",
            "‚ö†Ô∏è  Early stopping triggered at epoch 3\n",
            "\n",
            "‚úÖ Teacher Model Training Complete!\n",
            "   Best Validation Accuracy: 0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'teacher_model.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-709598192.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n‚úÖ Teacher Model Training Complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Best Validation Accuracy: {best_teacher_acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m \u001b[0mteacher_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'teacher_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;31m# ==========================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'teacher_model.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Knowledge Distillation for IoT Intrusion Detection - Full File Processing\n",
        "- Reduced model sizes for memory efficiency\n",
        "- Process entire files at once (no chunking within files)\n",
        "- Handle all 169 files properly\n",
        "- Stream one file at a time to avoid RAM overflow\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import kagglehub\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==========================================================\n",
        "# üéÆ GPU CONFIGURATION\n",
        "# ==========================================================\n",
        "\n",
        "def setup_gpu():\n",
        "    \"\"\"Configure PyTorch to use GPU efficiently\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üéÆ GPU Configuration\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
        "        print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        print(\"‚úÖ cuDNN autotuner enabled\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"‚ö†Ô∏è  No GPU detected, running on CPU\")\n",
        "\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "    return device\n",
        "\n",
        "device = setup_gpu()\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ MEMORY MANAGEMENT\n",
        "# ==========================================================\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Aggressive memory cleanup\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def print_memory_stats():\n",
        "    \"\"\"Print RAM and GPU usage\"\"\"\n",
        "    try:\n",
        "        import psutil\n",
        "        process = psutil.Process()\n",
        "        ram_gb = process.memory_info().rss / 1e9\n",
        "        print(f\"üíæ RAM Usage: {ram_gb:.2f} GB\", end=\"\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_gb = torch.cuda.memory_allocated() / 1e9\n",
        "        print(f\" | GPU: {gpu_gb:.2f} GB\")\n",
        "    else:\n",
        "        print()\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ HELPER FUNCTIONS\n",
        "# ==========================================================\n",
        "\n",
        "def load_and_clean(path, label_col=None):\n",
        "    \"\"\"Load CSV and separate features from labels\"\"\"\n",
        "    df = pd.read_csv(path, low_memory=False)\n",
        "    df = df.dropna()\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    if label_col is None:\n",
        "        label_col = \"Label\" if \"Label\" in df.columns else df.columns[-1]\n",
        "\n",
        "    X = df.drop(columns=[label_col])\n",
        "    y = df[label_col]\n",
        "\n",
        "    del df\n",
        "    gc.collect()\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def encode_objects(X):\n",
        "    \"\"\"Encode categorical columns and convert to numpy array\"\"\"\n",
        "    for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "        try:\n",
        "            X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "        except:\n",
        "            X[col] = 0\n",
        "    return X.values.astype(np.float32)\n",
        "\n",
        "def load_and_process_file(filepath, scaler, pca, label_encoder):\n",
        "    \"\"\"Load and process a single file completely\"\"\"\n",
        "    try:\n",
        "        X, y = load_and_clean(filepath)\n",
        "        X = encode_objects(X)\n",
        "\n",
        "        X_scaled = scaler.transform(X)\n",
        "        X_reduced = pca.transform(X_scaled)\n",
        "        y_encoded = label_encoder.transform(y.astype(str))\n",
        "\n",
        "        del X, y, X_scaled\n",
        "        gc.collect()\n",
        "\n",
        "        return X_reduced, y_encoded\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {os.path.basename(filepath)}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# ==========================================================\n",
        "# üì¶ FULL FILE DATASET\n",
        "# ==========================================================\n",
        "\n",
        "class FullFileDataset(Dataset):\n",
        "    \"\"\"Dataset that holds entire file in memory\"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ==========================================================\n",
        "# üéì REDUCED PYTORCH MODELS\n",
        "# ==========================================================\n",
        "\n",
        "class TeacherLSTM(nn.Module):\n",
        "    \"\"\"Teacher Model - [128, 64] (Reduced from [256,128,64])\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes, dropout=0.3):\n",
        "        super(TeacherLSTM, self).__init__()\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_sizes[0], batch_first=True)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(hidden_sizes[0], hidden_sizes[1], batch_first=True)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_sizes[1], 64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, features)\n",
        "        out, _ = self.lstm1(x)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        out, _ = self.lstm2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        # Take last timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.relu1(self.fc1(out))\n",
        "        out = self.relu2(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class StudentLSTM(nn.Module):\n",
        "    \"\"\"Student Model - [32] (Reduced from [32,16])\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_classes, dropout=0.2):\n",
        "        super(StudentLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_size, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        # Take last timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# ==========================================================\n",
        "# üéì KNOWLEDGE DISTILLATION LOSS\n",
        "# ==========================================================\n",
        "\n",
        "class DistillationLoss(nn.Module):\n",
        "    \"\"\"Combined loss for knowledge distillation\"\"\"\n",
        "\n",
        "    def __init__(self, temperature=4.0, alpha=0.7):\n",
        "        super(DistillationLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.alpha = alpha\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "        self.kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, labels):\n",
        "        # Hard target loss\n",
        "        hard_loss = self.ce_loss(student_logits, labels)\n",
        "\n",
        "        # Soft target loss\n",
        "        soft_student = torch.log_softmax(student_logits / self.temperature, dim=1)\n",
        "        soft_teacher = torch.softmax(teacher_logits / self.temperature, dim=1)\n",
        "\n",
        "        soft_loss = self.kl_loss(soft_student, soft_teacher) * (self.temperature ** 2)\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "# ==========================================================\n",
        "# üèãÔ∏è TRAINING FUNCTIONS (FULL FILE AT ONCE)\n",
        "# ==========================================================\n",
        "\n",
        "def train_on_file(model, filepath, scaler, pca, label_encoder, optimizer,\n",
        "                  criterion, device, batch_size=512, is_distillation=False,\n",
        "                  teacher_model=None):\n",
        "    \"\"\"Train on entire file at once\"\"\"\n",
        "\n",
        "    # Load and process entire file\n",
        "    X_file, y_file = load_and_process_file(filepath, scaler, pca, label_encoder)\n",
        "\n",
        "    if X_file is None:\n",
        "        return 0\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = FullFileDataset(X_file, y_file)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    model.train()\n",
        "    if teacher_model is not None:\n",
        "        teacher_model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        X_batch = X_batch.unsqueeze(1).to(device)  # Add sequence dimension\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        if is_distillation and teacher_model is not None:\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(X_batch)\n",
        "            loss = criterion(outputs, teacher_outputs, y_batch)\n",
        "        else:\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * len(y_batch)\n",
        "        total_samples += len(y_batch)\n",
        "\n",
        "        del X_batch, y_batch, outputs\n",
        "        clear_memory()\n",
        "\n",
        "    # Clean up file data\n",
        "    del X_file, y_file, dataset, dataloader\n",
        "    clear_memory()\n",
        "\n",
        "    return total_loss / total_samples if total_samples > 0 else 0\n",
        "\n",
        "\n",
        "def evaluate_on_files(model, file_list, scaler, pca, label_encoder,\n",
        "                      criterion, device, batch_size=512):\n",
        "    \"\"\"Evaluate on multiple files\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for filepath in file_list:\n",
        "        X_file, y_file = load_and_process_file(filepath, scaler, pca, label_encoder)\n",
        "\n",
        "        if X_file is None:\n",
        "            continue\n",
        "\n",
        "        dataset = FullFileDataset(X_file, y_file)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in dataloader:\n",
        "                X_batch = X_batch.unsqueeze(1).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct += (predicted == y_batch).sum().item()\n",
        "                total_loss += loss.item() * len(y_batch)\n",
        "                total_samples += len(y_batch)\n",
        "\n",
        "                del X_batch, y_batch, outputs\n",
        "                clear_memory()\n",
        "\n",
        "        del X_file, y_file, dataset, dataloader\n",
        "        clear_memory()\n",
        "\n",
        "    accuracy = correct / total_samples if total_samples > 0 else 0\n",
        "    avg_loss = total_loss / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# ==========================================================\n",
        "# üìÇ DOWNLOAD & SPLIT DATASET (169 FILES)\n",
        "# ==========================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üì• Downloading CIC-IoT-2023 Dataset from Kaggle...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "dataset_dir = kagglehub.dataset_download(\"akashdogra/cic-iot-2023\")\n",
        "print(f\"‚úÖ Dataset downloaded to: {dataset_dir}\")\n",
        "\n",
        "csv_files = sorted([\n",
        "    os.path.join(dataset_dir, f)\n",
        "    for f in os.listdir(dataset_dir)\n",
        "    if f.endswith(\".csv\")\n",
        "])\n",
        "\n",
        "print(f\"üìÇ Found {len(csv_files)} CSV files.\")\n",
        "\n",
        "# 60-20-20 split\n",
        "n_files = len(csv_files)\n",
        "train_idx = int(n_files * 0.60)\n",
        "val_idx = int(n_files * 0.80)\n",
        "\n",
        "train_files = csv_files[:train_idx]\n",
        "val_files = csv_files[train_idx:val_idx]\n",
        "test_files = csv_files[val_idx:]\n",
        "\n",
        "print(f\"\\nüìä Dataset Split (from {n_files} files):\")\n",
        "print(f\"   Training:   {len(train_files)} files\")\n",
        "print(f\"   Validation: {len(val_files)} files\")\n",
        "print(f\"   Testing:    {len(test_files)} files\")\n",
        "\n",
        "# ==========================================================\n",
        "# üè∑Ô∏è FIT PREPROCESSING (SCAN ALL TRAINING FILES FOR LABELS)\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üè∑Ô∏è  Fitting Preprocessing - Scanning ALL Training Files...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# CRITICAL FIX: Scan ALL training files to collect ALL unique labels\n",
        "all_labels = set()\n",
        "sample_data = []\n",
        "\n",
        "print(f\"Scanning {len(train_files)} training files for all unique labels...\")\n",
        "for i, filepath in enumerate(train_files):\n",
        "    try:\n",
        "        # Read only the label column to save memory\n",
        "        df = pd.read_csv(filepath, low_memory=False)\n",
        "        label_col = \"Label\" if \"Label\" in df.columns else df.columns[-1]\n",
        "\n",
        "        # Collect all unique labels from this file\n",
        "        unique_labels = df[label_col].dropna().astype(str).unique()\n",
        "        all_labels.update(unique_labels)\n",
        "\n",
        "        print(f\"  File {i+1}/{len(train_files)}: {os.path.basename(filepath)} - Found {len(unique_labels)} unique labels (Total: {len(all_labels)})\")\n",
        "\n",
        "        # Sample features from first 10 files only\n",
        "        if i < 10:\n",
        "            df_sample = df.head(1000).dropna()\n",
        "            X = df_sample.drop(columns=[label_col])\n",
        "\n",
        "            # Encode objects\n",
        "            for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "                try:\n",
        "                    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "                except:\n",
        "                    X[col] = 0\n",
        "\n",
        "            sample_data.append(X.values.astype(np.float32))\n",
        "\n",
        "        del df\n",
        "        gc.collect()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è  Error reading {os.path.basename(filepath)}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Convert set to sorted list for consistent encoding\n",
        "all_labels = sorted(list(all_labels))\n",
        "\n",
        "# Fit label encoder with ALL labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_labels)\n",
        "n_classes = len(label_encoder.classes_)\n",
        "\n",
        "print(f\"\\n‚úÖ LabelEncoder fitted with {n_classes} classes\")\n",
        "print(f\"   Classes found: {', '.join(label_encoder.classes_[:10])}{'...' if n_classes > 10 else ''}\")\n",
        "\n",
        "# Fit scaler\n",
        "scaler = StandardScaler()\n",
        "for data in sample_data:\n",
        "    scaler.partial_fit(data)\n",
        "\n",
        "print(f\"‚úÖ Scaler fitted on {len(sample_data)} file samples\")\n",
        "\n",
        "# Fit PCA\n",
        "n_features = sample_data[0].shape[1]\n",
        "n_components = min(30, n_features)\n",
        "\n",
        "pca = IncrementalPCA(n_components=n_components)\n",
        "for data in sample_data:\n",
        "    X_scaled = scaler.transform(data)\n",
        "    pca.partial_fit(X_scaled)\n",
        "\n",
        "print(f\"‚úÖ PCA fitted with {n_components} components (from {n_features} features)\")\n",
        "\n",
        "del all_labels, sample_data\n",
        "clear_memory()\n",
        "print_memory_stats()\n",
        "\n",
        "# ==========================================================\n",
        "# üéì STAGE 1: TRAIN TEACHER MODEL\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéì STAGE 1: Training Teacher Model\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize teacher model with REDUCED sizes\n",
        "teacher_model = TeacherLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_sizes=[128, 64],  # Reduced from [256, 128, 64]\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
        "print(f\"\\nüèóÔ∏è  Teacher Model: {teacher_params:,} parameters\")\n",
        "print(f\"   Architecture: Input({n_components}) ‚Üí LSTM(128) ‚Üí LSTM(64) ‚Üí FC(64) ‚Üí FC(32) ‚Üí Output({n_classes})\")\n",
        "\n",
        "# Optimizer and criterion\n",
        "teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
        "teacher_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "epochs_teacher = 3  # Train over all files 3 times\n",
        "batch_size = 512  # Large batch size allowed\n",
        "files_per_epoch = 20  # Process 20 files per epoch (will cycle through all 101 training files)\n",
        "\n",
        "best_teacher_acc = 0\n",
        "patience_counter = 0\n",
        "patience = 5  # Increased patience\n",
        "\n",
        "print(\"\\nüöÄ Training Teacher Model...\")\n",
        "print(f\"   Batch Size: {batch_size}\")\n",
        "print(f\"   Files per Epoch Cycle: {files_per_epoch}\")\n",
        "print(f\"   Total Training Files: {len(train_files)}\")\n",
        "print(f\"   Epochs: {epochs_teacher}\")\n",
        "\n",
        "for epoch in range(epochs_teacher):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TEACHER EPOCH {epoch+1}/{epochs_teacher}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Select rotating files\n",
        "    start_idx = (epoch * files_per_epoch) % len(train_files)\n",
        "    end_idx = min(start_idx + files_per_epoch, len(train_files))\n",
        "    selected_files = train_files[start_idx:end_idx]\n",
        "\n",
        "    if len(selected_files) < files_per_epoch and len(train_files) > files_per_epoch:\n",
        "        remaining = files_per_epoch - len(selected_files)\n",
        "        selected_files += train_files[:remaining]\n",
        "\n",
        "    print(f\"Training on {len(selected_files)} files (indices {start_idx} to {end_idx})\")\n",
        "\n",
        "    # Train on each file\n",
        "    epoch_losses = []\n",
        "    for i, filepath in enumerate(selected_files):\n",
        "        print(f\"\\n  üìÇ File {i+1}/{len(selected_files)}: {os.path.basename(filepath)}\")\n",
        "\n",
        "        train_loss = train_on_file(\n",
        "            teacher_model, filepath, scaler, pca, label_encoder,\n",
        "            teacher_optimizer, teacher_criterion, device, batch_size=batch_size\n",
        "        )\n",
        "\n",
        "        epoch_losses.append(train_loss)\n",
        "        print(f\"     Loss: {train_loss:.4f}\")\n",
        "        print_memory_stats()\n",
        "\n",
        "    avg_train_loss = np.mean(epoch_losses)\n",
        "\n",
        "    # Validate on subset of validation files\n",
        "    print(f\"\\n  üìä Validating...\")\n",
        "    val_loss, val_acc = evaluate_on_files(\n",
        "        teacher_model, val_files[:5], scaler, pca, label_encoder,\n",
        "        teacher_criterion, device, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  üìà Epoch Summary:\")\n",
        "    print(f\"     Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"     Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"     Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_teacher_acc:\n",
        "        best_teacher_acc = val_acc\n",
        "        torch.save(teacher_model.state_dict(), 'teacher_model.pth')\n",
        "        print(f\"  ‚úÖ Best teacher model saved! Val Acc: {val_acc:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    clear_memory()\n",
        "\n",
        "print(\"\\n‚úÖ Teacher Model Training Complete!\")\n",
        "print(f\"   Best Validation Accuracy: {best_teacher_acc:.4f}\")\n",
        "\n",
        "# Load best model if it was saved, otherwise keep current\n",
        "if os.path.exists('teacher_model.pth'):\n",
        "    teacher_model.load_state_dict(torch.load('teacher_model.pth'))\n",
        "    print(\"   Loaded best teacher model from disk\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  No saved model found, using final epoch weights\")\n",
        "\n",
        "# ==========================================================\n",
        "# üéí STAGE 2: KNOWLEDGE DISTILLATION - TRAIN STUDENT\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéí STAGE 2: Knowledge Distillation - Training Student Model\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize student model with REDUCED size\n",
        "student_model = StudentLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_size=32,  # Single layer, reduced from [32, 16]\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "student_params = sum(p.numel() for p in student_model.parameters())\n",
        "reduction_ratio = teacher_params / student_params\n",
        "\n",
        "print(f\"\\nüèóÔ∏è  Student Model: {student_params:,} parameters\")\n",
        "print(f\"   Architecture: Input({n_components}) ‚Üí LSTM(32) ‚Üí FC(32) ‚Üí Output({n_classes})\")\n",
        "print(f\"\\nüìä Model Comparison:\")\n",
        "print(f\"   Teacher Parameters: {teacher_params:,}\")\n",
        "print(f\"   Student Parameters: {student_params:,}\")\n",
        "print(f\"   Size Reduction:     {reduction_ratio:.1f}x smaller\")\n",
        "\n",
        "# Optimizer and distillation loss\n",
        "student_optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
        "distillation_criterion = DistillationLoss(temperature=4.0, alpha=0.7)\n",
        "\n",
        "epochs_student = 4\n",
        "best_student_acc = 0\n",
        "patience_counter = 0\n",
        "\n",
        "print(f\"\\nüöÄ Training Student with Knowledge Distillation...\")\n",
        "print(f\"   Temperature: {distillation_criterion.temperature}\")\n",
        "print(f\"   Alpha (soft target weight): {distillation_criterion.alpha}\")\n",
        "print(f\"   Batch Size: {batch_size}\")\n",
        "print(f\"   Files per Epoch: {files_per_epoch}\")\n",
        "\n",
        "for epoch in range(epochs_student):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"STUDENT EPOCH {epoch+1}/{epochs_student}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Select rotating files\n",
        "    start_idx = (epoch * files_per_epoch) % len(train_files)\n",
        "    end_idx = min(start_idx + files_per_epoch, len(train_files))\n",
        "    selected_files = train_files[start_idx:end_idx]\n",
        "\n",
        "    if len(selected_files) < files_per_epoch and len(train_files) > files_per_epoch:\n",
        "        remaining = files_per_epoch - len(selected_files)\n",
        "        selected_files += train_files[:remaining]\n",
        "\n",
        "    print(f\"Training on {len(selected_files)} files (indices {start_idx} to {end_idx})\")\n",
        "\n",
        "    # Train with distillation\n",
        "    epoch_losses = []\n",
        "    for i, filepath in enumerate(selected_files):\n",
        "        print(f\"\\n  üìÇ File {i+1}/{len(selected_files)}: {os.path.basename(filepath)}\")\n",
        "\n",
        "        train_loss = train_on_file(\n",
        "            student_model, filepath, scaler, pca, label_encoder,\n",
        "            student_optimizer, distillation_criterion, device,\n",
        "            batch_size=batch_size, is_distillation=True, teacher_model=teacher_model\n",
        "        )\n",
        "\n",
        "        epoch_losses.append(train_loss)\n",
        "        print(f\"     Loss: {train_loss:.4f}\")\n",
        "        print_memory_stats()\n",
        "\n",
        "    avg_train_loss = np.mean(epoch_losses)\n",
        "\n",
        "    # Validate\n",
        "    print(f\"\\n  üìä Validating...\")\n",
        "    val_criterion = nn.CrossEntropyLoss()\n",
        "    val_loss, val_acc = evaluate_on_files(\n",
        "        student_model, val_files[:5], scaler, pca, label_encoder,\n",
        "        val_criterion, device, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  üìà Epoch Summary:\")\n",
        "    print(f\"     Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"     Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"     Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_student_acc:\n",
        "        best_student_acc = val_acc\n",
        "        torch.save(student_model.state_dict(), 'student_model.pth')\n",
        "        print(f\"  ‚úÖ Best student model saved! Val Acc: {val_acc:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    clear_memory()\n",
        "\n",
        "print(\"\\n‚úÖ Student Model Training Complete!\")\n",
        "print(f\"   Best Validation Accuracy: {best_student_acc:.4f}\")\n",
        "\n",
        "# Load best model if it exists\n",
        "if os.path.exists('student_model.pth'):\n",
        "    student_model.load_state_dict(torch.load('student_model.pth'))\n",
        "    print(\"   Loaded best student model from disk\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  No saved model found, using final epoch weights\")\n",
        "\n",
        "# ==========================================================\n",
        "# üìà STAGE 3: FINAL EVALUATION\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìà STAGE 3: Final Evaluation on Test Set\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def evaluate_model_detailed(model, model_name, file_list):\n",
        "    \"\"\"Evaluate model on test set with detailed metrics\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model.eval()\n",
        "    y_true_all = []\n",
        "    y_pred_all = []\n",
        "\n",
        "    for i, filepath in enumerate(file_list):\n",
        "        print(f\"Processing file {i+1}/{len(file_list)}: {os.path.basename(filepath)}\")\n",
        "\n",
        "        X_file, y_file = load_and_process_file(filepath, scaler, pca, label_encoder)\n",
        "\n",
        "        if X_file is None:\n",
        "            continue\n",
        "\n",
        "        dataset = FullFileDataset(X_file, y_file)\n",
        "        dataloader = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in dataloader:\n",
        "                X_batch = X_batch.unsqueeze(1).to(device)\n",
        "\n",
        "                outputs = model(X_batch)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                y_true_all.extend(y_batch.numpy())\n",
        "                y_pred_all.extend(predicted.cpu().numpy())\n",
        "\n",
        "                del X_batch, outputs\n",
        "                clear_memory()\n",
        "\n",
        "        del X_file, y_file, dataset, dataloader\n",
        "        clear_memory()\n",
        "\n",
        "    y_true_all = np.array(y_true_all)\n",
        "    y_pred_all = np.array(y_pred_all)\n",
        "\n",
        "    accuracy = accuracy_score(y_true_all, y_pred_all)\n",
        "    precision = precision_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"\\nüìä {model_name} Performance:\")\n",
        "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"   Precision: {precision:.4f}\")\n",
        "    print(f\"   Recall:    {recall:.4f}\")\n",
        "    print(f\"   F1-Score:  {f1:.4f}\")\n",
        "\n",
        "    return y_true_all, y_pred_all, accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate both models\n",
        "teacher_results = evaluate_model_detailed(teacher_model, \"TEACHER MODEL\", test_files)\n",
        "student_results = evaluate_model_detailed(student_model, \"STUDENT MODEL (Distilled)\", test_files)\n",
        "\n",
        "# ==========================================================\n",
        "# üìä GENERATE REPORTS\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä Generating Final Report...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "y_true, y_pred, s_acc, s_prec, s_rec, s_f1 = student_results\n",
        "_, _, t_acc, t_prec, t_rec, t_f1 = teacher_results\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Student Model Confusion Matrix (Knowledge Distillation)', fontsize=16, pad=20)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
        "plt.yticks(rotation=0, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.savefig('student_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úÖ Confusion matrix saved as 'student_confusion_matrix.png'\")\n",
        "\n",
        "# Performance comparison\n",
        "performance_retention = (s_acc / t_acc) * 100 if t_acc > 0 else 0\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä FINAL COMPARISON: TEACHER vs STUDENT\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Metric':<15} {'Teacher':<15} {'Student':<15} {'Difference':<15}\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Accuracy':<15} {t_acc:<15.4f} {s_acc:<15.4f} {(s_acc-t_acc):<15.4f}\")\n",
        "print(f\"{'Precision':<15} {t_prec:<15.4f} {s_prec:<15.4f} {(s_prec-t_prec):<15.4f}\")\n",
        "print(f\"{'Recall':<15} {t_rec:<15.4f} {s_rec:<15.4f} {(s_rec-t_rec):<15.4f}\")\n",
        "print(f\"{'F1-Score':<15} {t_f1:<15.4f} {s_f1:<15.4f} {(s_f1-t_f1):<15.4f}\")\n",
        "print(f\"{'Parameters':<15} {teacher_params:<15,} {student_params:<15,} {'-':<15}\")\n",
        "print(f\"{'Model Size':<15} {'1.0x':<15} {f'{1/reduction_ratio:.2f}x':<15} {f'{reduction_ratio:.1f}x smaller':<15}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nüéØ Performance Retention: {performance_retention:.2f}%\")\n",
        "print(f\"üéØ Model Size Reduction: {reduction_ratio:.1f}x smaller\")\n",
        "print(f\"üéØ Parameter Reduction: {((teacher_params - student_params) / teacher_params * 100):.1f}% fewer parameters\")\n",
        "\n",
        "# ==========================================================\n",
        "# üíæ SAVE MODELS AND PREPROCESSING OBJECTS\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üíæ Saving Models and Preprocessing Objects\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save PyTorch models\n",
        "torch.save({\n",
        "    'model_state_dict': teacher_model.state_dict(),\n",
        "    'input_size': n_components,\n",
        "    'hidden_sizes': [128, 64],\n",
        "    'num_classes': n_classes,\n",
        "    'accuracy': t_acc,\n",
        "    'params': teacher_params\n",
        "}, 'teacher_model_complete.pth')\n",
        "print(\"‚úÖ Saved: teacher_model_complete.pth\")\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': student_model.state_dict(),\n",
        "    'input_size': n_components,\n",
        "    'hidden_size': 32,\n",
        "    'num_classes': n_classes,\n",
        "    'accuracy': s_acc,\n",
        "    'params': student_params\n",
        "}, 'student_model_complete.pth')\n",
        "print(\"‚úÖ Saved: student_model_complete.pth\")\n",
        "\n",
        "# Save preprocessing objects\n",
        "preprocessing_objects = {\n",
        "    'scaler': scaler,\n",
        "    'pca': pca,\n",
        "    'label_encoder': label_encoder\n",
        "}\n",
        "\n",
        "with open('preprocessing.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessing_objects, f)\n",
        "print(\"‚úÖ Saved: preprocessing.pkl\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'n_classes': int(n_classes),\n",
        "    'n_features': int(n_features),\n",
        "    'n_components': int(n_components),\n",
        "    'teacher_params': int(teacher_params),\n",
        "    'student_params': int(student_params),\n",
        "    'teacher_accuracy': float(t_acc),\n",
        "    'student_accuracy': float(s_acc),\n",
        "    'size_reduction': float(reduction_ratio),\n",
        "    'performance_retention': float(performance_retention),\n",
        "    'total_files': len(csv_files),\n",
        "    'train_files': len(train_files),\n",
        "    'val_files': len(val_files),\n",
        "    'test_files': len(test_files),\n",
        "    'classes': label_encoder.classes_.tolist()\n",
        "}\n",
        "\n",
        "with open('model_metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "print(\"‚úÖ Saved: model_metadata.json\")\n",
        "\n",
        "# Create summary\n",
        "with open('model_summary.txt', 'w') as f:\n",
        "    f.write(\"=\" * 80 + \"\\n\")\n",
        "    f.write(\"KNOWLEDGE DISTILLATION - PYTORCH MODEL SUMMARY\\n\")\n",
        "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"DATASET INFORMATION:\\n\")\n",
        "    f.write(f\"  Total Files: {len(csv_files)}\\n\")\n",
        "    f.write(f\"  Training Files: {len(train_files)}\\n\")\n",
        "    f.write(f\"  Validation Files: {len(val_files)}\\n\")\n",
        "    f.write(f\"  Test Files: {len(test_files)}\\n\\n\")\n",
        "\n",
        "    f.write(\"TEACHER MODEL:\\n\")\n",
        "    f.write(f\"  Architecture: LSTM [128, 64]\\n\")\n",
        "    f.write(f\"  Parameters: {teacher_params:,}\\n\")\n",
        "    f.write(f\"  Accuracy: {t_acc:.4f}\\n\")\n",
        "    f.write(f\"  Precision: {t_prec:.4f}\\n\")\n",
        "    f.write(f\"  Recall: {t_rec:.4f}\\n\")\n",
        "    f.write(f\"  F1-Score: {t_f1:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"STUDENT MODEL (DISTILLED):\\n\")\n",
        "    f.write(f\"  Architecture: LSTM [32]\\n\")\n",
        "    f.write(f\"  Parameters: {student_params:,}\\n\")\n",
        "    f.write(f\"  Accuracy: {s_acc:.4f}\\n\")\n",
        "    f.write(f\"  Precision: {s_prec:.4f}\\n\")\n",
        "    f.write(f\"  Recall: {s_rec:.4f}\\n\")\n",
        "    f.write(f\"  F1-Score: {s_f1:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"COMPRESSION METRICS:\\n\")\n",
        "    f.write(f\"  Size Reduction: {reduction_ratio:.1f}x smaller\\n\")\n",
        "    f.write(f\"  Performance Retention: {performance_retention:.2f}%\\n\")\n",
        "    f.write(f\"  Parameter Reduction: {((teacher_params - student_params) / teacher_params * 100):.1f}%\\n\\n\")\n",
        "\n",
        "    f.write(\"FILES GENERATED:\\n\")\n",
        "    f.write(\"  - teacher_model_complete.pth (Teacher model with metadata)\\n\")\n",
        "    f.write(\"  - student_model_complete.pth (Student model with metadata)\\n\")\n",
        "    f.write(\"  - preprocessing.pkl (Scaler, PCA, Label Encoder)\\n\")\n",
        "    f.write(\"  - model_metadata.json (Model specifications)\\n\")\n",
        "    f.write(\"  - student_confusion_matrix.png (Confusion matrix visualization)\\n\")\n",
        "\n",
        "print(\"‚úÖ Saved: model_summary.txt\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéâ KNOWLEDGE DISTILLATION COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n‚ú® Successfully processed all {len(csv_files)} files!\")\n",
        "print(f\"‚ú® Teacher Model: {teacher_params:,} parameters ‚Üí Accuracy: {t_acc:.4f}\")\n",
        "print(f\"‚ú® Student Model: {student_params:,} parameters ‚Üí Accuracy: {s_acc:.4f}\")\n",
        "print(f\"‚ú® Compression: {reduction_ratio:.1f}x smaller with {performance_retention:.1f}% performance retention\")\n",
        "print(\"\\nüì¶ All models saved and ready for deployment!\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "sF3aPhEPfgNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f3e3cb-b3fc-48a3-8132-df0a1174e684"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üéÆ GPU Configuration\n",
            "================================================================================\n",
            "‚úÖ GPU detected: Tesla T4\n",
            "‚úÖ CUDA Version: 12.6\n",
            "‚úÖ GPU Memory: 15.83 GB\n",
            "‚úÖ cuDNN autotuner enabled\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üì• Downloading CIC-IoT-2023 Dataset from Kaggle...\n",
            "================================================================================\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/akashdogra/cic-iot-2023?dataset_version_number=1...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.77G/2.77G [00:38<00:00, 77.7MB/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset downloaded to: /root/.cache/kagglehub/datasets/akashdogra/cic-iot-2023/versions/1\n",
            "üìÇ Found 169 CSV files.\n",
            "\n",
            "üìä Dataset Split (from 169 files):\n",
            "   Training:   101 files\n",
            "   Validation: 34 files\n",
            "   Testing:    34 files\n",
            "\n",
            "================================================================================\n",
            "üè∑Ô∏è  Fitting Preprocessing - Scanning ALL Training Files...\n",
            "================================================================================\n",
            "Scanning 101 training files for all unique labels...\n",
            "  File 1/101: part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 2/101: part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 3/101: part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 4/101: part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 5/101: part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 6/101: part-00005-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 7/101: part-00006-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 8/101: part-00007-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 9/101: part-00008-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 10/101: part-00009-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 11/101: part-00010-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 12/101: part-00011-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 13/101: part-00012-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 14/101: part-00013-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 15/101: part-00014-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 16/101: part-00015-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 17/101: part-00016-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 18/101: part-00017-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 19/101: part-00018-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 20/101: part-00019-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 21/101: part-00020-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 22/101: part-00021-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 23/101: part-00022-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 24/101: part-00023-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 25/101: part-00024-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 26/101: part-00025-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 27/101: part-00026-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 28/101: part-00027-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 29/101: part-00028-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 30/101: part-00029-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 31/101: part-00030-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 32/101: part-00031-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 33/101: part-00032-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 34/101: part-00033-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 35/101: part-00034-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 36/101: part-00035-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 37/101: part-00036-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 38/101: part-00037-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 39/101: part-00038-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 40/101: part-00039-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 41/101: part-00040-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 42/101: part-00041-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 43/101: part-00042-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 44/101: part-00043-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 45/101: part-00044-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 46/101: part-00045-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 47/101: part-00046-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 48/101: part-00047-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 49/101: part-00048-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 50/101: part-00049-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 51/101: part-00050-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 52/101: part-00051-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 53/101: part-00052-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 54/101: part-00053-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 55/101: part-00054-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 56/101: part-00055-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 57/101: part-00056-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 58/101: part-00057-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 59/101: part-00058-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 60/101: part-00059-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 61/101: part-00060-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 62/101: part-00061-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 63/101: part-00062-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 64/101: part-00063-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 65/101: part-00064-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 66/101: part-00065-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 67/101: part-00066-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 68/101: part-00067-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 69/101: part-00068-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 70/101: part-00069-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 71/101: part-00070-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 72/101: part-00071-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 73/101: part-00072-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 74/101: part-00073-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 75/101: part-00074-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 76/101: part-00075-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 77/101: part-00076-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 78/101: part-00077-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 79/101: part-00078-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 80/101: part-00079-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 81/101: part-00080-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 82/101: part-00081-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 83/101: part-00082-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 84/101: part-00083-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 85/101: part-00084-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 86/101: part-00085-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 87/101: part-00086-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 88/101: part-00087-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 89/101: part-00088-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 90/101: part-00089-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 91/101: part-00090-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 92/101: part-00091-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 93/101: part-00092-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 94/101: part-00093-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 95/101: part-00094-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 96/101: part-00095-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 97/101: part-00096-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 98/101: part-00097-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 99/101: part-00098-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 100/101: part-00099-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "  File 101/101: part-00100-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv - Found 34 unique labels (Total: 34)\n",
            "\n",
            "‚úÖ LabelEncoder fitted with 34 classes\n",
            "   Classes found: Backdoor_Malware, BenignTraffic, BrowserHijacking, CommandInjection, DDoS-ACK_Fragmentation, DDoS-HTTP_Flood, DDoS-ICMP_Flood, DDoS-ICMP_Fragmentation, DDoS-PSHACK_Flood, DDoS-RSTFINFlood...\n",
            "‚úÖ Scaler fitted on 10 file samples\n",
            "‚úÖ PCA fitted with 30 components (from 46 features)\n",
            "üíæ RAM Usage: 0.64 GB | GPU: 0.00 GB\n",
            "\n",
            "================================================================================\n",
            "üéì STAGE 1: Training Teacher Model\n",
            "================================================================================\n",
            "\n",
            "üèóÔ∏è  Teacher Model: 138,946 parameters\n",
            "   Architecture: Input(30) ‚Üí LSTM(128) ‚Üí LSTM(64) ‚Üí FC(64) ‚Üí FC(32) ‚Üí Output(34)\n",
            "\n",
            "üöÄ Training Teacher Model...\n",
            "   Batch Size: 512\n",
            "   Files per Epoch Cycle: 20\n",
            "   Total Training Files: 101\n",
            "   Epochs: 3\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 1/3\n",
            "================================================================================\n",
            "Training on 20 files (indices 0 to 20)\n",
            "\n",
            "  üìÇ File 1/20: part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.0492\n",
            "üíæ RAM Usage: 1.16 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 2/20: part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.4879\n",
            "üíæ RAM Usage: 1.19 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 3/20: part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.4643\n",
            "üíæ RAM Usage: 1.19 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 4/20: part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.4493\n",
            "üíæ RAM Usage: 1.18 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 5/20: part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.4435\n",
            "üíæ RAM Usage: 1.24 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 6/20: part-00005-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.4358\n",
            "üíæ RAM Usage: 1.24 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 7/20: part-00006-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.4260\n",
            "üíæ RAM Usage: 1.19 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 8/20: part-00007-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.4192\n",
            "üíæ RAM Usage: 1.24 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 9/20: part-00008-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.4114\n",
            "üíæ RAM Usage: 1.19 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 10/20: part-00009-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.4074\n",
            "üíæ RAM Usage: 1.24 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 11/20: part-00010-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3998\n",
            "üíæ RAM Usage: 1.19 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 12/20: part-00011-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3911\n",
            "üíæ RAM Usage: 1.24 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 13/20: part-00012-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3823\n",
            "üíæ RAM Usage: 1.19 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 14/20: part-00013-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3727\n",
            "üíæ RAM Usage: 1.26 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 15/20: part-00014-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3645\n",
            "üíæ RAM Usage: 1.23 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 16/20: part-00015-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3576\n",
            "üíæ RAM Usage: 1.20 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 17/20: part-00016-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3513\n",
            "üíæ RAM Usage: 1.20 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 18/20: part-00017-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3448\n",
            "üíæ RAM Usage: 1.25 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 19/20: part-00018-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3391\n",
            "üíæ RAM Usage: 1.20 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 20/20: part-00019-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3321\n",
            "üíæ RAM Usage: 1.20 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìä Validating...\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 0.4315\n",
            "     Val Loss: 0.3067\n",
            "     Val Accuracy: 0.8682\n",
            "  ‚úÖ Best teacher model saved! Val Acc: 0.8682\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 2/3\n",
            "================================================================================\n",
            "Training on 20 files (indices 20 to 40)\n",
            "\n",
            "  üìÇ File 1/20: part-00020-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3258\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 2/20: part-00021-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3189\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 3/20: part-00022-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3151\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 4/20: part-00023-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.3071\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 5/20: part-00024-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2946\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 6/20: part-00025-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2862\n",
            "üíæ RAM Usage: 1.33 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 7/20: part-00026-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2783\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 8/20: part-00027-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2735\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 9/20: part-00028-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2702\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 10/20: part-00029-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2630\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 11/20: part-00030-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2619\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 12/20: part-00031-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2561\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 13/20: part-00032-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2512\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 14/20: part-00033-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2466\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 15/20: part-00034-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2473\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 16/20: part-00035-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2373\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 17/20: part-00036-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2255\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 18/20: part-00037-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2171\n",
            "üíæ RAM Usage: 1.30 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 19/20: part-00038-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.2113\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 20/20: part-00039-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1960\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìä Validating...\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 0.2641\n",
            "     Val Loss: 0.1550\n",
            "     Val Accuracy: 0.9321\n",
            "  ‚úÖ Best teacher model saved! Val Acc: 0.9321\n",
            "\n",
            "================================================================================\n",
            "TEACHER EPOCH 3/3\n",
            "================================================================================\n",
            "Training on 20 files (indices 40 to 60)\n",
            "\n",
            "  üìÇ File 1/20: part-00040-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1900\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 2/20: part-00041-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1841\n",
            "üíæ RAM Usage: 1.33 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 3/20: part-00042-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1807\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 4/20: part-00043-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1793\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 5/20: part-00044-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1935\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 6/20: part-00045-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1711\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 7/20: part-00046-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1769\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 8/20: part-00047-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1765\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 9/20: part-00048-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1794\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 10/20: part-00049-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1713\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 11/20: part-00050-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1743\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 12/20: part-00051-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1656\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 13/20: part-00052-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1677\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 14/20: part-00053-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1734\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 15/20: part-00054-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1830\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 16/20: part-00055-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1556\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 17/20: part-00056-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1699\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 18/20: part-00057-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1629\n",
            "üíæ RAM Usage: 1.33 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 19/20: part-00058-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1579\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 20/20: part-00059-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.1637\n",
            "üíæ RAM Usage: 1.31 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìä Validating...\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 0.1739\n",
            "     Val Loss: 0.1127\n",
            "     Val Accuracy: 0.9611\n",
            "  ‚úÖ Best teacher model saved! Val Acc: 0.9611\n",
            "\n",
            "‚úÖ Teacher Model Training Complete!\n",
            "   Best Validation Accuracy: 0.9611\n",
            "   Loaded best teacher model from disk\n",
            "\n",
            "================================================================================\n",
            "üéí STAGE 2: Knowledge Distillation - Training Student Model\n",
            "================================================================================\n",
            "\n",
            "üèóÔ∏è  Student Model: 10,370 parameters\n",
            "   Architecture: Input(30) ‚Üí LSTM(32) ‚Üí FC(32) ‚Üí Output(34)\n",
            "\n",
            "üìä Model Comparison:\n",
            "   Teacher Parameters: 138,946\n",
            "   Student Parameters: 10,370\n",
            "   Size Reduction:     13.4x smaller\n",
            "\n",
            "üöÄ Training Student with Knowledge Distillation...\n",
            "   Temperature: 4.0\n",
            "   Alpha (soft target weight): 0.7\n",
            "   Batch Size: 512\n",
            "   Files per Epoch: 20\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 1/4\n",
            "================================================================================\n",
            "Training on 20 files (indices 0 to 20)\n",
            "\n",
            "  üìÇ File 1/20: part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 12.0894\n",
            "üíæ RAM Usage: 1.36 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 2/20: part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 2.6724\n",
            "üíæ RAM Usage: 1.37 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 3/20: part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.8982\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 4/20: part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.6120\n",
            "üíæ RAM Usage: 1.38 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 5/20: part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.4894\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 6/20: part-00005-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.4052\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 7/20: part-00006-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.3456\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 8/20: part-00007-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.3000\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 9/20: part-00008-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.2605\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 10/20: part-00009-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.2338\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 11/20: part-00010-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.1994\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 12/20: part-00011-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.1752\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 13/20: part-00012-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.1543\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 14/20: part-00013-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.1284\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 15/20: part-00014-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.0945\n",
            "üíæ RAM Usage: 1.38 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 16/20: part-00015-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.0559\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 17/20: part-00016-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 1.0180\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 18/20: part-00017-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.9865\n",
            "üíæ RAM Usage: 1.38 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 19/20: part-00018-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.9558\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 20/20: part-00019-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.9267\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìä Validating...\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 1.8501\n",
            "     Val Loss: 0.4064\n",
            "     Val Accuracy: 0.8489\n",
            "  ‚úÖ Best student model saved! Val Acc: 0.8489\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 2/4\n",
            "================================================================================\n",
            "Training on 20 files (indices 20 to 40)\n",
            "\n",
            "  üìÇ File 1/20: part-00020-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.9102\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 2/20: part-00021-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.8891\n",
            "üíæ RAM Usage: 1.38 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 3/20: part-00022-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.8784\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 4/20: part-00023-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.8586\n",
            "üíæ RAM Usage: 1.40 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 5/20: part-00024-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.8505\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 6/20: part-00025-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.8323\n",
            "üíæ RAM Usage: 1.41 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 7/20: part-00026-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.8169\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 8/20: part-00027-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.8098\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 9/20: part-00028-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.8006\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 10/20: part-00029-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7923\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 11/20: part-00030-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7815\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 12/20: part-00031-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7739\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 13/20: part-00032-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7729\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 14/20: part-00033-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7612\n",
            "üíæ RAM Usage: 1.41 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 15/20: part-00034-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7571\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 16/20: part-00035-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7518\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 17/20: part-00036-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7461\n",
            "üíæ RAM Usage: 1.41 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 18/20: part-00037-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7349\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 19/20: part-00038-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7353\n",
            "üíæ RAM Usage: 1.39 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 20/20: part-00039-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7249\n",
            "üíæ RAM Usage: 1.38 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìä Validating...\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 0.7989\n",
            "     Val Loss: 0.3555\n",
            "     Val Accuracy: 0.8657\n",
            "  ‚úÖ Best student model saved! Val Acc: 0.8657\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 3/4\n",
            "================================================================================\n",
            "Training on 20 files (indices 40 to 60)\n",
            "\n",
            "  üìÇ File 1/20: part-00040-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7172\n",
            "üíæ RAM Usage: 1.36 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 2/20: part-00041-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7088\n",
            "üíæ RAM Usage: 1.36 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 3/20: part-00042-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7016\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 4/20: part-00043-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.7008\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 5/20: part-00044-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6931\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 6/20: part-00045-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6835\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 7/20: part-00046-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6814\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 8/20: part-00047-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6718\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 9/20: part-00048-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6717\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 10/20: part-00049-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6624\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 11/20: part-00050-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6595\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 12/20: part-00051-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6519\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 13/20: part-00052-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6457\n",
            "üíæ RAM Usage: 1.36 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 14/20: part-00053-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6393\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 15/20: part-00054-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6352\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 16/20: part-00055-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6289\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 17/20: part-00056-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6268\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 18/20: part-00057-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6183\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 19/20: part-00058-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6126\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 20/20: part-00059-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6073\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìä Validating...\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 0.6609\n",
            "     Val Loss: 0.3115\n",
            "     Val Accuracy: 0.8817\n",
            "  ‚úÖ Best student model saved! Val Acc: 0.8817\n",
            "\n",
            "================================================================================\n",
            "STUDENT EPOCH 4/4\n",
            "================================================================================\n",
            "Training on 20 files (indices 60 to 80)\n",
            "\n",
            "  üìÇ File 1/20: part-00060-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6077\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 2/20: part-00061-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.6014\n",
            "üíæ RAM Usage: 1.33 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 3/20: part-00062-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5965\n",
            "üíæ RAM Usage: 1.35 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 4/20: part-00063-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5985\n",
            "üíæ RAM Usage: 1.33 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 5/20: part-00064-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5890\n",
            "üíæ RAM Usage: 1.34 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 6/20: part-00065-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5871\n",
            "üíæ RAM Usage: 1.33 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 7/20: part-00066-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5819\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 8/20: part-00067-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5835\n",
            "üíæ RAM Usage: 1.33 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 9/20: part-00068-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5743\n",
            "üíæ RAM Usage: 1.32 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 10/20: part-00069-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5765\n",
            "üíæ RAM Usage: 1.30 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 11/20: part-00070-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5724\n",
            "üíæ RAM Usage: 1.27 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 12/20: part-00071-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5651\n",
            "üíæ RAM Usage: 1.26 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 13/20: part-00072-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5667\n",
            "üíæ RAM Usage: 1.27 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 14/20: part-00073-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5626\n",
            "üíæ RAM Usage: 1.24 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 15/20: part-00074-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5590\n",
            "üíæ RAM Usage: 1.24 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 16/20: part-00075-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5546\n",
            "üíæ RAM Usage: 1.25 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 17/20: part-00076-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5481\n",
            "üíæ RAM Usage: 1.26 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 18/20: part-00077-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5430\n",
            "üíæ RAM Usage: 1.25 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 19/20: part-00078-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5340\n",
            "üíæ RAM Usage: 1.25 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìÇ File 20/20: part-00079-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "     Loss: 0.5282\n",
            "üíæ RAM Usage: 1.24 GB | GPU: 0.02 GB\n",
            "\n",
            "  üìä Validating...\n",
            "\n",
            "  üìà Epoch Summary:\n",
            "     Avg Train Loss: 0.5715\n",
            "     Val Loss: 0.2710\n",
            "     Val Accuracy: 0.8829\n",
            "  ‚úÖ Best student model saved! Val Acc: 0.8829\n",
            "\n",
            "‚úÖ Student Model Training Complete!\n",
            "   Best Validation Accuracy: 0.8829\n",
            "   Loaded best student model from disk\n",
            "\n",
            "================================================================================\n",
            "üìà STAGE 3: Final Evaluation on Test Set\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "Evaluating TEACHER MODEL...\n",
            "============================================================\n",
            "Processing file 1/34: part-00135-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 2/34: part-00136-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 3/34: part-00137-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 4/34: part-00138-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 5/34: part-00139-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 6/34: part-00140-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 7/34: part-00141-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 8/34: part-00142-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 9/34: part-00143-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 10/34: part-00144-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 11/34: part-00145-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 12/34: part-00146-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 13/34: part-00147-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 14/34: part-00148-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 15/34: part-00149-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 16/34: part-00150-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 17/34: part-00151-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 18/34: part-00152-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 19/34: part-00153-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 20/34: part-00154-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 21/34: part-00155-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 22/34: part-00156-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 23/34: part-00157-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 24/34: part-00158-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 25/34: part-00159-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 26/34: part-00160-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 27/34: part-00161-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 28/34: part-00162-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 29/34: part-00163-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 30/34: part-00164-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 31/34: part-00165-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 32/34: part-00166-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 33/34: part-00167-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 34/34: part-00168-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "\n",
            "üìä TEACHER MODEL Performance:\n",
            "   Accuracy:  0.9611\n",
            "   Precision: 0.9610\n",
            "   Recall:    0.9611\n",
            "   F1-Score:  0.9598\n",
            "\n",
            "============================================================\n",
            "Evaluating STUDENT MODEL (Distilled)...\n",
            "============================================================\n",
            "Processing file 1/34: part-00135-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 2/34: part-00136-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 3/34: part-00137-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 4/34: part-00138-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 5/34: part-00139-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 6/34: part-00140-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 7/34: part-00141-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 8/34: part-00142-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 9/34: part-00143-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 10/34: part-00144-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 11/34: part-00145-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 12/34: part-00146-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 13/34: part-00147-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 14/34: part-00148-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 15/34: part-00149-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n",
            "Processing file 16/34: part-00150-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Knowledge Distillation for IoT Intrusion Detection - Full File Processing\n",
        "- Reduced model sizes for memory efficiency\n",
        "- Process entire files at once (no chunking within files)\n",
        "- Handle all 169 files properly\n",
        "- Stream one file at a time to avoid RAM overflow\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import kagglehub\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==========================================================\n",
        "# üéÆ GPU CONFIGURATION\n",
        "# ==========================================================\n",
        "\n",
        "def setup_gpu():\n",
        "    \"\"\"Configure PyTorch to use GPU efficiently\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üéÆ GPU Configuration\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
        "        print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        print(\"‚úÖ cuDNN autotuner enabled\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"‚ö†Ô∏è  No GPU detected, running on CPU\")\n",
        "\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "    return device\n",
        "\n",
        "device = setup_gpu()\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ MEMORY MANAGEMENT\n",
        "# ==========================================================\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Aggressive memory cleanup\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def print_memory_stats():\n",
        "    \"\"\"Print RAM and GPU usage\"\"\"\n",
        "    try:\n",
        "        import psutil\n",
        "        process = psutil.Process()\n",
        "        ram_gb = process.memory_info().rss / 1e9\n",
        "        print(f\"üíæ RAM Usage: {ram_gb:.2f} GB\", end=\"\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_gb = torch.cuda.memory_allocated() / 1e9\n",
        "        print(f\" | GPU: {gpu_gb:.2f} GB\")\n",
        "    else:\n",
        "        print()\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ HELPER FUNCTIONS\n",
        "# ==========================================================\n",
        "\n",
        "def load_and_clean(path, label_col=None):\n",
        "    \"\"\"Load CSV and separate features from labels\"\"\"\n",
        "    df = pd.read_csv(path, low_memory=False)\n",
        "    df = df.dropna()\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    if label_col is None:\n",
        "        label_col = \"Label\" if \"Label\" in df.columns else df.columns[-1]\n",
        "\n",
        "    X = df.drop(columns=[label_col])\n",
        "    y = df[label_col]\n",
        "\n",
        "    del df\n",
        "    gc.collect()\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def encode_objects(X):\n",
        "    \"\"\"Encode categorical columns and convert to numpy array\"\"\"\n",
        "    for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "        try:\n",
        "            X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "        except:\n",
        "            X[col] = 0\n",
        "    return X.values.astype(np.float32)\n",
        "\n",
        "def load_and_process_file(filepath, scaler, pca, label_encoder):\n",
        "    \"\"\"Load and process a single file completely\"\"\"\n",
        "    try:\n",
        "        X, y = load_and_clean(filepath)\n",
        "        X = encode_objects(X)\n",
        "\n",
        "        X_scaled = scaler.transform(X)\n",
        "        X_reduced = pca.transform(X_scaled)\n",
        "        y_encoded = label_encoder.transform(y.astype(str))\n",
        "\n",
        "        del X, y, X_scaled\n",
        "        gc.collect()\n",
        "\n",
        "        return X_reduced, y_encoded\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {os.path.basename(filepath)}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# ==========================================================\n",
        "# üì¶ FULL FILE DATASET\n",
        "# ==========================================================\n",
        "\n",
        "class FullFileDataset(Dataset):\n",
        "    \"\"\"Dataset that holds entire file in memory\"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ==========================================================\n",
        "# üéì REDUCED PYTORCH MODELS\n",
        "# ==========================================================\n",
        "\n",
        "class TeacherLSTM(nn.Module):\n",
        "    \"\"\"Teacher Model - [128, 64] (Reduced from [256,128,64])\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes, dropout=0.3):\n",
        "        super(TeacherLSTM, self).__init__()\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_sizes[0], batch_first=True)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(hidden_sizes[0], hidden_sizes[1], batch_first=True)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_sizes[1], 64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, features)\n",
        "        out, _ = self.lstm1(x)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        out, _ = self.lstm2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        # Take last timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.relu1(self.fc1(out))\n",
        "        out = self.relu2(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class StudentLSTM(nn.Module):\n",
        "    \"\"\"Student Model - [32] (Reduced from [32,16])\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_classes, dropout=0.2):\n",
        "        super(StudentLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_size, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        # Take last timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# ==========================================================\n",
        "# üéì KNOWLEDGE DISTILLATION LOSS\n",
        "# ==========================================================\n",
        "\n",
        "class DistillationLoss(nn.Module):\n",
        "    \"\"\"Combined loss for knowledge distillation\"\"\"\n",
        "\n",
        "    def __init__(self, temperature=4.0, alpha=0.7):\n",
        "        super(DistillationLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.alpha = alpha\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "        self.kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, labels):\n",
        "        # Hard target loss\n",
        "        hard_loss = self.ce_loss(student_logits, labels)\n",
        "\n",
        "        # Soft target loss\n",
        "        soft_student = torch.log_softmax(student_logits / self.temperature, dim=1)\n",
        "        soft_teacher = torch.softmax(teacher_logits / self.temperature, dim=1)\n",
        "\n",
        "        soft_loss = self.kl_loss(soft_student, soft_teacher) * (self.temperature ** 2)\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "# ==========================================================\n",
        "# üèãÔ∏è TRAINING FUNCTIONS (FULL FILE AT ONCE)\n",
        "# ==========================================================\n",
        "\n",
        "def train_on_file(model, filepath, scaler, pca, label_encoder, optimizer,\n",
        "                  criterion, device, batch_size=512, is_distillation=False,\n",
        "                  teacher_model=None):\n",
        "    \"\"\"Train on entire file at once\"\"\"\n",
        "\n",
        "    # Load and process entire file\n",
        "    X_file, y_file = load_and_process_file(filepath, scaler, pca, label_encoder)\n",
        "\n",
        "    if X_file is None:\n",
        "        return 0\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = FullFileDataset(X_file, y_file)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    model.train()\n",
        "    if teacher_model is not None:\n",
        "        teacher_model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        X_batch = X_batch.unsqueeze(1).to(device)  # Add sequence dimension\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        if is_distillation and teacher_model is not None:\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(X_batch)\n",
        "            loss = criterion(outputs, teacher_outputs, y_batch)\n",
        "        else:\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * len(y_batch)\n",
        "        total_samples += len(y_batch)\n",
        "\n",
        "        del X_batch, y_batch, outputs\n",
        "        clear_memory()\n",
        "\n",
        "    # Clean up file data\n",
        "    del X_file, y_file, dataset, dataloader\n",
        "    clear_memory()\n",
        "\n",
        "    return total_loss / total_samples if total_samples > 0 else 0\n",
        "\n",
        "\n",
        "def evaluate_on_files(model, file_list, scaler, pca, label_encoder,\n",
        "                      criterion, device, batch_size=512):\n",
        "    \"\"\"Evaluate on multiple files\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for filepath in file_list:\n",
        "        X_file, y_file = load_and_process_file(filepath, scaler, pca, label_encoder)\n",
        "\n",
        "        if X_file is None:\n",
        "            continue\n",
        "\n",
        "        dataset = FullFileDataset(X_file, y_file)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in dataloader:\n",
        "                X_batch = X_batch.unsqueeze(1).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct += (predicted == y_batch).sum().item()\n",
        "                total_loss += loss.item() * len(y_batch)\n",
        "                total_samples += len(y_batch)\n",
        "\n",
        "                del X_batch, y_batch, outputs\n",
        "                clear_memory()\n",
        "\n",
        "        del X_file, y_file, dataset, dataloader\n",
        "        clear_memory()\n",
        "\n",
        "    accuracy = correct / total_samples if total_samples > 0 else 0\n",
        "    avg_loss = total_loss / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# ==========================================================\n",
        "# üìÇ DOWNLOAD & SPLIT DATASET (169 FILES)\n",
        "# ==========================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üì• Downloading CIC-IoT-2023 Dataset from Kaggle...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "dataset_dir = kagglehub.dataset_download(\"akashdogra/cic-iot-2023\")\n",
        "print(f\"‚úÖ Dataset downloaded to: {dataset_dir}\")\n",
        "\n",
        "csv_files = sorted([\n",
        "    os.path.join(dataset_dir, f)\n",
        "    for f in os.listdir(dataset_dir)\n",
        "    if f.endswith(\".csv\")\n",
        "])\n",
        "\n",
        "print(f\"üìÇ Found {len(csv_files)} CSV files.\")\n",
        "\n",
        "# 60-20-20 split\n",
        "n_files = len(csv_files)\n",
        "train_idx = int(n_files * 0.60)\n",
        "val_idx = int(n_files * 0.80)\n",
        "\n",
        "train_files = csv_files[:train_idx]\n",
        "val_files = csv_files[train_idx:val_idx]\n",
        "test_files = csv_files[val_idx:]\n",
        "\n",
        "print(f\"\\nüìä Dataset Split (from {n_files} files):\")\n",
        "print(f\"   Training:   {len(train_files)} files\")\n",
        "print(f\"   Validation: {len(val_files)} files\")\n",
        "print(f\"   Testing:    {len(test_files)} files\")\n",
        "\n",
        "# ==========================================================\n",
        "# üè∑Ô∏è FIT PREPROCESSING (SCAN ALL TRAINING FILES FOR LABELS)\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üè∑Ô∏è  Fitting Preprocessing - Scanning ALL Training Files...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# CRITICAL FIX: Scan ALL training files to collect ALL unique labels\n",
        "all_labels = set()\n",
        "sample_data = []\n",
        "\n",
        "print(f\"Scanning {len(train_files)} training files for all unique labels...\")\n",
        "for i, filepath in enumerate(train_files):\n",
        "    try:\n",
        "        # Read only the label column to save memory\n",
        "        df = pd.read_csv(filepath, low_memory=False)\n",
        "        label_col = \"Label\" if \"Label\" in df.columns else df.columns[-1]\n",
        "\n",
        "        # Collect all unique labels from this file\n",
        "        unique_labels = df[label_col].dropna().astype(str).unique()\n",
        "        all_labels.update(unique_labels)\n",
        "\n",
        "        print(f\"  File {i+1}/{len(train_files)}: {os.path.basename(filepath)} - Found {len(unique_labels)} unique labels (Total: {len(all_labels)})\")\n",
        "\n",
        "        # Sample features from first 10 files only\n",
        "        if i < 10:\n",
        "            df_sample = df.head(1000).dropna()\n",
        "            X = df_sample.drop(columns=[label_col])\n",
        "\n",
        "            # Encode objects\n",
        "            for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "                try:\n",
        "                    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "                except:\n",
        "                    X[col] = 0\n",
        "\n",
        "            sample_data.append(X.values.astype(np.float32))\n",
        "\n",
        "        del df\n",
        "        gc.collect()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è  Error reading {os.path.basename(filepath)}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Convert set to sorted list for consistent encoding\n",
        "all_labels = sorted(list(all_labels))\n",
        "\n",
        "# Fit label encoder with ALL labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_labels)\n",
        "n_classes = len(label_encoder.classes_)\n",
        "\n",
        "print(f\"\\n‚úÖ LabelEncoder fitted with {n_classes} classes\")\n",
        "print(f\"   Classes found: {', '.join(label_encoder.classes_[:10])}{'...' if n_classes > 10 else ''}\")\n",
        "\n",
        "# Fit scaler\n",
        "scaler = StandardScaler()\n",
        "for data in sample_data:\n",
        "    scaler.partial_fit(data)\n",
        "\n",
        "print(f\"‚úÖ Scaler fitted on {len(sample_data)} file samples\")\n",
        "\n",
        "# Fit PCA\n",
        "n_features = sample_data[0].shape[1]\n",
        "n_components = min(30, n_features)\n",
        "\n",
        "pca = IncrementalPCA(n_components=n_components)\n",
        "for data in sample_data:\n",
        "    X_scaled = scaler.transform(data)\n",
        "    pca.partial_fit(X_scaled)\n",
        "\n",
        "print(f\"‚úÖ PCA fitted with {n_components} components (from {n_features} features)\")\n",
        "\n",
        "del all_labels, sample_data\n",
        "clear_memory()\n",
        "print_memory_stats()\n",
        "\n",
        "# ==========================================================\n",
        "# üéì STAGE 1: TRAIN TEACHER MODEL\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéì STAGE 1: Training Teacher Model\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize teacher model with REDUCED sizes\n",
        "teacher_model = TeacherLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_sizes=[128, 64],  # Reduced from [256, 128, 64]\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
        "print(f\"\\nüèóÔ∏è  Teacher Model: {teacher_params:,} parameters\")\n",
        "print(f\"   Architecture: Input({n_components}) ‚Üí LSTM(128) ‚Üí LSTM(64) ‚Üí FC(64) ‚Üí FC(32) ‚Üí Output({n_classes})\")\n",
        "\n",
        "# Optimizer and criterion\n",
        "teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
        "teacher_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "epochs_teacher = 3  # Train over all files 3 times\n",
        "batch_size = 512  # Large batch size allowed\n",
        "files_per_epoch = 20  # Process 20 files per epoch (will cycle through all 101 training files)\n",
        "\n",
        "best_teacher_acc = 0\n",
        "patience_counter = 0\n",
        "patience = 5  # Increased patience\n",
        "\n",
        "print(\"\\nüöÄ Training Teacher Model...\")\n",
        "print(f\"   Batch Size: {batch_size}\")\n",
        "print(f\"   Files per Epoch Cycle: {files_per_epoch}\")\n",
        "print(f\"   Total Training Files: {len(train_files)}\")\n",
        "print(f\"   Epochs: {epochs_teacher}\")\n",
        "\n",
        "for epoch in range(epochs_teacher):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TEACHER EPOCH {epoch+1}/{epochs_teacher}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Select rotating files\n",
        "    start_idx = (epoch * files_per_epoch) % len(train_files)\n",
        "    end_idx = min(start_idx + files_per_epoch, len(train_files))\n",
        "    selected_files = train_files[start_idx:end_idx]\n",
        "\n",
        "    if len(selected_files) < files_per_epoch and len(train_files) > files_per_epoch:\n",
        "        remaining = files_per_epoch - len(selected_files)\n",
        "        selected_files += train_files[:remaining]\n",
        "\n",
        "    print(f\"Training on {len(selected_files)} files (indices {start_idx} to {end_idx})\")\n",
        "\n",
        "    # Train on each file\n",
        "    epoch_losses = []\n",
        "    for i, filepath in enumerate(selected_files):\n",
        "        print(f\"\\n  üìÇ File {i+1}/{len(selected_files)}: {os.path.basename(filepath)}\")\n",
        "\n",
        "        train_loss = train_on_file(\n",
        "            teacher_model, filepath, scaler, pca, label_encoder,\n",
        "            teacher_optimizer, teacher_criterion, device, batch_size=batch_size\n",
        "        )\n",
        "\n",
        "        epoch_losses.append(train_loss)\n",
        "        print(f\"     Loss: {train_loss:.4f}\")\n",
        "        print_memory_stats()\n",
        "\n",
        "    avg_train_loss = np.mean(epoch_losses)\n",
        "\n",
        "    # Validate on subset of validation files\n",
        "    print(f\"\\n  üìä Validating...\")\n",
        "    val_loss, val_acc = evaluate_on_files(\n",
        "        teacher_model, val_files[:5], scaler, pca, label_encoder,\n",
        "        teacher_criterion, device, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  üìà Epoch Summary:\")\n",
        "    print(f\"     Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"     Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"     Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_teacher_acc:\n",
        "        best_teacher_acc = val_acc\n",
        "        torch.save(teacher_model.state_dict(), 'teacher_model.pth')\n",
        "        print(f\"  ‚úÖ Best teacher model saved! Val Acc: {val_acc:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    clear_memory()\n",
        "\n",
        "print(\"\\n‚úÖ Teacher Model Training Complete!\")\n",
        "print(f\"   Best Validation Accuracy: {best_teacher_acc:.4f}\")\n",
        "\n",
        "# Load best model if it was saved, otherwise keep current\n",
        "if os.path.exists('teacher_model.pth'):\n",
        "    teacher_model.load_state_dict(torch.load('teacher_model.pth'))\n",
        "    print(\"   Loaded best teacher model from disk\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  No saved model found, using final epoch weights\")\n",
        "\n",
        "# ==========================================================\n",
        "# üéí STAGE 2: KNOWLEDGE DISTILLATION - TRAIN STUDENT\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéí STAGE 2: Knowledge Distillation - Training Student Model\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize student model with REDUCED size\n",
        "student_model = StudentLSTM(\n",
        "    input_size=n_components,\n",
        "    hidden_size=32,  # Single layer, reduced from [32, 16]\n",
        "    num_classes=n_classes,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "student_params = sum(p.numel() for p in student_model.parameters())\n",
        "reduction_ratio = teacher_params / student_params\n",
        "\n",
        "print(f\"\\nüèóÔ∏è  Student Model: {student_params:,} parameters\")\n",
        "print(f\"   Architecture: Input({n_components}) ‚Üí LSTM(32) ‚Üí FC(32) ‚Üí Output({n_classes})\")\n",
        "print(f\"\\nüìä Model Comparison:\")\n",
        "print(f\"   Teacher Parameters: {teacher_params:,}\")\n",
        "print(f\"   Student Parameters: {student_params:,}\")\n",
        "print(f\"   Size Reduction:     {reduction_ratio:.1f}x smaller\")\n",
        "\n",
        "# Optimizer and distillation loss\n",
        "student_optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
        "distillation_criterion = DistillationLoss(temperature=4.0, alpha=0.7)\n",
        "\n",
        "epochs_student = 4\n",
        "best_student_acc = 0\n",
        "patience_counter = 0\n",
        "\n",
        "print(f\"\\nüöÄ Training Student with Knowledge Distillation...\")\n",
        "print(f\"   Temperature: {distillation_criterion.temperature}\")\n",
        "print(f\"   Alpha (soft target weight): {distillation_criterion.alpha}\")\n",
        "print(f\"   Batch Size: {batch_size}\")\n",
        "print(f\"   Files per Epoch: {files_per_epoch}\")\n",
        "\n",
        "for epoch in range(epochs_student):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"STUDENT EPOCH {epoch+1}/{epochs_student}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Select rotating files\n",
        "    start_idx = (epoch * files_per_epoch) % len(train_files)\n",
        "    end_idx = min(start_idx + files_per_epoch, len(train_files))\n",
        "    selected_files = train_files[start_idx:end_idx]\n",
        "\n",
        "    if len(selected_files) < files_per_epoch and len(train_files) > files_per_epoch:\n",
        "        remaining = files_per_epoch - len(selected_files)\n",
        "        selected_files += train_files[:remaining]\n",
        "\n",
        "    print(f\"Training on {len(selected_files)} files (indices {start_idx} to {end_idx})\")\n",
        "\n",
        "    # Train with distillation\n",
        "    epoch_losses = []\n",
        "    for i, filepath in enumerate(selected_files):\n",
        "        print(f\"\\n  üìÇ File {i+1}/{len(selected_files)}: {os.path.basename(filepath)}\")\n",
        "\n",
        "        train_loss = train_on_file(\n",
        "            student_model, filepath, scaler, pca, label_encoder,\n",
        "            student_optimizer, distillation_criterion, device,\n",
        "            batch_size=batch_size, is_distillation=True, teacher_model=teacher_model\n",
        "        )\n",
        "\n",
        "        epoch_losses.append(train_loss)\n",
        "        print(f\"     Loss: {train_loss:.4f}\")\n",
        "        print_memory_stats()\n",
        "\n",
        "    avg_train_loss = np.mean(epoch_losses)\n",
        "\n",
        "    # Validate\n",
        "    print(f\"\\n  üìä Validating...\")\n",
        "    val_criterion = nn.CrossEntropyLoss()\n",
        "    val_loss, val_acc = evaluate_on_files(\n",
        "        student_model, val_files[:5], scaler, pca, label_encoder,\n",
        "        val_criterion, device, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  üìà Epoch Summary:\")\n",
        "    print(f\"     Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"     Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"     Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_student_acc:\n",
        "        best_student_acc = val_acc\n",
        "        torch.save(student_model.state_dict(), 'student_model.pth')\n",
        "        print(f\"  ‚úÖ Best student model saved! Val Acc: {val_acc:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    clear_memory()\n",
        "\n",
        "print(\"\\n‚úÖ Student Model Training Complete!\")\n",
        "print(f\"   Best Validation Accuracy: {best_student_acc:.4f}\")\n",
        "\n",
        "# Load best model if it exists\n",
        "if os.path.exists('student_model.pth'):\n",
        "    student_model.load_state_dict(torch.load('student_model.pth'))\n",
        "    print(\"   Loaded best student model from disk\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  No saved model found, using final epoch weights\")\n",
        "\n",
        "# ==========================================================\n",
        "# üìà STAGE 3: FINAL EVALUATION\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìà STAGE 3: Final Evaluation on Test Set\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def evaluate_model_detailed(model, model_name, file_list):\n",
        "    \"\"\"Evaluate model on test set with detailed metrics\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model.eval()\n",
        "    y_true_all = []\n",
        "    y_pred_all = []\n",
        "\n",
        "    for i, filepath in enumerate(file_list):\n",
        "        print(f\"Processing file {i+1}/{len(file_list)}: {os.path.basename(filepath)}\")\n",
        "\n",
        "        X_file, y_file = load_and_process_file(filepath, scaler, pca, label_encoder)\n",
        "\n",
        "        if X_file is None:\n",
        "            continue\n",
        "\n",
        "        dataset = FullFileDataset(X_file, y_file)\n",
        "        dataloader = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in dataloader:\n",
        "                X_batch = X_batch.unsqueeze(1).to(device)\n",
        "\n",
        "                outputs = model(X_batch)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                y_true_all.extend(y_batch.numpy())\n",
        "                y_pred_all.extend(predicted.cpu().numpy())\n",
        "\n",
        "                del X_batch, outputs\n",
        "                clear_memory()\n",
        "\n",
        "        del X_file, y_file, dataset, dataloader\n",
        "        clear_memory()\n",
        "\n",
        "    y_true_all = np.array(y_true_all)\n",
        "    y_pred_all = np.array(y_pred_all)\n",
        "\n",
        "    accuracy = accuracy_score(y_true_all, y_pred_all)\n",
        "    precision = precision_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_all, y_pred_all, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"\\nüìä {model_name} Performance:\")\n",
        "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"   Precision: {precision:.4f}\")\n",
        "    print(f\"   Recall:    {recall:.4f}\")\n",
        "    print(f\"   F1-Score:  {f1:.4f}\")\n",
        "\n",
        "    return y_true_all, y_pred_all, accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate both models\n",
        "teacher_results = evaluate_model_detailed(teacher_model, \"TEACHER MODEL\", test_files)\n",
        "student_results = evaluate_model_detailed(student_model, \"STUDENT MODEL (Distilled)\", test_files)\n",
        "\n",
        "# ==========================================================\n",
        "# üìä GENERATE REPORTS\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä Generating Final Report...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "y_true, y_pred, s_acc, s_prec, s_rec, s_f1 = student_results\n",
        "_, _, t_acc, t_prec, t_rec, t_f1 = teacher_results\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Student Model Confusion Matrix (Knowledge Distillation)', fontsize=16, pad=20)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
        "plt.yticks(rotation=0, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.savefig('student_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úÖ Confusion matrix saved as 'student_confusion_matrix.png'\")\n",
        "\n",
        "# Performance comparison\n",
        "performance_retention = (s_acc / t_acc) * 100 if t_acc > 0 else 0\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä FINAL COMPARISON: TEACHER vs STUDENT\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Metric':<15} {'Teacher':<15} {'Student':<15} {'Difference':<15}\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Accuracy':<15} {t_acc:<15.4f} {s_acc:<15.4f} {(s_acc-t_acc):<15.4f}\")\n",
        "print(f\"{'Precision':<15} {t_prec:<15.4f} {s_prec:<15.4f} {(s_prec-t_prec):<15.4f}\")\n",
        "print(f\"{'Recall':<15} {t_rec:<15.4f} {s_rec:<15.4f} {(s_rec-t_rec):<15.4f}\")\n",
        "print(f\"{'F1-Score':<15} {t_f1:<15.4f} {s_f1:<15.4f} {(s_f1-t_f1):<15.4f}\")\n",
        "print(f\"{'Parameters':<15} {teacher_params:<15,} {student_params:<15,} {'-':<15}\")\n",
        "print(f\"{'Model Size':<15} {'1.0x':<15} {f'{1/reduction_ratio:.2f}x':<15} {f'{reduction_ratio:.1f}x smaller':<15}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nüéØ Performance Retention: {performance_retention:.2f}%\")\n",
        "print(f\"üéØ Model Size Reduction: {reduction_ratio:.1f}x smaller\")\n",
        "print(f\"üéØ Parameter Reduction: {((teacher_params - student_params) / teacher_params * 100):.1f}% fewer parameters\")\n",
        "\n",
        "# ==========================================================\n",
        "# üíæ SAVE MODELS AND PREPROCESSING OBJECTS\n",
        "# ==========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üíæ Saving Models and Preprocessing Objects\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save PyTorch models\n",
        "torch.save({\n",
        "    'model_state_dict': teacher_model.state_dict(),\n",
        "    'input_size': n_components,\n",
        "    'hidden_sizes': [128, 64],\n",
        "    'num_classes': n_classes,\n",
        "    'accuracy': t_acc,\n",
        "    'params': teacher_params\n",
        "}, 'teacher_model_complete.pth')\n",
        "print(\"‚úÖ Saved: teacher_model_complete.pth\")\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': student_model.state_dict(),\n",
        "    'input_size': n_components,\n",
        "    'hidden_size': 32,\n",
        "    'num_classes': n_classes,\n",
        "    'accuracy': s_acc,\n",
        "    'params': student_params\n",
        "}, 'student_model_complete.pth')\n",
        "print(\"‚úÖ Saved: student_model_complete.pth\")\n",
        "\n",
        "# Save preprocessing objects\n",
        "preprocessing_objects = {\n",
        "    'scaler': scaler,\n",
        "    'pca': pca,\n",
        "    'label_encoder': label_encoder\n",
        "}\n",
        "\n",
        "with open('preprocessing.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessing_objects, f)\n",
        "print(\"‚úÖ Saved: preprocessing.pkl\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'n_classes': int(n_classes),\n",
        "    'n_features': int(n_features),\n",
        "    'n_components': int(n_components),\n",
        "    'teacher_params': int(teacher_params),\n",
        "    'student_params': int(student_params),\n",
        "    'teacher_accuracy': float(t_acc),\n",
        "    'student_accuracy': float(s_acc),\n",
        "    'size_reduction': float(reduction_ratio),\n",
        "    'performance_retention': float(performance_retention),\n",
        "    'total_files': len(csv_files),\n",
        "    'train_files': len(train_files),\n",
        "    'val_files': len(val_files),\n",
        "    'test_files': len(test_files),\n",
        "    'classes': label_encoder.classes_.tolist()\n",
        "}\n",
        "\n",
        "with open('model_metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "print(\"‚úÖ Saved: model_metadata.json\")\n",
        "\n",
        "# Create summary\n",
        "with open('model_summary.txt', 'w') as f:\n",
        "    f.write(\"=\" * 80 + \"\\n\")\n",
        "    f.write(\"KNOWLEDGE DISTILLATION - PYTORCH MODEL SUMMARY\\n\")\n",
        "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"DATASET INFORMATION:\\n\")\n",
        "    f.write(f\"  Total Files: {len(csv_files)}\\n\")\n",
        "    f.write(f\"  Training Files: {len(train_files)}\\n\")\n",
        "    f.write(f\"  Validation Files: {len(val_files)}\\n\")\n",
        "    f.write(f\"  Test Files: {len(test_files)}\\n\\n\")\n",
        "\n",
        "    f.write(\"TEACHER MODEL:\\n\")\n",
        "    f.write(f\"  Architecture: LSTM [128, 64]\\n\")\n",
        "    f.write(f\"  Parameters: {teacher_params:,}\\n\")\n",
        "    f.write(f\"  Accuracy: {t_acc:.4f}\\n\")\n",
        "    f.write(f\"  Precision: {t_prec:.4f}\\n\")\n",
        "    f.write(f\"  Recall: {t_rec:.4f}\\n\")\n",
        "    f.write(f\"  F1-Score: {t_f1:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"STUDENT MODEL (DISTILLED):\\n\")\n",
        "    f.write(f\"  Architecture: LSTM [32]\\n\")\n",
        "    f.write(f\"  Parameters: {student_params:,}\\n\")\n",
        "    f.write(f\"  Accuracy: {s_acc:.4f}\\n\")\n",
        "    f.write(f\"  Precision: {s_prec:.4f}\\n\")\n",
        "    f.write(f\"  Recall: {s_rec:.4f}\\n\")\n",
        "    f.write(f\"  F1-Score: {s_f1:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"COMPRESSION METRICS:\\n\")\n",
        "    f.write(f\"  Size Reduction: {reduction_ratio:.1f}x smaller\\n\")\n",
        "    f.write(f\"  Performance Retention: {performance_retention:.2f}%\\n\")\n",
        "    f.write(f\"  Parameter Reduction: {((teacher_params - student_params) / teacher_params * 100):.1f}%\\n\\n\")\n",
        "\n",
        "    f.write(\"FILES GENERATED:\\n\")\n",
        "    f.write(\"  - teacher_model_complete.pth (Teacher model with metadata)\\n\")\n",
        "    f.write(\"  - student_model_complete.pth (Student model with metadata)\\n\")\n",
        "    f.write(\"  - preprocessing.pkl (Scaler, PCA, Label Encoder)\\n\")\n",
        "    f.write(\"  - model_metadata.json (Model specifications)\\n\")\n",
        "    f.write(\"  - student_confusion_matrix.png (Confusion matrix visualization)\\n\")\n",
        "\n",
        "print(\"‚úÖ Saved: model_summary.txt\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéâ KNOWLEDGE DISTILLATION COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n‚ú® Successfully processed all {len(csv_files)} files!\")\n",
        "print(f\"‚ú® Teacher Model: {teacher_params:,} parameters ‚Üí Accuracy: {t_acc:.4f}\")\n",
        "print(f\"‚ú® Student Model: {student_params:,} parameters ‚Üí Accuracy: {s_acc:.4f}\")\n",
        "print(f\"‚ú® Compression: {reduction_ratio:.1f}x smaller with {performance_retention:.1f}% performance retention\")\n",
        "print(\"\\nüì¶ All models saved and ready for deployment!\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "oNIzUwhihpu5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}